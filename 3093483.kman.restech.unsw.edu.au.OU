/home/z5102138/anaconda3/envs/py36/bin/python
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_1
----------------------



epoch 1, loss 0.7777, train acc 33.92%, f1 0.4978, precision 0.3314, recall 1.0000, auc 0.5087
epoch 501, loss 0.4870, train acc 74.27%, f1 0.7105, precision 0.5625, recall 0.9643, auc 0.7995
epoch 1001, loss 0.3298, train acc 78.95%, f1 0.7500, precision 0.6136, recall 0.9643, auc 0.8343
epoch 1501, loss 0.3874, train acc 78.95%, f1 0.7500, precision 0.6136, recall 0.9643, auc 0.8343
epoch 2001, loss 0.3466, train acc 82.46%, f1 0.7857, precision 0.6548, recall 0.9821, auc 0.8650
epoch 2501, loss 0.2980, train acc 83.04%, f1 0.7914, precision 0.6627, recall 0.9821, auc 0.8693
epoch 3001, loss 0.2960, train acc 84.80%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8824
epoch 3501, loss 0.3257, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4001, loss 0.3084, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 4501, loss 0.3288, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 5001, loss 0.2623, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 5501, loss 0.3004, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.3181, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6501, loss 0.2455, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.3013, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.3062, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8001, loss 0.2224, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8501, loss 0.2813, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9001, loss 0.2409, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9501, loss 0.2386, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10001, loss 0.2392, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 10501, loss 0.2553, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 11001, loss 0.2499, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 11501, loss 0.2974, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 12001, loss 0.3121, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 12501, loss 0.2512, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 13001, loss 0.1643, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 13501, loss 0.1932, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 14001, loss 0.3016, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 14501, loss 0.1866, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15001, loss 0.2947, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15501, loss 0.2453, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 16001, loss 0.1939, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 16501, loss 0.2277, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 17001, loss 0.2904, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 17501, loss 0.2737, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 18001, loss 0.2734, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 18501, loss 0.1869, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 19001, loss 0.1944, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 19501, loss 0.2449, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
running_time is 20.324746798
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.3
normal_0.5
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_1
./test_glass0/result_MLP_20000_0.3_normal_0.5/record_1/
----------------------



the AUC is 0.5862068965517242

the Fscore is 0.5384615384615384

the precision is 0.3684210526315789

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_2
----------------------



epoch 1, loss 0.7222, train acc 33.33%, f1 0.4956, precision 0.3294, recall 1.0000, auc 0.5043
epoch 501, loss 0.4270, train acc 69.01%, f1 0.6788, precision 0.5138, recall 1.0000, auc 0.7696
epoch 1001, loss 0.3753, train acc 77.19%, f1 0.7383, precision 0.5914, recall 0.9821, auc 0.8259
epoch 1501, loss 0.3320, train acc 81.87%, f1 0.7801, precision 0.6471, recall 0.9821, auc 0.8606
epoch 2001, loss 0.2467, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 2501, loss 0.2373, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 3001, loss 0.2859, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 3501, loss 0.1966, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 4001, loss 0.2350, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 4501, loss 0.2017, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 5001, loss 0.1619, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 5501, loss 0.1573, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 6001, loss 0.1872, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 6501, loss 0.1371, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 7001, loss 0.1666, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 7501, loss 0.1673, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 8001, loss 0.2431, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 8501, loss 0.1886, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9001, loss 0.1877, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 9501, loss 0.2180, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10001, loss 0.1409, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 10501, loss 0.1661, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 11001, loss 0.1496, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 11501, loss 0.1790, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 12001, loss 0.1842, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 12501, loss 0.2635, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.1519, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.1738, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1659, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 14501, loss 0.2124, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 15001, loss 0.2068, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1445, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16001, loss 0.1813, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16501, loss 0.1795, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17001, loss 0.1586, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17501, loss 0.1257, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 18001, loss 0.1404, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 18501, loss 0.1576, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19001, loss 0.2222, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19501, loss 0.1132, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 20.111303784
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.3
normal_0.5
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_2
./test_glass0/result_MLP_20000_0.3_normal_0.5/record_1/
----------------------



the AUC is 0.518472906403941

the Fscore is 0.125

the precision is 0.5

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_3
----------------------



epoch 1, loss 0.5558, train acc 38.01%, f1 0.5138, precision 0.3457, recall 1.0000, auc 0.5391
epoch 501, loss 0.3296, train acc 71.93%, f1 0.6962, precision 0.5392, recall 0.9821, auc 0.7867
epoch 1001, loss 0.2694, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 1501, loss 0.3600, train acc 77.19%, f1 0.7383, precision 0.5914, recall 0.9821, auc 0.8259
epoch 2001, loss 0.4314, train acc 78.95%, f1 0.7534, precision 0.6111, recall 0.9821, auc 0.8389
epoch 2501, loss 0.3658, train acc 78.95%, f1 0.7534, precision 0.6111, recall 0.9821, auc 0.8389
epoch 3001, loss 0.3347, train acc 80.70%, f1 0.7692, precision 0.6322, recall 0.9821, auc 0.8519
epoch 3501, loss 0.3615, train acc 80.70%, f1 0.7692, precision 0.6322, recall 0.9821, auc 0.8519
epoch 4001, loss 0.3144, train acc 82.46%, f1 0.7857, precision 0.6548, recall 0.9821, auc 0.8650
epoch 4501, loss 0.3206, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 5001, loss 0.3115, train acc 84.80%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8824
epoch 5501, loss 0.1984, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.2157, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6501, loss 0.2092, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7001, loss 0.1916, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 7501, loss 0.2012, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8001, loss 0.1927, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8501, loss 0.2435, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 9001, loss 0.2411, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 9501, loss 0.2221, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10001, loss 0.1842, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 10501, loss 0.1383, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11001, loss 0.1406, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11501, loss 0.1842, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12001, loss 0.1934, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.1727, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13001, loss 0.1470, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.1737, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1785, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.1416, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.1723, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1889, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16001, loss 0.1488, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1545, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.1558, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17501, loss 0.1563, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 18001, loss 0.1931, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 18501, loss 0.1672, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19001, loss 0.1392, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19501, loss 0.1664, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 20.340962380999997
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.3
normal_0.5
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_3
./test_glass0/result_MLP_20000_0.3_normal_0.5/record_1/
----------------------



the AUC is 0.625615763546798

the Fscore is 0.4210526315789473

the precision is 0.8

the recall is 0.2857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_4
----------------------



epoch 1, loss 0.6668, train acc 49.71%, f1 0.5612, precision 0.3929, recall 0.9821, auc 0.6215
epoch 501, loss 0.3955, train acc 71.35%, f1 0.6879, precision 0.5347, recall 0.9643, auc 0.7778
epoch 1001, loss 0.3574, train acc 73.68%, f1 0.7059, precision 0.5567, recall 0.9643, auc 0.7952
epoch 1501, loss 0.4318, train acc 74.85%, f1 0.7114, precision 0.5699, recall 0.9464, auc 0.7993
epoch 2001, loss 0.3794, train acc 77.19%, f1 0.7347, precision 0.5934, recall 0.9643, auc 0.8213
epoch 2501, loss 0.2978, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 3001, loss 0.3104, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 3501, loss 0.2506, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.3013, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4501, loss 0.2426, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5001, loss 0.2694, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 5501, loss 0.3289, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6001, loss 0.3159, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 6501, loss 0.2892, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 7001, loss 0.2799, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 7501, loss 0.2404, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8001, loss 0.2309, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8501, loss 0.2254, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9001, loss 0.2994, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9501, loss 0.1798, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10001, loss 0.2903, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10501, loss 0.2224, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 11001, loss 0.2835, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 11501, loss 0.2382, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 12001, loss 0.2089, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 12501, loss 0.1709, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 13001, loss 0.1883, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 13501, loss 0.2147, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 14001, loss 0.2423, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 14501, loss 0.2116, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 15001, loss 0.1857, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 15501, loss 0.2820, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 16001, loss 0.2630, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 16501, loss 0.2634, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 17001, loss 0.1637, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 17501, loss 0.1760, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 18001, loss 0.2482, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 18501, loss 0.2827, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 19001, loss 0.2983, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 19501, loss 0.1419, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
running_time is 20.182973967
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.3
normal_0.5
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_4
./test_glass0/result_MLP_20000_0.3_normal_0.5/record_1/
----------------------



the AUC is 0.6096059113300493

the Fscore is 0.43478260869565216

the precision is 0.5555555555555556

the recall is 0.35714285714285715

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_5
----------------------



epoch 1, loss 0.7223, train acc 44.77%, f1 0.5411, precision 0.3709, recall 1.0000, auc 0.5905
epoch 501, loss 0.3857, train acc 70.35%, f1 0.6832, precision 0.5238, recall 0.9821, auc 0.7756
epoch 1001, loss 0.3711, train acc 78.49%, f1 0.7448, precision 0.6067, recall 0.9643, auc 0.8313
epoch 1501, loss 0.3583, train acc 80.81%, f1 0.7660, precision 0.6353, recall 0.9643, auc 0.8485
epoch 2001, loss 0.3083, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 2501, loss 0.3545, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 3001, loss 0.3458, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 3501, loss 0.2908, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 4001, loss 0.3203, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 4501, loss 0.2804, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 5001, loss 0.2465, train acc 86.05%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8919
epoch 5501, loss 0.2307, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 6001, loss 0.2579, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 6501, loss 0.3309, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 7001, loss 0.2181, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 7501, loss 0.1843, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 8001, loss 0.2605, train acc 89.53%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9224
epoch 8501, loss 0.2706, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 9001, loss 0.2452, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 9501, loss 0.2123, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 10001, loss 0.1816, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 10501, loss 0.2385, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 11001, loss 0.1587, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 11501, loss 0.2239, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 12001, loss 0.1939, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 12501, loss 0.2469, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 13001, loss 0.1888, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 13501, loss 0.2038, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 14001, loss 0.1788, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 14501, loss 0.2052, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 15001, loss 0.1643, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 15501, loss 0.2257, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 16001, loss 0.2217, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 16501, loss 0.1564, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 17001, loss 0.1787, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 17501, loss 0.1583, train acc 94.77%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9612
epoch 18001, loss 0.1550, train acc 95.35%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9655
epoch 18501, loss 0.1655, train acc 95.35%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9655
epoch 19001, loss 0.1533, train acc 95.93%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9698
epoch 19501, loss 0.1437, train acc 96.51%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9741
running_time is 20.398822764
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.3
normal_0.5
./test_glass0/model_MLP_20000_0.3/record_1/MLP_20000_0.3_5
./test_glass0/result_MLP_20000_0.3_normal_0.5/record_1/
----------------------



the AUC is 0.6071428571428572

the Fscore is 0.43478260869565216

the precision is 0.5555555555555556

the recall is 0.35714285714285715

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_1
----------------------



epoch 1, loss 0.7617, train acc 34.50%, f1 0.4955, precision 0.3313, recall 0.9821, auc 0.5085
epoch 501, loss 0.4129, train acc 73.68%, f1 0.7097, precision 0.5556, recall 0.9821, auc 0.7998
epoch 1001, loss 0.2977, train acc 76.61%, f1 0.7297, precision 0.5870, recall 0.9643, auc 0.8169
epoch 1501, loss 0.3718, train acc 78.95%, f1 0.7534, precision 0.6111, recall 0.9821, auc 0.8389
epoch 2001, loss 0.2672, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 2501, loss 0.3338, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 3001, loss 0.2565, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 3501, loss 0.3128, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 4001, loss 0.2898, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 4501, loss 0.2318, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 5001, loss 0.1894, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 5501, loss 0.3707, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6001, loss 0.2692, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 6501, loss 0.2428, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 7001, loss 0.1875, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 7501, loss 0.2016, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 8001, loss 0.2649, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8501, loss 0.2802, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9001, loss 0.2329, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9501, loss 0.1821, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 10001, loss 0.2282, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 10501, loss 0.2324, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 11001, loss 0.2356, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 11501, loss 0.1738, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12001, loss 0.2419, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12501, loss 0.1678, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13001, loss 0.1911, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13501, loss 0.1249, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14001, loss 0.2186, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14501, loss 0.1919, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15001, loss 0.2088, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15501, loss 0.1843, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16001, loss 0.1953, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16501, loss 0.2036, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17001, loss 0.2249, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17501, loss 0.1889, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.2374, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18501, loss 0.1829, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19001, loss 0.2398, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2518, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.231161471
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.31
normal_0.5
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_1
./test_glass0/result_MLP_20000_0.31_normal_0.5/record_1/
----------------------



the AUC is 0.5775862068965517

the Fscore is 0.45161290322580644

the precision is 0.4117647058823529

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_2
----------------------



epoch 1, loss 0.5877, train acc 35.67%, f1 0.5045, precision 0.3373, recall 1.0000, auc 0.5217
epoch 501, loss 0.3948, train acc 72.51%, f1 0.7044, precision 0.5437, recall 1.0000, auc 0.7957
epoch 1001, loss 0.4024, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 1501, loss 0.3059, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 2001, loss 0.3039, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 2501, loss 0.2415, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3001, loss 0.2162, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 3501, loss 0.2518, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 4001, loss 0.2259, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 4501, loss 0.2677, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5001, loss 0.2111, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 5501, loss 0.1954, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6001, loss 0.2566, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.2503, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7001, loss 0.1574, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 7501, loss 0.1827, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 8001, loss 0.1354, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 8501, loss 0.2384, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 9001, loss 0.1592, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 9501, loss 0.1608, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 10001, loss 0.1986, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 10501, loss 0.2236, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 11001, loss 0.1797, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 11501, loss 0.2193, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 12001, loss 0.2044, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 12501, loss 0.1235, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.1821, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.1381, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.2227, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 14501, loss 0.1972, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 15001, loss 0.1281, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 15501, loss 0.1169, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16001, loss 0.1773, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16501, loss 0.1962, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17001, loss 0.1499, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17501, loss 0.1178, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 18001, loss 0.1036, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 18501, loss 0.1793, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19001, loss 0.1454, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19501, loss 0.2305, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
running_time is 20.236468107
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.31
normal_0.5
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_2
./test_glass0/result_MLP_20000_0.31_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_3
----------------------



epoch 1, loss 0.7035, train acc 41.52%, f1 0.5283, precision 0.3590, recall 1.0000, auc 0.5652
epoch 501, loss 0.3788, train acc 73.10%, f1 0.7013, precision 0.5510, recall 0.9643, auc 0.7908
epoch 1001, loss 0.3922, train acc 73.10%, f1 0.7013, precision 0.5510, recall 0.9643, auc 0.7908
epoch 1501, loss 0.3256, train acc 77.78%, f1 0.7397, precision 0.6000, recall 0.9643, auc 0.8256
epoch 2001, loss 0.2682, train acc 78.95%, f1 0.7534, precision 0.6111, recall 0.9821, auc 0.8389
epoch 2501, loss 0.3489, train acc 79.53%, f1 0.7586, precision 0.6180, recall 0.9821, auc 0.8432
epoch 3001, loss 0.2592, train acc 81.29%, f1 0.7746, precision 0.6395, recall 0.9821, auc 0.8563
epoch 3501, loss 0.2991, train acc 81.29%, f1 0.7746, precision 0.6395, recall 0.9821, auc 0.8563
epoch 4001, loss 0.3476, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 4501, loss 0.3184, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 5001, loss 0.2372, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2764, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 6001, loss 0.1952, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 6501, loss 0.2259, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 7001, loss 0.2374, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 7501, loss 0.2350, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 8001, loss 0.1908, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8501, loss 0.1924, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 9001, loss 0.1612, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9501, loss 0.2022, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10001, loss 0.2102, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10501, loss 0.2654, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 11001, loss 0.2216, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11501, loss 0.2075, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 12001, loss 0.1751, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.1427, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13001, loss 0.1430, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13501, loss 0.2607, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14001, loss 0.2195, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14501, loss 0.1992, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15001, loss 0.2332, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15501, loss 0.2383, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 16001, loss 0.1485, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 16501, loss 0.1580, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 17001, loss 0.1798, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 17501, loss 0.2039, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 18001, loss 0.1493, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1444, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19001, loss 0.0928, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 19501, loss 0.1400, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
running_time is 20.391905934
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.31
normal_0.5
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_3
./test_glass0/result_MLP_20000_0.31_normal_0.5/record_1/
----------------------



the AUC is 0.5899014778325122

the Fscore is 0.3333333333333333

the precision is 0.75

the recall is 0.21428571428571427

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_4
----------------------



epoch 1, loss 0.6167, train acc 42.11%, f1 0.5263, precision 0.3595, recall 0.9821, auc 0.5650
epoch 501, loss 0.3841, train acc 69.01%, f1 0.6748, precision 0.5140, recall 0.9821, auc 0.7650
epoch 1001, loss 0.3957, train acc 73.68%, f1 0.7059, precision 0.5567, recall 0.9643, auc 0.7952
epoch 1501, loss 0.3108, train acc 74.27%, f1 0.7143, precision 0.5612, recall 0.9821, auc 0.8041
epoch 2001, loss 0.2700, train acc 79.53%, f1 0.7586, precision 0.6180, recall 0.9821, auc 0.8432
epoch 2501, loss 0.2596, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 3001, loss 0.3388, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 3501, loss 0.3287, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 4001, loss 0.2979, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4501, loss 0.2978, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 5001, loss 0.1998, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 5501, loss 0.2375, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.2908, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 6501, loss 0.3023, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7001, loss 0.2546, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.2994, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 8001, loss 0.2776, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 8501, loss 0.2099, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9001, loss 0.1703, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 9501, loss 0.3110, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 10001, loss 0.1970, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 10501, loss 0.2522, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.1958, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.1917, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12001, loss 0.2100, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12501, loss 0.2050, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13001, loss 0.2513, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13501, loss 0.2988, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 14001, loss 0.2158, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 14501, loss 0.3016, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 15001, loss 0.2570, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 15501, loss 0.2094, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 16001, loss 0.2310, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 16501, loss 0.1926, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 17001, loss 0.2188, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 17501, loss 0.2149, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 18001, loss 0.2277, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 18501, loss 0.1782, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 19001, loss 0.2333, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 19501, loss 0.1934, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
running_time is 20.144706842
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.31
normal_0.5
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_4
./test_glass0/result_MLP_20000_0.31_normal_0.5/record_1/
----------------------



the AUC is 0.6637931034482759

the Fscore is 0.5384615384615384

the precision is 0.5833333333333334

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_5
----------------------



epoch 1, loss 0.7329, train acc 32.56%, f1 0.4912, precision 0.3256, recall 1.0000, auc 0.5000
epoch 501, loss 0.3394, train acc 68.02%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7629
epoch 1001, loss 0.3266, train acc 76.74%, f1 0.7297, precision 0.5870, recall 0.9643, auc 0.8183
epoch 1501, loss 0.2839, train acc 78.49%, f1 0.7448, precision 0.6067, recall 0.9643, auc 0.8313
epoch 2001, loss 0.4200, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 2501, loss 0.3373, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 3001, loss 0.2634, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 3501, loss 0.3156, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 4001, loss 0.3111, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 4501, loss 0.2708, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 5001, loss 0.3218, train acc 84.30%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8790
epoch 5501, loss 0.2640, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 6001, loss 0.2173, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 6501, loss 0.2883, train acc 86.05%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8919
epoch 7001, loss 0.2846, train acc 86.05%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8919
epoch 7501, loss 0.2793, train acc 86.05%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8919
epoch 8001, loss 0.3249, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 8501, loss 0.2476, train acc 86.63%, f1 0.8271, precision 0.7143, recall 0.9821, auc 0.8962
epoch 9001, loss 0.2894, train acc 86.63%, f1 0.8271, precision 0.7143, recall 0.9821, auc 0.8962
epoch 9501, loss 0.2703, train acc 86.63%, f1 0.8271, precision 0.7143, recall 0.9821, auc 0.8962
epoch 10001, loss 0.2354, train acc 87.21%, f1 0.8333, precision 0.7237, recall 0.9821, auc 0.9006
epoch 10501, loss 0.3101, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 11001, loss 0.2772, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 11501, loss 0.2962, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 12001, loss 0.2034, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 12501, loss 0.2940, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 13001, loss 0.2917, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 13501, loss 0.3254, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 14001, loss 0.2695, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 14501, loss 0.2835, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 15001, loss 0.3442, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 15501, loss 0.2148, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 16001, loss 0.2204, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 16501, loss 0.3392, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 17001, loss 0.3189, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 17501, loss 0.2198, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 18001, loss 0.3161, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 18501, loss 0.3085, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 19001, loss 0.3083, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 19501, loss 0.2060, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
running_time is 20.138727855
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.31
normal_0.5
./test_glass0/model_MLP_20000_0.31/record_1/MLP_20000_0.31_5
./test_glass0/result_MLP_20000_0.31_normal_0.5/record_1/
----------------------



the AUC is 0.6607142857142857

the Fscore is 0.5384615384615384

the precision is 0.5833333333333334

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_1
----------------------



epoch 1, loss 0.5625, train acc 33.92%, f1 0.4978, precision 0.3314, recall 1.0000, auc 0.5087
epoch 501, loss 0.3854, train acc 75.44%, f1 0.7200, precision 0.5745, recall 0.9643, auc 0.8082
epoch 1001, loss 0.3383, train acc 77.78%, f1 0.7397, precision 0.6000, recall 0.9643, auc 0.8256
epoch 1501, loss 0.3954, train acc 80.12%, f1 0.7639, precision 0.6250, recall 0.9821, auc 0.8476
epoch 2001, loss 0.3645, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 2501, loss 0.2651, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 3001, loss 0.3394, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3501, loss 0.3282, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.1946, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4501, loss 0.2923, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5001, loss 0.2903, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5501, loss 0.2758, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.3085, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6501, loss 0.2420, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.2883, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.2011, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 8001, loss 0.2622, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8501, loss 0.2019, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 9001, loss 0.2382, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 9501, loss 0.3003, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 10001, loss 0.2721, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 10501, loss 0.2545, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 11001, loss 0.2195, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 11501, loss 0.1872, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 12001, loss 0.2909, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 12501, loss 0.2305, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13001, loss 0.2117, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13501, loss 0.2660, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14001, loss 0.1843, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14501, loss 0.1531, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15001, loss 0.2978, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15501, loss 0.1709, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16001, loss 0.1822, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16501, loss 0.3166, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17001, loss 0.2222, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17501, loss 0.2515, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.2051, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18501, loss 0.1801, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19001, loss 0.1591, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.1937, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.156958308
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.32
normal_0.5
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_1
./test_glass0/result_MLP_20000_0.32_normal_0.5/record_1/
----------------------



the AUC is 0.5086206896551724

the Fscore is 0.4

the precision is 0.3333333333333333

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_2
----------------------



epoch 1, loss 0.7746, train acc 38.60%, f1 0.5161, precision 0.3478, recall 1.0000, auc 0.5435
epoch 501, loss 0.4030, train acc 73.10%, f1 0.7051, precision 0.5500, recall 0.9821, auc 0.7954
epoch 1001, loss 0.3988, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 1501, loss 0.2897, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 2001, loss 0.3355, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 2501, loss 0.2847, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 3001, loss 0.2857, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 3501, loss 0.2392, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 4001, loss 0.2940, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4501, loss 0.2518, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 5001, loss 0.2646, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5501, loss 0.2781, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6001, loss 0.1823, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.2199, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7001, loss 0.2120, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7501, loss 0.2365, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 8001, loss 0.2428, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 8501, loss 0.2641, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9001, loss 0.1796, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9501, loss 0.1862, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 10001, loss 0.2136, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 10501, loss 0.1766, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 11001, loss 0.2483, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 11501, loss 0.1561, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12001, loss 0.1333, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12501, loss 0.1472, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 13001, loss 0.1723, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 13501, loss 0.1936, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 14001, loss 0.1768, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 14501, loss 0.1926, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15001, loss 0.1453, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15501, loss 0.2506, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16001, loss 0.1991, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 16501, loss 0.2406, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 17001, loss 0.1691, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 17501, loss 0.2227, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 18001, loss 0.2138, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 18501, loss 0.1635, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19001, loss 0.2518, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.1953, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 20.137227792999997
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.32
normal_0.5
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_2
./test_glass0/result_MLP_20000_0.32_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_3
----------------------



epoch 1, loss 0.7444, train acc 49.12%, f1 0.5445, precision 0.3852, recall 0.9286, auc 0.6034
epoch 501, loss 0.4074, train acc 71.35%, f1 0.6957, precision 0.5333, recall 1.0000, auc 0.7870
epoch 1001, loss 0.3089, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 1501, loss 0.3121, train acc 77.78%, f1 0.7432, precision 0.5978, recall 0.9821, auc 0.8302
epoch 2001, loss 0.3489, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 2501, loss 0.2694, train acc 80.70%, f1 0.7692, precision 0.6322, recall 0.9821, auc 0.8519
epoch 3001, loss 0.3046, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 3501, loss 0.2572, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 4001, loss 0.3605, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 4501, loss 0.1640, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 5001, loss 0.2375, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 5501, loss 0.2806, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6001, loss 0.2682, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6501, loss 0.2346, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 7001, loss 0.2254, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 7501, loss 0.1548, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8001, loss 0.2092, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 8501, loss 0.1865, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9001, loss 0.1707, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9501, loss 0.2021, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10001, loss 0.1862, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.2135, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11001, loss 0.1895, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11501, loss 0.1627, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12001, loss 0.1352, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.1856, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.1917, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13501, loss 0.1057, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1477, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.1663, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.2022, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1426, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.1518, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1140, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 17001, loss 0.1897, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 17501, loss 0.1150, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 18001, loss 0.1757, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 18501, loss 0.2086, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 19001, loss 0.1967, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 19501, loss 0.1673, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
running_time is 20.287681443
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.32
normal_0.5
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_3
./test_glass0/result_MLP_20000_0.32_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_4
----------------------



epoch 1, loss 0.6230, train acc 55.56%, f1 0.5914, precision 0.4231, recall 0.9821, auc 0.6650
epoch 501, loss 0.3554, train acc 66.67%, f1 0.6587, precision 0.4955, recall 0.9821, auc 0.7476
epoch 1001, loss 0.3386, train acc 73.10%, f1 0.7013, precision 0.5510, recall 0.9643, auc 0.7908
epoch 1501, loss 0.3442, train acc 75.44%, f1 0.7200, precision 0.5745, recall 0.9643, auc 0.8082
epoch 2001, loss 0.3431, train acc 77.19%, f1 0.7417, precision 0.5895, recall 1.0000, auc 0.8304
epoch 2501, loss 0.2714, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 3001, loss 0.4034, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 3501, loss 0.2964, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 4001, loss 0.3329, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 4501, loss 0.2622, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 5001, loss 0.2046, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2088, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 6001, loss 0.2153, train acc 88.30%, f1 0.8462, precision 0.7432, recall 0.9821, auc 0.9085
epoch 6501, loss 0.1547, train acc 88.30%, f1 0.8462, precision 0.7432, recall 0.9821, auc 0.9085
epoch 7001, loss 0.2707, train acc 90.06%, f1 0.8661, precision 0.7746, recall 0.9821, auc 0.9215
epoch 7501, loss 0.1597, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 8001, loss 0.2093, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8501, loss 0.2571, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 9001, loss 0.1972, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9501, loss 0.2670, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 10001, loss 0.2817, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 10501, loss 0.1697, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.2077, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.2252, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12001, loss 0.2120, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 12501, loss 0.2750, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 13001, loss 0.2029, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 13501, loss 0.2287, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 14001, loss 0.1773, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 14501, loss 0.2183, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 15001, loss 0.1801, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 15501, loss 0.2225, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 16001, loss 0.1918, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 16501, loss 0.2636, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 17001, loss 0.1627, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 17501, loss 0.1886, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 18001, loss 0.1795, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 18501, loss 0.1294, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 19001, loss 0.2423, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.1747, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
running_time is 20.163938305
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.32
normal_0.5
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_4
./test_glass0/result_MLP_20000_0.32_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_5
----------------------



epoch 1, loss 0.6534, train acc 32.56%, f1 0.4912, precision 0.3256, recall 1.0000, auc 0.5000
epoch 501, loss 0.5047, train acc 68.60%, f1 0.6747, precision 0.5091, recall 1.0000, auc 0.7672
epoch 1001, loss 0.3889, train acc 77.33%, f1 0.7347, precision 0.5934, recall 0.9643, auc 0.8227
epoch 1501, loss 0.3568, train acc 78.49%, f1 0.7483, precision 0.6044, recall 0.9821, auc 0.8359
epoch 2001, loss 0.4230, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 2501, loss 0.3631, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 3001, loss 0.3530, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 3501, loss 0.3166, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 4001, loss 0.2406, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 4501, loss 0.2660, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 5001, loss 0.3058, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 5501, loss 0.3180, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 6001, loss 0.3191, train acc 86.05%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8919
epoch 6501, loss 0.3150, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7001, loss 0.2735, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7501, loss 0.2055, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 8001, loss 0.2930, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 8501, loss 0.2630, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 9001, loss 0.2375, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 9501, loss 0.2401, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 10001, loss 0.3221, train acc 90.12%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9267
epoch 10501, loss 0.1543, train acc 90.70%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9310
epoch 11001, loss 0.2135, train acc 90.70%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9310
epoch 11501, loss 0.2494, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 12001, loss 0.2536, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 12501, loss 0.1799, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 13001, loss 0.1695, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 13501, loss 0.2470, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 14001, loss 0.2206, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 14501, loss 0.2106, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 15001, loss 0.2299, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 15501, loss 0.1789, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 16001, loss 0.1403, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 16501, loss 0.2134, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 17001, loss 0.2342, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 17501, loss 0.2608, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 18001, loss 0.1782, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 18501, loss 0.2169, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 19001, loss 0.1495, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 19501, loss 0.1790, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
running_time is 20.240501881
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.32
normal_0.5
./test_glass0/model_MLP_20000_0.32/record_1/MLP_20000_0.32_5
./test_glass0/result_MLP_20000_0.32_normal_0.5/record_1/
----------------------



the AUC is 0.5178571428571429

the Fscore is 0.125

the precision is 0.5

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_1
----------------------



epoch 1, loss 0.6622, train acc 35.09%, f1 0.5022, precision 0.3353, recall 1.0000, auc 0.5174
epoch 501, loss 0.3672, train acc 70.76%, f1 0.6835, precision 0.5294, recall 0.9643, auc 0.7734
epoch 1001, loss 0.3242, train acc 77.19%, f1 0.7347, precision 0.5934, recall 0.9643, auc 0.8213
epoch 1501, loss 0.3443, train acc 78.36%, f1 0.7483, precision 0.6044, recall 0.9821, auc 0.8345
epoch 2001, loss 0.3393, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 2501, loss 0.2502, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 3001, loss 0.2333, train acc 84.21%, f1 0.8029, precision 0.6790, recall 0.9821, auc 0.8780
epoch 3501, loss 0.3903, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 4001, loss 0.3293, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 4501, loss 0.2743, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5001, loss 0.3540, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5501, loss 0.2842, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.2283, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6501, loss 0.3501, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 7001, loss 0.3156, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 7501, loss 0.2594, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8001, loss 0.3140, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8501, loss 0.2535, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 9001, loss 0.1806, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 9501, loss 0.2875, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 10001, loss 0.3042, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 10501, loss 0.3168, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11001, loss 0.2243, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11501, loss 0.2452, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12001, loss 0.3005, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12501, loss 0.3012, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13001, loss 0.2221, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13501, loss 0.2361, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14001, loss 0.2181, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14501, loss 0.2593, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15001, loss 0.1863, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15501, loss 0.2631, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16001, loss 0.3121, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16501, loss 0.3242, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17001, loss 0.3084, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17501, loss 0.3087, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 18001, loss 0.3143, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 18501, loss 0.2721, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 19001, loss 0.2682, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 19501, loss 0.2787, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
running_time is 20.14576749
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.33
normal_0.5
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_1
./test_glass0/result_MLP_20000_0.33_normal_0.5/record_1/
----------------------



the AUC is 0.6551724137931034

the Fscore is 0.5833333333333334

the precision is 0.4117647058823529

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_2
----------------------



epoch 1, loss 0.6938, train acc 32.75%, f1 0.4934, precision 0.3275, recall 1.0000, auc 0.5000
epoch 501, loss 0.4091, train acc 69.59%, f1 0.6829, precision 0.5185, recall 1.0000, auc 0.7739
epoch 1001, loss 0.3293, train acc 77.78%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8348
epoch 1501, loss 0.3800, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 2001, loss 0.3078, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 2501, loss 0.2538, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3001, loss 0.3045, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 3501, loss 0.3159, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 4001, loss 0.2465, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 4501, loss 0.2598, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5001, loss 0.2451, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 5501, loss 0.2441, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6001, loss 0.2735, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 6501, loss 0.1837, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7001, loss 0.2173, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7501, loss 0.1350, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 8001, loss 0.1627, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 8501, loss 0.2370, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9001, loss 0.1841, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 9501, loss 0.1846, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10001, loss 0.1486, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.2034, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11001, loss 0.2165, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11501, loss 0.1783, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 12001, loss 0.1724, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.2087, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13001, loss 0.2265, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13501, loss 0.1925, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14001, loss 0.1679, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14501, loss 0.1723, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15001, loss 0.1571, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1758, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.1438, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1887, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.2054, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17501, loss 0.1553, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18001, loss 0.2112, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1653, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19001, loss 0.1801, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19501, loss 0.1645, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
running_time is 20.295607375
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.33
normal_0.5
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_2
./test_glass0/result_MLP_20000_0.33_normal_0.5/record_1/
----------------------



the AUC is 0.46674876847290636

the Fscore is 0.10526315789473682

the precision is 0.2

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_3
----------------------



epoch 1, loss 0.6620, train acc 35.67%, f1 0.5045, precision 0.3373, recall 1.0000, auc 0.5217
epoch 501, loss 0.3937, train acc 70.18%, f1 0.6832, precision 0.5238, recall 0.9821, auc 0.7737
epoch 1001, loss 0.3142, train acc 73.68%, f1 0.7097, precision 0.5556, recall 0.9821, auc 0.7998
epoch 1501, loss 0.3898, train acc 77.19%, f1 0.7383, precision 0.5914, recall 0.9821, auc 0.8259
epoch 2001, loss 0.3236, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 2501, loss 0.4505, train acc 80.70%, f1 0.7692, precision 0.6322, recall 0.9821, auc 0.8519
epoch 3001, loss 0.3368, train acc 82.46%, f1 0.7857, precision 0.6548, recall 0.9821, auc 0.8650
epoch 3501, loss 0.2588, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 4001, loss 0.3495, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 4501, loss 0.2601, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 5001, loss 0.2975, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 5501, loss 0.2425, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6001, loss 0.1835, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6501, loss 0.2633, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7001, loss 0.1606, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 7501, loss 0.2440, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 8001, loss 0.2340, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 8501, loss 0.1712, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9001, loss 0.2342, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9501, loss 0.2449, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10001, loss 0.1685, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.1971, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11001, loss 0.2723, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11501, loss 0.2196, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12001, loss 0.1890, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.2106, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13001, loss 0.1971, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13501, loss 0.1929, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14001, loss 0.1481, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14501, loss 0.1520, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.1930, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1292, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.1910, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.2027, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.1945, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 17501, loss 0.1506, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18001, loss 0.1564, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1856, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 19001, loss 0.1892, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.1611, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
running_time is 20.093371465
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.33
normal_0.5
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_3
./test_glass0/result_MLP_20000_0.33_normal_0.5/record_1/
----------------------



the AUC is 0.644088669950739

the Fscore is 0.4761904761904762

the precision is 0.7142857142857143

the recall is 0.35714285714285715

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_4
----------------------



epoch 1, loss 0.7887, train acc 54.39%, f1 0.5895, precision 0.4179, recall 1.0000, auc 0.6609
epoch 501, loss 0.3934, train acc 68.42%, f1 0.6707, precision 0.5093, recall 0.9821, auc 0.7606
epoch 1001, loss 0.4142, train acc 72.51%, f1 0.6968, precision 0.5455, recall 0.9643, auc 0.7865
epoch 1501, loss 0.4058, train acc 74.85%, f1 0.7190, precision 0.5670, recall 0.9821, auc 0.8085
epoch 2001, loss 0.2840, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 2501, loss 0.3798, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 3001, loss 0.2774, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 3501, loss 0.2486, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 4001, loss 0.2604, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 4501, loss 0.3144, train acc 84.80%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8824
epoch 5001, loss 0.3015, train acc 85.38%, f1 0.8148, precision 0.6962, recall 0.9821, auc 0.8867
epoch 5501, loss 0.2792, train acc 85.96%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8911
epoch 6001, loss 0.3444, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6501, loss 0.2337, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.2408, train acc 87.13%, f1 0.8333, precision 0.7237, recall 0.9821, auc 0.8998
epoch 7501, loss 0.2680, train acc 88.89%, f1 0.8527, precision 0.7534, recall 0.9821, auc 0.9128
epoch 8001, loss 0.2505, train acc 89.47%, f1 0.8594, precision 0.7639, recall 0.9821, auc 0.9172
epoch 8501, loss 0.2499, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9001, loss 0.2311, train acc 90.64%, f1 0.8730, precision 0.7857, recall 0.9821, auc 0.9259
epoch 9501, loss 0.2044, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 10001, loss 0.2308, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 10501, loss 0.2539, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.1572, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.1706, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12001, loss 0.2090, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12501, loss 0.2286, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13001, loss 0.3216, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13501, loss 0.2451, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 14001, loss 0.3000, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 14501, loss 0.2641, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 15001, loss 0.2256, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 15501, loss 0.2144, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 16001, loss 0.2196, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 16501, loss 0.1896, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 17001, loss 0.2254, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 17501, loss 0.1472, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 18001, loss 0.2543, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 18501, loss 0.1296, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 19001, loss 0.2367, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2196, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.170057419000003
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.33
normal_0.5
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_4
./test_glass0/result_MLP_20000_0.33_normal_0.5/record_1/
----------------------



the AUC is 0.5369458128078817

the Fscore is 0.22222222222222224

the precision is 0.5

the recall is 0.14285714285714285

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_5
----------------------



epoch 1, loss 0.5985, train acc 47.67%, f1 0.5500, precision 0.3819, recall 0.9821, auc 0.6075
epoch 501, loss 0.3980, train acc 68.02%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7629
epoch 1001, loss 0.3062, train acc 75.00%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8147
epoch 1501, loss 0.4096, train acc 77.91%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8362
epoch 2001, loss 0.2621, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 2501, loss 0.4039, train acc 81.40%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8621
epoch 3001, loss 0.2882, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 3501, loss 0.3218, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4001, loss 0.2739, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 4501, loss 0.3585, train acc 83.14%, f1 0.7914, precision 0.6627, recall 0.9821, auc 0.8704
epoch 5001, loss 0.3030, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 5501, loss 0.3471, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 6001, loss 0.2697, train acc 84.88%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8833
epoch 6501, loss 0.3331, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7001, loss 0.3290, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7501, loss 0.2966, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 8001, loss 0.2614, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 8501, loss 0.2683, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 9001, loss 0.2644, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 9501, loss 0.2003, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 10001, loss 0.2355, train acc 90.12%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9267
epoch 10501, loss 0.2157, train acc 89.53%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9224
epoch 11001, loss 0.2388, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 11501, loss 0.2217, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 12001, loss 0.2591, train acc 90.70%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9310
epoch 12501, loss 0.2218, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 13001, loss 0.2365, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 13501, loss 0.2680, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 14001, loss 0.2291, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 14501, loss 0.2368, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 15001, loss 0.2183, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 15501, loss 0.2279, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 16001, loss 0.2283, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 16501, loss 0.2106, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 17001, loss 0.2796, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 17501, loss 0.2335, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 18001, loss 0.2250, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 18501, loss 0.1780, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 19001, loss 0.2196, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 19501, loss 0.2674, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
running_time is 20.168341735
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.33
normal_0.5
./test_glass0/model_MLP_20000_0.33/record_1/MLP_20000_0.33_5
./test_glass0/result_MLP_20000_0.33_normal_0.5/record_1/
----------------------



the AUC is 0.5178571428571429

the Fscore is 0.125

the precision is 0.5

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_1
----------------------



epoch 1, loss 0.8377, train acc 35.67%, f1 0.5045, precision 0.3373, recall 1.0000, auc 0.5217
epoch 501, loss 0.3421, train acc 70.76%, f1 0.6914, precision 0.5283, recall 1.0000, auc 0.7826
epoch 1001, loss 0.3184, train acc 76.02%, f1 0.7285, precision 0.5789, recall 0.9821, auc 0.8172
epoch 1501, loss 0.3990, train acc 78.36%, f1 0.7483, precision 0.6044, recall 0.9821, auc 0.8345
epoch 2001, loss 0.2548, train acc 78.95%, f1 0.7534, precision 0.6111, recall 0.9821, auc 0.8389
epoch 2501, loss 0.3622, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 3001, loss 0.2522, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 3501, loss 0.3207, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.3049, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4501, loss 0.3583, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5001, loss 0.3054, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2536, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.2624, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6501, loss 0.2460, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.2272, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.2614, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 8001, loss 0.2408, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 8501, loss 0.1825, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9001, loss 0.1398, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9501, loss 0.2465, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10001, loss 0.2371, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10501, loss 0.1641, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.2322, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.1885, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12001, loss 0.2599, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12501, loss 0.2812, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13001, loss 0.1925, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 13501, loss 0.2322, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 14001, loss 0.2619, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 14501, loss 0.2406, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 15001, loss 0.2759, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15501, loss 0.2501, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16001, loss 0.1892, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16501, loss 0.2077, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17001, loss 0.2434, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17501, loss 0.2575, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 18001, loss 0.1592, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18501, loss 0.1968, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19001, loss 0.2523, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2128, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.264527833
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.34
normal_0.5
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_1
./test_glass0/result_MLP_20000_0.34_normal_0.5/record_1/
----------------------



the AUC is 0.5800492610837438

the Fscore is 0.4864864864864865

the precision is 0.391304347826087

the recall is 0.6428571428571429

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_2
----------------------



epoch 1, loss 0.6718, train acc 53.22%, f1 0.5833, precision 0.4118, recall 1.0000, auc 0.6522
epoch 501, loss 0.3948, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 1001, loss 0.3542, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 1501, loss 0.3347, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 2001, loss 0.3189, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 2501, loss 0.2541, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3001, loss 0.2392, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 3501, loss 0.3071, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 4001, loss 0.2017, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4501, loss 0.3007, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5001, loss 0.2456, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 5501, loss 0.2129, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 6001, loss 0.2789, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.2074, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7001, loss 0.2379, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7501, loss 0.1869, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 8001, loss 0.1928, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 8501, loss 0.2687, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9001, loss 0.1664, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 9501, loss 0.1806, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 10001, loss 0.1897, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.1915, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11001, loss 0.1961, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11501, loss 0.1700, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12001, loss 0.2145, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.1372, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.2473, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.2180, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14001, loss 0.2180, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.2422, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15001, loss 0.2344, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 15501, loss 0.1275, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 16001, loss 0.1680, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 16501, loss 0.1847, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17001, loss 0.1490, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17501, loss 0.1770, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 18001, loss 0.1526, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 18501, loss 0.1687, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 19001, loss 0.1443, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 19501, loss 0.1660, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 20.121152279
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.34
normal_0.5
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_2
./test_glass0/result_MLP_20000_0.34_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_3
----------------------



epoch 1, loss 0.6056, train acc 35.67%, f1 0.5045, precision 0.3373, recall 1.0000, auc 0.5217
epoch 501, loss 0.4095, train acc 69.01%, f1 0.6788, precision 0.5138, recall 1.0000, auc 0.7696
epoch 1001, loss 0.3984, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 1501, loss 0.3392, train acc 76.02%, f1 0.7285, precision 0.5789, recall 0.9821, auc 0.8172
epoch 2001, loss 0.4105, train acc 78.36%, f1 0.7483, precision 0.6044, recall 0.9821, auc 0.8345
epoch 2501, loss 0.3503, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 3001, loss 0.3268, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 3501, loss 0.3552, train acc 81.87%, f1 0.7801, precision 0.6471, recall 0.9821, auc 0.8606
epoch 4001, loss 0.2176, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 4501, loss 0.3145, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 5001, loss 0.3586, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 5501, loss 0.2666, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.2705, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 6501, loss 0.3078, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 7001, loss 0.2037, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.1896, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8001, loss 0.1836, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 8501, loss 0.2313, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 9001, loss 0.2344, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 9501, loss 0.1502, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 10001, loss 0.2298, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 10501, loss 0.1996, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 11001, loss 0.2181, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 11501, loss 0.1785, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12001, loss 0.1333, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 12501, loss 0.1531, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.1385, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 13501, loss 0.2070, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1780, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 14501, loss 0.1629, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.1991, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 15501, loss 0.1775, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16001, loss 0.1417, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 16501, loss 0.1179, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17001, loss 0.1121, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17501, loss 0.1100, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 18001, loss 0.1549, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 18501, loss 0.2146, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19001, loss 0.1042, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19501, loss 0.1999, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 20.044733471999997
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.34
normal_0.5
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_3
./test_glass0/result_MLP_20000_0.34_normal_0.5/record_1/
----------------------



the AUC is 0.6847290640394088

the Fscore is 0.588235294117647

the precision is 0.5

the recall is 0.7142857142857143

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_4
----------------------



epoch 1, loss 0.7712, train acc 33.92%, f1 0.4978, precision 0.3314, recall 1.0000, auc 0.5087
epoch 501, loss 0.4364, train acc 66.08%, f1 0.6548, precision 0.4911, recall 0.9821, auc 0.7432
epoch 1001, loss 0.3920, train acc 69.59%, f1 0.6750, precision 0.5192, recall 0.9643, auc 0.7648
epoch 1501, loss 0.3091, train acc 73.10%, f1 0.7013, precision 0.5510, recall 0.9643, auc 0.7908
epoch 2001, loss 0.4027, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 2501, loss 0.3589, train acc 77.78%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8348
epoch 3001, loss 0.3272, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 3501, loss 0.2939, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 4001, loss 0.2958, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 4501, loss 0.2661, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 5001, loss 0.2551, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 5501, loss 0.2744, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 6001, loss 0.2602, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6501, loss 0.3549, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 7001, loss 0.2935, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 7501, loss 0.2755, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 8001, loss 0.3146, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 8501, loss 0.2785, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 9001, loss 0.2568, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 9501, loss 0.2438, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10001, loss 0.2223, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10501, loss 0.3253, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11001, loss 0.2468, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11501, loss 0.2479, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12001, loss 0.1705, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12501, loss 0.1989, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 13001, loss 0.2369, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 13501, loss 0.2142, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 14001, loss 0.2244, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 14501, loss 0.3030, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 15001, loss 0.2447, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 15501, loss 0.1645, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 16001, loss 0.2443, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 16501, loss 0.2897, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 17001, loss 0.2260, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 17501, loss 0.2469, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 18001, loss 0.2947, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 18501, loss 0.2042, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 19001, loss 0.2044, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 19501, loss 0.2116, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
running_time is 20.17801249
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.34
normal_0.5
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_4
./test_glass0/result_MLP_20000_0.34_normal_0.5/record_1/
----------------------



the AUC is 0.7573891625615764

the Fscore is 0.6666666666666666

the precision is 0.52

the recall is 0.9285714285714286

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_5
----------------------



epoch 1, loss 0.8047, train acc 51.74%, f1 0.5464, precision 0.3937, recall 0.8929, auc 0.6145
epoch 501, loss 0.3581, train acc 67.44%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7586
epoch 1001, loss 0.3123, train acc 76.16%, f1 0.7248, precision 0.5806, recall 0.9643, auc 0.8140
epoch 1501, loss 0.3261, train acc 78.49%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8405
epoch 2001, loss 0.3684, train acc 80.23%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8534
epoch 2501, loss 0.3534, train acc 80.81%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8578
epoch 3001, loss 0.3291, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 3501, loss 0.3180, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 4001, loss 0.3120, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4501, loss 0.2855, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 5001, loss 0.3260, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 5501, loss 0.3153, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 6001, loss 0.3376, train acc 86.05%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8966
epoch 6501, loss 0.2570, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7001, loss 0.1848, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7501, loss 0.2631, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 8001, loss 0.2518, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 8501, loss 0.2102, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 9001, loss 0.2573, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 9501, loss 0.2789, train acc 90.12%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9267
epoch 10001, loss 0.2339, train acc 90.70%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9310
epoch 10501, loss 0.2906, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 11001, loss 0.2352, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 11501, loss 0.1957, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 12001, loss 0.2027, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 12501, loss 0.1959, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 13001, loss 0.2305, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 13501, loss 0.2706, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 14001, loss 0.2246, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 14501, loss 0.2020, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 15001, loss 0.2464, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 15501, loss 0.1757, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 16001, loss 0.2372, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 16501, loss 0.1607, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 17001, loss 0.1680, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 17501, loss 0.2490, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 18001, loss 0.2082, train acc 93.60%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9526
epoch 18501, loss 0.2118, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 19001, loss 0.1750, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
epoch 19501, loss 0.1721, train acc 94.19%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9569
running_time is 20.326320979000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.34
normal_0.5
./test_glass0/model_MLP_20000_0.34/record_1/MLP_20000_0.34_5
./test_glass0/result_MLP_20000_0.34_normal_0.5/record_1/
----------------------



the AUC is 0.48214285714285715

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_1
----------------------



epoch 1, loss 0.6135, train acc 49.71%, f1 0.5326, precision 0.3828, recall 0.8750, auc 0.5940
epoch 501, loss 0.3612, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 1001, loss 0.3367, train acc 76.61%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8261
epoch 1501, loss 0.2825, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 2001, loss 0.2368, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 2501, loss 0.3318, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 3001, loss 0.3004, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3501, loss 0.2415, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.2929, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4501, loss 0.2673, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 5001, loss 0.2886, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5501, loss 0.3341, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.2230, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 6501, loss 0.2838, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7001, loss 0.1811, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 7501, loss 0.2717, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 8001, loss 0.2968, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 8501, loss 0.2683, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9001, loss 0.2498, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 9501, loss 0.2588, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10001, loss 0.2435, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10501, loss 0.2185, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 11001, loss 0.2265, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 11501, loss 0.2109, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12001, loss 0.2018, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12501, loss 0.2070, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 13001, loss 0.2308, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 13501, loss 0.2071, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 14001, loss 0.2232, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 14501, loss 0.2048, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15001, loss 0.2512, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15501, loss 0.2440, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16001, loss 0.2250, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16501, loss 0.2170, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 17001, loss 0.2274, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 17501, loss 0.2532, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 18001, loss 0.1625, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 18501, loss 0.1836, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 19001, loss 0.2405, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 19501, loss 0.1974, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
running_time is 20.395015190000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.35
normal_0.5
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_1
./test_glass0/result_MLP_20000_0.35_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_2
----------------------



epoch 1, loss 0.6829, train acc 32.75%, f1 0.4934, precision 0.3275, recall 1.0000, auc 0.5000
epoch 501, loss 0.3406, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.4710, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 1501, loss 0.3170, train acc 77.19%, f1 0.7417, precision 0.5895, recall 1.0000, auc 0.8304
epoch 2001, loss 0.3718, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 2501, loss 0.3947, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 3001, loss 0.3678, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 3501, loss 0.3308, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 4001, loss 0.3091, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 4501, loss 0.2457, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 5001, loss 0.3203, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2356, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.2511, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 6501, loss 0.3336, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 7001, loss 0.2992, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 7501, loss 0.3121, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 8001, loss 0.3014, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 8501, loss 0.2318, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 9001, loss 0.3175, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 9501, loss 0.2766, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 10001, loss 0.3577, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 10501, loss 0.3314, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 11001, loss 0.2782, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 11501, loss 0.3035, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 12001, loss 0.2485, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 12501, loss 0.3249, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13001, loss 0.2648, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13501, loss 0.2231, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14001, loss 0.2762, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14501, loss 0.2830, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 15001, loss 0.2279, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 15501, loss 0.2222, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 16001, loss 0.2527, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 16501, loss 0.2139, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 17001, loss 0.2212, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 17501, loss 0.2301, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 18001, loss 0.3099, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 18501, loss 0.2519, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 19001, loss 0.3050, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 19501, loss 0.2613, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
running_time is 20.108167748
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.35
normal_0.5
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_2
./test_glass0/result_MLP_20000_0.35_normal_0.5/record_1/
----------------------



the AUC is 0.5689655172413793

the Fscore is 0.5283018867924528

the precision is 0.358974358974359

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_3
----------------------



epoch 1, loss 0.6828, train acc 42.11%, f1 0.5308, precision 0.3613, recall 1.0000, auc 0.5696
epoch 501, loss 0.3910, train acc 69.59%, f1 0.6829, precision 0.5185, recall 1.0000, auc 0.7739
epoch 1001, loss 0.3702, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 1501, loss 0.4140, train acc 77.78%, f1 0.7432, precision 0.5978, recall 0.9821, auc 0.8302
epoch 2001, loss 0.3193, train acc 78.36%, f1 0.7483, precision 0.6044, recall 0.9821, auc 0.8345
epoch 2501, loss 0.3436, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 3001, loss 0.2709, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 3501, loss 0.3004, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4001, loss 0.3433, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4501, loss 0.3009, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 5001, loss 0.2151, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 5501, loss 0.2360, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6001, loss 0.1294, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.3276, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7001, loss 0.2510, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 7501, loss 0.2277, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 8001, loss 0.1941, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 8501, loss 0.1635, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 9001, loss 0.1935, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9501, loss 0.1808, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10001, loss 0.1722, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.1444, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11001, loss 0.1810, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11501, loss 0.1823, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12001, loss 0.1577, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12501, loss 0.1765, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 13001, loss 0.1851, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 13501, loss 0.2041, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14001, loss 0.1762, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14501, loss 0.2205, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.1689, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.2232, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.1736, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1731, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.1678, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17501, loss 0.2027, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18001, loss 0.2198, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1970, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19001, loss 0.2188, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.2345, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 20.321278965999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.35
normal_0.5
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_3
./test_glass0/result_MLP_20000_0.35_normal_0.5/record_1/
----------------------



the AUC is 0.6970443349753696

the Fscore is 0.5714285714285714

the precision is 0.8571428571428571

the recall is 0.42857142857142855

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_4
----------------------



epoch 1, loss 0.6828, train acc 35.09%, f1 0.5022, precision 0.3353, recall 1.0000, auc 0.5174
epoch 501, loss 0.3925, train acc 66.08%, f1 0.6588, precision 0.4912, recall 1.0000, auc 0.7478
epoch 1001, loss 0.4243, train acc 71.35%, f1 0.6957, precision 0.5333, recall 1.0000, auc 0.7870
epoch 1501, loss 0.3622, train acc 72.51%, f1 0.7044, precision 0.5437, recall 1.0000, auc 0.7957
epoch 2001, loss 0.3282, train acc 75.44%, f1 0.7237, precision 0.5729, recall 0.9821, auc 0.8128
epoch 2501, loss 0.3839, train acc 76.61%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8261
epoch 3001, loss 0.3056, train acc 77.78%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8348
epoch 3501, loss 0.3249, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 4001, loss 0.2957, train acc 80.12%, f1 0.7639, precision 0.6250, recall 0.9821, auc 0.8476
epoch 4501, loss 0.3195, train acc 80.70%, f1 0.7692, precision 0.6322, recall 0.9821, auc 0.8519
epoch 5001, loss 0.3634, train acc 84.80%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8824
epoch 5501, loss 0.3455, train acc 85.96%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8911
epoch 6001, loss 0.3503, train acc 82.46%, f1 0.7857, precision 0.6548, recall 0.9821, auc 0.8650
epoch 6501, loss 0.3094, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 7001, loss 0.3027, train acc 85.38%, f1 0.8148, precision 0.6962, recall 0.9821, auc 0.8867
epoch 7501, loss 0.2408, train acc 85.96%, f1 0.8209, precision 0.7051, recall 0.9821, auc 0.8911
epoch 8001, loss 0.2662, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 8501, loss 0.2400, train acc 87.72%, f1 0.8397, precision 0.7333, recall 0.9821, auc 0.9041
epoch 9001, loss 0.2867, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 9501, loss 0.2768, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 10001, loss 0.2374, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 10501, loss 0.1715, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 11001, loss 0.2741, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 11501, loss 0.2844, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12001, loss 0.2395, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12501, loss 0.2053, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13001, loss 0.2588, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13501, loss 0.2122, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14001, loss 0.2963, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14501, loss 0.2143, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15001, loss 0.1669, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15501, loss 0.2642, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 16001, loss 0.2723, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 16501, loss 0.2199, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17001, loss 0.2098, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17501, loss 0.2556, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.2063, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 18501, loss 0.2389, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 19001, loss 0.2466, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2119, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
running_time is 20.155931559
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.35
normal_0.5
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_4
./test_glass0/result_MLP_20000_0.35_normal_0.5/record_1/
----------------------



the AUC is 0.522167487684729

the Fscore is 0.32

the precision is 0.36363636363636365

the recall is 0.2857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_5
----------------------



epoch 1, loss 0.5442, train acc 49.42%, f1 0.5628, precision 0.3916, recall 1.0000, auc 0.6250
epoch 501, loss 0.3719, train acc 68.02%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7629
epoch 1001, loss 0.3151, train acc 75.58%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8190
epoch 1501, loss 0.3926, train acc 79.07%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8448
epoch 2001, loss 0.3344, train acc 79.65%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8491
epoch 2501, loss 0.3597, train acc 80.81%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8578
epoch 3001, loss 0.3235, train acc 80.81%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8578
epoch 3501, loss 0.2769, train acc 81.40%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8621
epoch 4001, loss 0.2614, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4501, loss 0.3732, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 5001, loss 0.3081, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 5501, loss 0.2900, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 6001, loss 0.2807, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 6501, loss 0.3340, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 7001, loss 0.3230, train acc 83.72%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8793
epoch 7501, loss 0.2246, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 8001, loss 0.3011, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 8501, loss 0.3433, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 9001, loss 0.2260, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 9501, loss 0.2838, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 10001, loss 0.2183, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 10501, loss 0.3194, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 11001, loss 0.2657, train acc 89.53%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9224
epoch 11501, loss 0.1650, train acc 90.12%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9267
epoch 12001, loss 0.2539, train acc 90.12%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9267
epoch 12501, loss 0.2603, train acc 90.70%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9310
epoch 13001, loss 0.3137, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 13501, loss 0.2313, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 14001, loss 0.2568, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 14501, loss 0.1829, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 15001, loss 0.2059, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 15501, loss 0.2094, train acc 91.28%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9353
epoch 16001, loss 0.2231, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 16501, loss 0.2997, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 17001, loss 0.1951, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 17501, loss 0.2323, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 18001, loss 0.2539, train acc 91.86%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9397
epoch 18501, loss 0.1941, train acc 93.02%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9483
epoch 19001, loss 0.2386, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
epoch 19501, loss 0.2461, train acc 92.44%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9440
running_time is 20.277307788999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.35
normal_0.5
./test_glass0/model_MLP_20000_0.35/record_1/MLP_20000_0.35_5
./test_glass0/result_MLP_20000_0.35_normal_0.5/record_1/
----------------------



the AUC is 0.48214285714285715

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_1
----------------------



epoch 1, loss 0.8407, train acc 45.03%, f1 0.5437, precision 0.3733, recall 1.0000, auc 0.5913
epoch 501, loss 0.3659, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 1001, loss 0.3381, train acc 76.61%, f1 0.7333, precision 0.5851, recall 0.9821, auc 0.8215
epoch 1501, loss 0.3892, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 2001, loss 0.2730, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 2501, loss 0.3451, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 3001, loss 0.3080, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 3501, loss 0.2743, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4001, loss 0.2342, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 4501, loss 0.2988, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5001, loss 0.2902, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5501, loss 0.2804, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.3016, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 6501, loss 0.3383, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 7001, loss 0.2698, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 7501, loss 0.2580, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8001, loss 0.2639, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8501, loss 0.2486, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 9001, loss 0.2455, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9501, loss 0.2990, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 10001, loss 0.2098, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 10501, loss 0.2322, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 11001, loss 0.2006, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 11501, loss 0.2091, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12001, loss 0.2367, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12501, loss 0.1975, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13001, loss 0.2743, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13501, loss 0.2080, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14001, loss 0.2428, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14501, loss 0.2093, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15001, loss 0.2150, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15501, loss 0.1554, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16001, loss 0.2357, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16501, loss 0.2314, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17001, loss 0.1944, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17501, loss 0.1725, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.1795, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18501, loss 0.1573, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19001, loss 0.1464, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2148, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.351827339
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.36
normal_0.5
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_1
./test_glass0/result_MLP_20000_0.36_normal_0.5/record_1/
----------------------



the AUC is 0.46551724137931033

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_2
----------------------



epoch 1, loss 0.6958, train acc 42.11%, f1 0.4649, precision 0.3333, recall 0.7679, auc 0.5100
epoch 501, loss 0.3669, train acc 69.59%, f1 0.6829, precision 0.5185, recall 1.0000, auc 0.7739
epoch 1001, loss 0.3535, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 1501, loss 0.1929, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 2001, loss 0.3604, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 2501, loss 0.2301, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 3001, loss 0.2085, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 3501, loss 0.2501, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4001, loss 0.2209, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 4501, loss 0.2602, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5001, loss 0.2786, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5501, loss 0.3167, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6001, loss 0.2764, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.3034, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7001, loss 0.2616, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7501, loss 0.2324, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 8001, loss 0.2223, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 8501, loss 0.1988, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9001, loss 0.2420, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9501, loss 0.2887, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 10001, loss 0.1959, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 10501, loss 0.2584, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 11001, loss 0.1955, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 11501, loss 0.2213, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12001, loss 0.1988, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12501, loss 0.2053, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13001, loss 0.2641, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13501, loss 0.2103, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14001, loss 0.2527, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14501, loss 0.2459, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15001, loss 0.2186, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15501, loss 0.1580, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16001, loss 0.2283, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16501, loss 0.1914, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17001, loss 0.2079, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17501, loss 0.1964, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 18001, loss 0.2764, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18501, loss 0.2658, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19001, loss 0.2549, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.2190, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
running_time is 20.341721576
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.36
normal_0.5
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_2
./test_glass0/result_MLP_20000_0.36_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_3
----------------------



epoch 1, loss 0.7319, train acc 35.67%, f1 0.5045, precision 0.3373, recall 1.0000, auc 0.5217
epoch 501, loss 0.4042, train acc 67.25%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7565
epoch 1001, loss 0.4175, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 1501, loss 0.3115, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 2001, loss 0.3752, train acc 76.61%, f1 0.7333, precision 0.5851, recall 0.9821, auc 0.8215
epoch 2501, loss 0.3086, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 3001, loss 0.2778, train acc 77.19%, f1 0.7417, precision 0.5895, recall 1.0000, auc 0.8304
epoch 3501, loss 0.3293, train acc 79.53%, f1 0.7586, precision 0.6180, recall 0.9821, auc 0.8432
epoch 4001, loss 0.3472, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 4501, loss 0.3208, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 5001, loss 0.3337, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 5501, loss 0.2537, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 6001, loss 0.2961, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 6501, loss 0.2734, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 7001, loss 0.2673, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 7501, loss 0.2518, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 8001, loss 0.2461, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 8501, loss 0.2392, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 9001, loss 0.2538, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9501, loss 0.3123, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10001, loss 0.2597, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 10501, loss 0.2243, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.2165, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 11501, loss 0.1944, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12001, loss 0.2113, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 12501, loss 0.2164, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 13001, loss 0.1826, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 13501, loss 0.1876, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 14001, loss 0.1733, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 14501, loss 0.1639, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15001, loss 0.2699, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15501, loss 0.2482, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 16001, loss 0.2263, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 16501, loss 0.1780, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 17001, loss 0.1507, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 17501, loss 0.1999, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 18001, loss 0.1994, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 18501, loss 0.1278, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 19001, loss 0.1784, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.2322, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 20.185269315
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.36
normal_0.5
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_3
./test_glass0/result_MLP_20000_0.36_normal_0.5/record_1/
----------------------



the AUC is 0.5517241379310345

the Fscore is 0.5185185185185185

the precision is 0.35

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_4
----------------------



epoch 1, loss 0.8411, train acc 33.33%, f1 0.4412, precision 0.3041, recall 0.8036, auc 0.4540
epoch 501, loss 0.3787, train acc 68.42%, f1 0.6747, precision 0.5091, recall 1.0000, auc 0.7652
epoch 1001, loss 0.4005, train acc 71.93%, f1 0.7000, precision 0.5385, recall 1.0000, auc 0.7913
epoch 1501, loss 0.3400, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 2001, loss 0.3521, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 2501, loss 0.3467, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 3001, loss 0.3999, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 3501, loss 0.3723, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 4001, loss 0.3482, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 4501, loss 0.2939, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 5001, loss 0.2982, train acc 84.80%, f1 0.8088, precision 0.6875, recall 0.9821, auc 0.8824
epoch 5501, loss 0.3828, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 6001, loss 0.2914, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 6501, loss 0.2063, train acc 86.55%, f1 0.8271, precision 0.7143, recall 0.9821, auc 0.8954
epoch 7001, loss 0.2906, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 7501, loss 0.3212, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8001, loss 0.2687, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8501, loss 0.2245, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 9001, loss 0.3445, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 9501, loss 0.3127, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 10001, loss 0.2118, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 10501, loss 0.2266, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 11001, loss 0.2245, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 11501, loss 0.3252, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12001, loss 0.2237, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 12501, loss 0.3241, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13001, loss 0.3068, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 13501, loss 0.1997, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14001, loss 0.3193, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14501, loss 0.2411, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15001, loss 0.2018, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15501, loss 0.2753, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 16001, loss 0.2159, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 16501, loss 0.2474, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 17001, loss 0.1995, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 17501, loss 0.2383, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 18001, loss 0.1873, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 18501, loss 0.1667, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 19001, loss 0.2189, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 19501, loss 0.2197, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
running_time is 20.384366642
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.36
normal_0.5
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_4
./test_glass0/result_MLP_20000_0.36_normal_0.5/record_1/
----------------------



the AUC is 0.752463054187192

the Fscore is 0.6666666666666666

the precision is 0.6923076923076923

the recall is 0.6428571428571429

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_5
----------------------



epoch 1, loss 0.7681, train acc 38.95%, f1 0.5161, precision 0.3478, recall 1.0000, auc 0.5474
epoch 501, loss 0.3544, train acc 67.44%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7586
epoch 1001, loss 0.3461, train acc 73.26%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8017
epoch 1501, loss 0.2960, train acc 76.74%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8276
epoch 2001, loss 0.2699, train acc 79.07%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8448
epoch 2501, loss 0.3661, train acc 80.23%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8534
epoch 3001, loss 0.3333, train acc 81.40%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8621
epoch 3501, loss 0.3388, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 4001, loss 0.2968, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 4501, loss 0.3607, train acc 81.98%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8664
epoch 5001, loss 0.3653, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 5501, loss 0.3145, train acc 83.72%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8793
epoch 6001, loss 0.2781, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 6501, loss 0.3452, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 7001, loss 0.2817, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 7501, loss 0.3001, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 8001, loss 0.3277, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 8501, loss 0.3166, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 9001, loss 0.3609, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 9501, loss 0.2808, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 10001, loss 0.3103, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 10501, loss 0.3224, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 11001, loss 0.1890, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 11501, loss 0.2504, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 12001, loss 0.3614, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 12501, loss 0.3338, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 13001, loss 0.2888, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 13501, loss 0.2832, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 14001, loss 0.3163, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 14501, loss 0.2629, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 15001, loss 0.3137, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 15501, loss 0.2118, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 16001, loss 0.3092, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 16501, loss 0.2892, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 17001, loss 0.2848, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 17501, loss 0.2387, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 18001, loss 0.3091, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 18501, loss 0.3194, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 19001, loss 0.2313, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 19501, loss 0.3276, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
running_time is 20.085722698
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.36
normal_0.5
./test_glass0/model_MLP_20000_0.36/record_1/MLP_20000_0.36_5
./test_glass0/result_MLP_20000_0.36_normal_0.5/record_1/
----------------------



the AUC is 0.6964285714285715

the Fscore is 0.6060606060606061

the precision is 0.5263157894736842

the recall is 0.7142857142857143

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_1
----------------------



epoch 1, loss 0.6717, train acc 46.78%, f1 0.5473, precision 0.3793, recall 0.9821, auc 0.5998
epoch 501, loss 0.4260, train acc 70.18%, f1 0.6871, precision 0.5234, recall 1.0000, auc 0.7783
epoch 1001, loss 0.3134, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 1501, loss 0.3286, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 2001, loss 0.3817, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 2501, loss 0.2608, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3001, loss 0.3345, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3501, loss 0.3296, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.2646, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4501, loss 0.2934, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 5001, loss 0.2320, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2633, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.2517, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 6501, loss 0.2145, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.2512, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.2467, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8001, loss 0.2037, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 8501, loss 0.2590, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9001, loss 0.2503, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9501, loss 0.2605, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10001, loss 0.1524, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10501, loss 0.2418, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11001, loss 0.2562, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11501, loss 0.2888, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12001, loss 0.2224, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12501, loss 0.2190, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13001, loss 0.2493, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13501, loss 0.2670, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14001, loss 0.3070, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14501, loss 0.2565, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15001, loss 0.2603, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15501, loss 0.2714, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16001, loss 0.2400, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16501, loss 0.2772, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17001, loss 0.2582, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17501, loss 0.3427, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 18001, loss 0.3520, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 18501, loss 0.3347, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 19001, loss 0.2474, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 19501, loss 0.2952, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
running_time is 20.284988562
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.37
normal_0.5
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_1
./test_glass0/result_MLP_20000_0.37_normal_0.5/record_1/
----------------------



the AUC is 0.5431034482758621

the Fscore is 0.4242424242424242

the precision is 0.3684210526315789

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_2
----------------------



epoch 1, loss 0.8998, train acc 33.33%, f1 0.4956, precision 0.3294, recall 1.0000, auc 0.5043
epoch 501, loss 0.4440, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.3599, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 1501, loss 0.3061, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 2001, loss 0.3829, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 2501, loss 0.3552, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 3001, loss 0.2669, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 3501, loss 0.3568, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 4001, loss 0.3209, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4501, loss 0.2507, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5001, loss 0.2675, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 5501, loss 0.2741, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6001, loss 0.2232, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6501, loss 0.2447, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 7001, loss 0.2940, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 7501, loss 0.1839, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 8001, loss 0.2039, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8501, loss 0.2020, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9001, loss 0.2143, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 9501, loss 0.2372, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10001, loss 0.2115, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 10501, loss 0.2785, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11001, loss 0.1759, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11501, loss 0.1614, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12001, loss 0.2144, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 12501, loss 0.2235, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13001, loss 0.1728, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13501, loss 0.1693, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 14001, loss 0.1730, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.2255, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.2506, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 15501, loss 0.1525, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.2089, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1971, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.1710, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17501, loss 0.2337, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18001, loss 0.2398, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1710, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19001, loss 0.2058, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.1958, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 20.125032926
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.37
normal_0.5
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_2
./test_glass0/result_MLP_20000_0.37_normal_0.5/record_1/
----------------------



the AUC is 0.6268472906403941

the Fscore is 0.45454545454545453

the precision is 0.625

the recall is 0.35714285714285715

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_3
----------------------



epoch 1, loss 0.8615, train acc 32.75%, f1 0.4934, precision 0.3275, recall 1.0000, auc 0.5000
epoch 501, loss 0.4192, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.4518, train acc 71.93%, f1 0.7000, precision 0.5385, recall 1.0000, auc 0.7913
epoch 1501, loss 0.4413, train acc 71.93%, f1 0.7000, precision 0.5385, recall 1.0000, auc 0.7913
epoch 2001, loss 0.3973, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 2501, loss 0.3710, train acc 73.68%, f1 0.7097, precision 0.5556, recall 0.9821, auc 0.7998
epoch 3001, loss 0.3880, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 3501, loss 0.4388, train acc 71.93%, f1 0.7000, precision 0.5385, recall 1.0000, auc 0.7913
epoch 4001, loss 0.4361, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 4501, loss 0.4172, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 5001, loss 0.3725, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 5501, loss 0.4537, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 6001, loss 0.3902, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 6501, loss 0.4009, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 7001, loss 0.3542, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 7501, loss 0.4065, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 8001, loss 0.3664, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 8501, loss 0.4675, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 9001, loss 0.3314, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 9501, loss 0.3804, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 10001, loss 0.2942, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 10501, loss 0.3913, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 11001, loss 0.4139, train acc 76.02%, f1 0.7285, precision 0.5789, recall 0.9821, auc 0.8172
epoch 11501, loss 0.3082, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 12001, loss 0.3299, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 12501, loss 0.3789, train acc 77.78%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8348
epoch 13001, loss 0.3680, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 13501, loss 0.3652, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 14001, loss 0.3048, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 14501, loss 0.3233, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 15001, loss 0.3228, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 15501, loss 0.2767, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 16001, loss 0.3607, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 16501, loss 0.3235, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 17001, loss 0.3385, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 17501, loss 0.2921, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 18001, loss 0.2690, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 18501, loss 0.3389, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 19001, loss 0.2126, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 19501, loss 0.2556, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
running_time is 20.227632217
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.37
normal_0.5
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_3
./test_glass0/result_MLP_20000_0.37_normal_0.5/record_1/
----------------------



the AUC is 0.5172413793103448

the Fscore is 0.5

the precision is 0.3333333333333333

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_4
----------------------



epoch 1, loss 0.6714, train acc 33.33%, f1 0.4956, precision 0.3294, recall 1.0000, auc 0.5043
epoch 501, loss 0.4812, train acc 66.08%, f1 0.6588, precision 0.4912, recall 1.0000, auc 0.7478
epoch 1001, loss 0.3606, train acc 70.18%, f1 0.6832, precision 0.5238, recall 0.9821, auc 0.7737
epoch 1501, loss 0.3944, train acc 73.68%, f1 0.7134, precision 0.5545, recall 1.0000, auc 0.8043
epoch 2001, loss 0.3074, train acc 75.44%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8174
epoch 2501, loss 0.3428, train acc 77.78%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8348
epoch 3001, loss 0.2991, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 3501, loss 0.2868, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 4001, loss 0.2471, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 4501, loss 0.2547, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 5001, loss 0.3384, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2490, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 6001, loss 0.3313, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 6501, loss 0.2585, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 7001, loss 0.2122, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 7501, loss 0.3228, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 8001, loss 0.1908, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 8501, loss 0.2642, train acc 90.06%, f1 0.8661, precision 0.7746, recall 0.9821, auc 0.9215
epoch 9001, loss 0.2638, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 9501, loss 0.2001, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 10001, loss 0.2643, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 10501, loss 0.2897, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11001, loss 0.2325, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.2725, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12001, loss 0.3128, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12501, loss 0.2268, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 13001, loss 0.1773, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 13501, loss 0.1695, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 14001, loss 0.1749, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 14501, loss 0.2488, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15001, loss 0.2130, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15501, loss 0.2099, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 16001, loss 0.1900, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16501, loss 0.2643, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17001, loss 0.2849, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 17501, loss 0.2723, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.2425, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 18501, loss 0.1921, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 19001, loss 0.2573, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
epoch 19501, loss 0.2433, train acc 95.32%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9652
running_time is 20.289534335
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.37
normal_0.5
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_4
./test_glass0/result_MLP_20000_0.37_normal_0.5/record_1/
----------------------



the AUC is 0.5726600985221675

the Fscore is 0.3157894736842105

the precision is 0.6

the recall is 0.21428571428571427

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_5
----------------------



epoch 1, loss 0.7094, train acc 35.47%, f1 0.5022, precision 0.3353, recall 1.0000, auc 0.5216
epoch 501, loss 0.4677, train acc 67.44%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7586
epoch 1001, loss 0.3960, train acc 75.00%, f1 0.7190, precision 0.5670, recall 0.9821, auc 0.8100
epoch 1501, loss 0.4657, train acc 77.33%, f1 0.7417, precision 0.5895, recall 1.0000, auc 0.8319
epoch 2001, loss 0.3495, train acc 80.23%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8534
epoch 2501, loss 0.3709, train acc 81.40%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8621
epoch 3001, loss 0.3155, train acc 80.81%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8578
epoch 3501, loss 0.3441, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4001, loss 0.2720, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4501, loss 0.2879, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 5001, loss 0.2642, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 5501, loss 0.3514, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 6001, loss 0.2506, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 6501, loss 0.3328, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 7001, loss 0.2728, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 7501, loss 0.3445, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 8001, loss 0.2115, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 8501, loss 0.3227, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 9001, loss 0.2976, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 9501, loss 0.3561, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 10001, loss 0.3034, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 10501, loss 0.3584, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 11001, loss 0.3451, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 11501, loss 0.2758, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 12001, loss 0.3177, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 12501, loss 0.2977, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 13001, loss 0.2625, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 13501, loss 0.3006, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 14001, loss 0.2052, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 14501, loss 0.3449, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 15001, loss 0.2813, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 15501, loss 0.2585, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 16001, loss 0.3489, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 16501, loss 0.3003, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 17001, loss 0.2429, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 17501, loss 0.2666, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 18001, loss 0.3004, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 18501, loss 0.3823, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 19001, loss 0.2493, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 19501, loss 0.2781, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
running_time is 20.324908785999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.37
normal_0.5
./test_glass0/model_MLP_20000_0.37/record_1/MLP_20000_0.37_5
./test_glass0/result_MLP_20000_0.37_normal_0.5/record_1/
----------------------



the AUC is 0.625

the Fscore is 0.5

the precision is 0.5

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_1
----------------------



epoch 1, loss 0.8451, train acc 33.33%, f1 0.4956, precision 0.3294, recall 1.0000, auc 0.5043
epoch 501, loss 0.4117, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.3802, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 1501, loss 0.3731, train acc 76.61%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8261
epoch 2001, loss 0.3727, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 2501, loss 0.3060, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 3001, loss 0.3704, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 3501, loss 0.2844, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 4001, loss 0.3321, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4501, loss 0.3408, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 5001, loss 0.2504, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 5501, loss 0.2955, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 6001, loss 0.2373, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 6501, loss 0.2890, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 7001, loss 0.2585, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 7501, loss 0.2880, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 8001, loss 0.3029, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 8501, loss 0.3188, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 9001, loss 0.2353, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 9501, loss 0.2710, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 10001, loss 0.3041, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 10501, loss 0.2420, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 11001, loss 0.2948, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 11501, loss 0.2509, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 12001, loss 0.2663, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 12501, loss 0.2926, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 13001, loss 0.2820, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 13501, loss 0.2720, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14001, loss 0.2946, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 14501, loss 0.2720, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 15001, loss 0.2723, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 15501, loss 0.2190, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 16001, loss 0.2250, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16501, loss 0.2603, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 17001, loss 0.2694, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 17501, loss 0.2836, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18001, loss 0.3009, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18501, loss 0.2661, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 19001, loss 0.2840, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 19501, loss 0.2435, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
running_time is 20.231156992000003
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.38
normal_0.5
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_1
./test_glass0/result_MLP_20000_0.38_normal_0.5/record_1/
----------------------



the AUC is 0.5997536945812807

the Fscore is 0.5238095238095237

the precision is 0.39285714285714285

the recall is 0.7857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_2
----------------------



epoch 1, loss 0.9248, train acc 36.84%, f1 0.5091, precision 0.3415, recall 1.0000, auc 0.5304
epoch 501, loss 0.3716, train acc 68.42%, f1 0.6747, precision 0.5091, recall 1.0000, auc 0.7652
epoch 1001, loss 0.3146, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 1501, loss 0.3267, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 2001, loss 0.2823, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 2501, loss 0.2763, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 3001, loss 0.3129, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 3501, loss 0.2676, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 4001, loss 0.2180, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 4501, loss 0.2336, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 5001, loss 0.2684, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 5501, loss 0.1916, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6001, loss 0.2947, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6501, loss 0.2125, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 7001, loss 0.2005, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 7501, loss 0.2364, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8001, loss 0.2131, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8501, loss 0.2515, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 9001, loss 0.2091, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 9501, loss 0.2858, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 10001, loss 0.1881, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10501, loss 0.2400, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 11001, loss 0.1889, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 11501, loss 0.1571, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12001, loss 0.2020, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12501, loss 0.1913, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13001, loss 0.2687, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.2203, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1962, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.1761, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.2623, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.1599, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.2252, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16501, loss 0.1545, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17001, loss 0.1726, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 17501, loss 0.2144, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18001, loss 0.1128, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 18501, loss 0.1654, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19001, loss 0.1663, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 19501, loss 0.1938, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 20.354829912
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.38
normal_0.5
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_2
./test_glass0/result_MLP_20000_0.38_normal_0.5/record_1/
----------------------



the AUC is 0.5209359605911329

the Fscore is 0.2727272727272727

the precision is 0.375

the recall is 0.21428571428571427

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_3
----------------------



epoch 1, loss 0.7655, train acc 40.94%, f1 0.5258, precision 0.3567, recall 1.0000, auc 0.5609
epoch 501, loss 0.3998, train acc 66.67%, f1 0.6627, precision 0.4956, recall 1.0000, auc 0.7522
epoch 1001, loss 0.4394, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 1501, loss 0.3937, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 2001, loss 0.3947, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 2501, loss 0.3076, train acc 74.27%, f1 0.7143, precision 0.5612, recall 0.9821, auc 0.8041
epoch 3001, loss 0.3389, train acc 74.27%, f1 0.7143, precision 0.5612, recall 0.9821, auc 0.8041
epoch 3501, loss 0.3416, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 4001, loss 0.4194, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 4501, loss 0.2943, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 5001, loss 0.4142, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 5501, loss 0.3949, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 6001, loss 0.4182, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 6501, loss 0.3005, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 7001, loss 0.2926, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 7501, loss 0.3580, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 8001, loss 0.3011, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 8501, loss 0.2895, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 9001, loss 0.3218, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 9501, loss 0.2568, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 10001, loss 0.3767, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 10501, loss 0.2652, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 11001, loss 0.3284, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 11501, loss 0.2698, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12001, loss 0.2630, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12501, loss 0.2837, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13001, loss 0.2723, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 13501, loss 0.3169, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14001, loss 0.3065, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 14501, loss 0.2576, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 15001, loss 0.2080, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 15501, loss 0.2292, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 16001, loss 0.2519, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16501, loss 0.2379, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 17001, loss 0.3603, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17501, loss 0.2175, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18001, loss 0.3155, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 18501, loss 0.2612, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 19001, loss 0.2261, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 19501, loss 0.2947, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
running_time is 20.177068282
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.38
normal_0.5
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_3
./test_glass0/result_MLP_20000_0.38_normal_0.5/record_1/
----------------------



the AUC is 0.7192118226600985

the Fscore is 0.6250000000000001

the precision is 0.5555555555555556

the recall is 0.7142857142857143

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_4
----------------------



epoch 1, loss 0.8452, train acc 35.09%, f1 0.5022, precision 0.3353, recall 1.0000, auc 0.5174
epoch 501, loss 0.4342, train acc 67.25%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7565
epoch 1001, loss 0.4682, train acc 69.59%, f1 0.6829, precision 0.5185, recall 1.0000, auc 0.7739
epoch 1501, loss 0.3827, train acc 72.51%, f1 0.7044, precision 0.5437, recall 1.0000, auc 0.7957
epoch 2001, loss 0.3315, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 2501, loss 0.3165, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 3001, loss 0.4236, train acc 78.95%, f1 0.7568, precision 0.6087, recall 1.0000, auc 0.8435
epoch 3501, loss 0.3564, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 4001, loss 0.3335, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 4501, loss 0.3617, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 5001, loss 0.3307, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 5501, loss 0.2871, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 6001, loss 0.3064, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 6501, loss 0.3657, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 7001, loss 0.3696, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 7501, loss 0.3256, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8001, loss 0.2647, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 8501, loss 0.2967, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 9001, loss 0.2714, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 9501, loss 0.2911, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 10001, loss 0.3066, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10501, loss 0.2948, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11001, loss 0.2221, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11501, loss 0.2651, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12001, loss 0.2506, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 12501, loss 0.2052, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 13001, loss 0.2674, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 13501, loss 0.2366, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 14001, loss 0.2453, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 14501, loss 0.2219, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15001, loss 0.2337, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 15501, loss 0.1669, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 16001, loss 0.2900, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 16501, loss 0.3412, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 17001, loss 0.2248, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 17501, loss 0.2183, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 18001, loss 0.1665, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 18501, loss 0.2241, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 19001, loss 0.2067, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 19501, loss 0.2376, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
running_time is 20.315636093
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.38
normal_0.5
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_4
./test_glass0/result_MLP_20000_0.38_normal_0.5/record_1/
----------------------



the AUC is 0.772167487684729

the Fscore is 0.6875000000000001

the precision is 0.6111111111111112

the recall is 0.7857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_5
----------------------



epoch 1, loss 0.6060, train acc 44.77%, f1 0.5366, precision 0.3691, recall 0.9821, auc 0.5859
epoch 501, loss 0.4378, train acc 67.44%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7586
epoch 1001, loss 0.4579, train acc 73.26%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8017
epoch 1501, loss 0.3553, train acc 77.91%, f1 0.7467, precision 0.5957, recall 1.0000, auc 0.8362
epoch 2001, loss 0.2746, train acc 79.65%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8491
epoch 2501, loss 0.3371, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 3001, loss 0.3083, train acc 83.72%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8793
epoch 3501, loss 0.3191, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 4001, loss 0.3743, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 4501, loss 0.3026, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 5001, loss 0.3386, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 5501, loss 0.2601, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 6001, loss 0.3429, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 6501, loss 0.2950, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 7001, loss 0.2004, train acc 86.05%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8966
epoch 7501, loss 0.3586, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 8001, loss 0.2498, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 8501, loss 0.2677, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 9001, loss 0.2854, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 9501, loss 0.3327, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 10001, loss 0.2681, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 10501, loss 0.2557, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 11001, loss 0.2591, train acc 86.63%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9009
epoch 11501, loss 0.2711, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 12001, loss 0.3238, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 12501, loss 0.2497, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 13001, loss 0.2426, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 13501, loss 0.2513, train acc 87.21%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9052
epoch 14001, loss 0.2351, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 14501, loss 0.1956, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 15001, loss 0.2601, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 15501, loss 0.2655, train acc 87.79%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9095
epoch 16001, loss 0.2813, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 16501, loss 0.2862, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 17001, loss 0.1973, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 17501, loss 0.2652, train acc 88.37%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9138
epoch 18001, loss 0.2261, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 18501, loss 0.2263, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 19001, loss 0.2189, train acc 88.95%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9181
epoch 19501, loss 0.2708, train acc 89.53%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9224
running_time is 20.076339934
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.38
normal_0.5
./test_glass0/model_MLP_20000_0.38/record_1/MLP_20000_0.38_5
./test_glass0/result_MLP_20000_0.38_normal_0.5/record_1/
----------------------



the AUC is 0.6428571428571428

the Fscore is 0.5333333333333333

the precision is 0.5

the recall is 0.5714285714285714

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_1
----------------------



epoch 1, loss 0.7437, train acc 54.39%, f1 0.5851, precision 0.4167, recall 0.9821, auc 0.6563
epoch 501, loss 0.4267, train acc 68.42%, f1 0.6747, precision 0.5091, recall 1.0000, auc 0.7652
epoch 1001, loss 0.4338, train acc 73.10%, f1 0.7089, precision 0.5490, recall 1.0000, auc 0.8000
epoch 1501, loss 0.4158, train acc 76.61%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8261
epoch 2001, loss 0.4089, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 2501, loss 0.3803, train acc 80.12%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8522
epoch 3001, loss 0.4076, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 3501, loss 0.3100, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 4001, loss 0.3470, train acc 82.46%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8696
epoch 4501, loss 0.3526, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 5001, loss 0.3232, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 5501, loss 0.3449, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 6001, loss 0.3833, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 6501, loss 0.2875, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 7001, loss 0.2855, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 7501, loss 0.2962, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 8001, loss 0.2907, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 8501, loss 0.2106, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 9001, loss 0.3209, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 9501, loss 0.2778, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 10001, loss 0.2501, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 10501, loss 0.2993, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 11001, loss 0.3148, train acc 85.38%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8913
epoch 11501, loss 0.3272, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 12001, loss 0.2228, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 12501, loss 0.3655, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13001, loss 0.3870, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 13501, loss 0.2219, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14001, loss 0.2448, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 14501, loss 0.2645, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 15001, loss 0.2548, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 15501, loss 0.2640, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16001, loss 0.2867, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 16501, loss 0.2512, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 17001, loss 0.2238, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 17501, loss 0.2547, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18001, loss 0.3096, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 18501, loss 0.3046, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 19001, loss 0.2933, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 19501, loss 0.2356, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
running_time is 20.253404218
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_20000_0.39
normal_0.5
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_1
./test_glass0/result_MLP_20000_0.39_normal_0.5/record_1/
----------------------



the AUC is 0.6022167487684729

the Fscore is 0.5416666666666667

the precision is 0.38235294117647056

the recall is 0.9285714285714286

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_2
----------------------



epoch 1, loss 0.7860, train acc 36.84%, f1 0.4857, precision 0.3312, recall 0.9107, auc 0.5075
epoch 501, loss 0.4096, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.3352, train acc 76.61%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8261
epoch 1501, loss 0.3029, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 2001, loss 0.2511, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 2501, loss 0.3060, train acc 84.21%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8826
epoch 3001, loss 0.2669, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 3501, loss 0.3025, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 4001, loss 0.2490, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 4501, loss 0.2632, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 5001, loss 0.3000, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 5501, loss 0.2663, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 6001, loss 0.1719, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 6501, loss 0.2012, train acc 91.23%, f1 0.8819, precision 0.7887, recall 1.0000, auc 0.9348
epoch 7001, loss 0.2278, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 7501, loss 0.2093, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8001, loss 0.1875, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 8501, loss 0.2660, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 9001, loss 0.2538, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 9501, loss 0.2524, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 10001, loss 0.2269, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 10501, loss 0.2095, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 11001, loss 0.2313, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 11501, loss 0.1709, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 12001, loss 0.1891, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 12501, loss 0.2382, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13001, loss 0.1612, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 13501, loss 0.2103, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 14001, loss 0.2661, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.1890, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15001, loss 0.2301, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 15501, loss 0.2468, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 16001, loss 0.1398, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 16501, loss 0.1772, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17001, loss 0.2097, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 17501, loss 0.2604, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 18001, loss 0.2165, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 18501, loss 0.1736, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19001, loss 0.2283, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 19501, loss 0.2292, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
running_time is 20.292739280000003
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_20000_0.39
normal_0.5
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_2
./test_glass0/result_MLP_20000_0.39_normal_0.5/record_1/
----------------------



the AUC is 0.5541871921182266

the Fscore is 0.23529411764705882

the precision is 0.6666666666666666

the recall is 0.14285714285714285

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_3
----------------------



epoch 1, loss 0.7441, train acc 32.75%, f1 0.4889, precision 0.3254, recall 0.9821, auc 0.4954
epoch 501, loss 0.4970, train acc 67.84%, f1 0.6707, precision 0.5045, recall 1.0000, auc 0.7609
epoch 1001, loss 0.3651, train acc 72.51%, f1 0.7044, precision 0.5437, recall 1.0000, auc 0.7957
epoch 1501, loss 0.3797, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 2001, loss 0.3361, train acc 78.36%, f1 0.7517, precision 0.6022, recall 1.0000, auc 0.8391
epoch 2501, loss 0.3226, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 3001, loss 0.2862, train acc 81.87%, f1 0.7832, precision 0.6437, recall 1.0000, auc 0.8652
epoch 3501, loss 0.2465, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4001, loss 0.2840, train acc 84.80%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8870
epoch 4501, loss 0.3000, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5001, loss 0.2887, train acc 85.96%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.8957
epoch 5501, loss 0.2619, train acc 86.55%, f1 0.8296, precision 0.7089, recall 1.0000, auc 0.9000
epoch 6001, loss 0.2975, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6501, loss 0.2005, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7001, loss 0.2168, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 7501, loss 0.2307, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 8001, loss 0.2257, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 8501, loss 0.2172, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9001, loss 0.2882, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 9501, loss 0.2460, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10001, loss 0.2479, train acc 90.64%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9304
epoch 10501, loss 0.2135, train acc 90.06%, f1 0.8682, precision 0.7671, recall 1.0000, auc 0.9261
epoch 11001, loss 0.2284, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 11501, loss 0.1429, train acc 91.81%, f1 0.8889, precision 0.8000, recall 1.0000, auc 0.9391
epoch 12001, loss 0.2445, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 12501, loss 0.2440, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 13001, loss 0.2373, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 13501, loss 0.1794, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 14001, loss 0.2194, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 14501, loss 0.2269, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 15001, loss 0.2329, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 15501, loss 0.1926, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 16001, loss 0.2653, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 16501, loss 0.2736, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 17001, loss 0.2229, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 17501, loss 0.2044, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 18001, loss 0.2797, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 18501, loss 0.1684, train acc 92.40%, f1 0.8960, precision 0.8116, recall 1.0000, auc 0.9435
epoch 19001, loss 0.2118, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 19501, loss 0.3207, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
running_time is 20.182710323
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_20000_0.39
normal_0.5
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_3
./test_glass0/result_MLP_20000_0.39_normal_0.5/record_1/
----------------------



the AUC is 0.5923645320197044

the Fscore is 0.41666666666666663

the precision is 0.5

the recall is 0.35714285714285715

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_4
----------------------



epoch 1, loss 1.0362, train acc 46.78%, f1 0.5381, precision 0.3759, recall 0.9464, auc 0.5906
epoch 501, loss 0.4666, train acc 67.25%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7565
epoch 1001, loss 0.4157, train acc 70.18%, f1 0.6871, precision 0.5234, recall 1.0000, auc 0.7783
epoch 1501, loss 0.4330, train acc 74.27%, f1 0.7179, precision 0.5600, recall 1.0000, auc 0.8087
epoch 2001, loss 0.3782, train acc 74.85%, f1 0.7226, precision 0.5657, recall 1.0000, auc 0.8130
epoch 2501, loss 0.3035, train acc 76.02%, f1 0.7320, precision 0.5773, recall 1.0000, auc 0.8217
epoch 3001, loss 0.2694, train acc 79.53%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8478
epoch 3501, loss 0.3752, train acc 80.70%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8565
epoch 4001, loss 0.3403, train acc 81.29%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.8609
epoch 4501, loss 0.3468, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 5001, loss 0.3454, train acc 83.04%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8739
epoch 5501, loss 0.2912, train acc 87.13%, f1 0.8358, precision 0.7179, recall 1.0000, auc 0.9043
epoch 6001, loss 0.3397, train acc 83.63%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8783
epoch 6501, loss 0.2832, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7001, loss 0.2991, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 7501, loss 0.2563, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 8001, loss 0.2458, train acc 87.72%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9087
epoch 8501, loss 0.3018, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9001, loss 0.3246, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 9501, loss 0.2171, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 10001, loss 0.2471, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 10501, loss 0.2258, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 11001, loss 0.2490, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 11501, loss 0.3294, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12001, loss 0.2487, train acc 88.30%, f1 0.8485, precision 0.7368, recall 1.0000, auc 0.9130
epoch 12501, loss 0.3363, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 13001, loss 0.2292, train acc 88.89%, f1 0.8550, precision 0.7467, recall 1.0000, auc 0.9174
epoch 13501, loss 0.2576, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 14001, loss 0.1954, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 14501, loss 0.2102, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 15001, loss 0.2560, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 15501, loss 0.2476, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 16001, loss 0.3024, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 16501, loss 0.2004, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 17001, loss 0.2723, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 17501, loss 0.3234, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18001, loss 0.2981, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 18501, loss 0.3254, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 19001, loss 0.2796, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
epoch 19501, loss 0.2971, train acc 89.47%, f1 0.8615, precision 0.7568, recall 1.0000, auc 0.9217
running_time is 20.118296812
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_20000_0.39
normal_0.5
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_4
./test_glass0/result_MLP_20000_0.39_normal_0.5/record_1/
----------------------



the AUC is 0.5726600985221675

the Fscore is 0.3157894736842105

the precision is 0.6

the recall is 0.21428571428571427

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_5
----------------------



epoch 1, loss 0.7856, train acc 33.72%, f1 0.4956, precision 0.3294, recall 1.0000, auc 0.5086
epoch 501, loss 0.3979, train acc 67.44%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.7586
epoch 1001, loss 0.3659, train acc 75.58%, f1 0.7273, precision 0.5714, recall 1.0000, auc 0.8190
epoch 1501, loss 0.3903, train acc 76.74%, f1 0.7368, precision 0.5833, recall 1.0000, auc 0.8276
epoch 2001, loss 0.4067, train acc 79.65%, f1 0.7619, precision 0.6154, recall 1.0000, auc 0.8491
epoch 2501, loss 0.2955, train acc 80.23%, f1 0.7671, precision 0.6222, recall 1.0000, auc 0.8534
epoch 3001, loss 0.2570, train acc 80.81%, f1 0.7724, precision 0.6292, recall 1.0000, auc 0.8578
epoch 3501, loss 0.4107, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4001, loss 0.2514, train acc 82.56%, f1 0.7887, precision 0.6512, recall 1.0000, auc 0.8707
epoch 4501, loss 0.3116, train acc 83.14%, f1 0.7943, precision 0.6588, recall 1.0000, auc 0.8750
epoch 5001, loss 0.3537, train acc 83.72%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8793
epoch 5501, loss 0.3151, train acc 83.72%, f1 0.8000, precision 0.6667, recall 1.0000, auc 0.8793
epoch 6001, loss 0.2320, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 6501, loss 0.3379, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 7001, loss 0.3681, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 7501, loss 0.3289, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 8001, loss 0.3757, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 8501, loss 0.2941, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 9001, loss 0.3548, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 9501, loss 0.2921, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 10001, loss 0.3130, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 10501, loss 0.2578, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 11001, loss 0.2637, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 11501, loss 0.3080, train acc 84.30%, f1 0.8058, precision 0.6747, recall 1.0000, auc 0.8836
epoch 12001, loss 0.3713, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 12501, loss 0.2704, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 13001, loss 0.3569, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 13501, loss 0.3425, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 14001, loss 0.2829, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 14501, loss 0.3443, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 15001, loss 0.2760, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 15501, loss 0.3345, train acc 84.88%, f1 0.8116, precision 0.6829, recall 1.0000, auc 0.8879
epoch 16001, loss 0.2964, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 16501, loss 0.2414, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 17001, loss 0.3387, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 17501, loss 0.3250, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 18001, loss 0.3148, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 18501, loss 0.2540, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 19001, loss 0.2863, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
epoch 19501, loss 0.2722, train acc 85.47%, f1 0.8175, precision 0.6914, recall 1.0000, auc 0.8922
running_time is 20.202010995
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_20000_0.39
normal_0.5
./test_glass0/model_MLP_20000_0.39/record_1/MLP_20000_0.39_5
./test_glass0/result_MLP_20000_0.39_normal_0.5/record_1/
----------------------



the AUC is 0.625

the Fscore is 0.5

the precision is 0.5

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_1
----------------------



epoch 1, loss 0.6930, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.4127, train acc 84.21%, f1 0.7477, precision 0.7843, recall 0.7143, auc 0.8093
epoch 1001, loss 0.3299, train acc 86.55%, f1 0.7965, precision 0.7895, recall 0.8036, auc 0.8496
epoch 1501, loss 0.2770, train acc 89.47%, f1 0.8448, precision 0.8167, recall 0.8750, auc 0.8897
epoch 2001, loss 0.2717, train acc 89.47%, f1 0.8448, precision 0.8167, recall 0.8750, auc 0.8897
epoch 2501, loss 0.2636, train acc 88.30%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8856
epoch 3001, loss 0.3519, train acc 89.47%, f1 0.8500, precision 0.7969, recall 0.9107, auc 0.8988
epoch 3501, loss 0.2759, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 4001, loss 0.2121, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 4501, loss 0.2322, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 5001, loss 0.1334, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 5501, loss 0.1025, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 6001, loss 0.1925, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 6501, loss 0.1134, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 7001, loss 0.1387, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 7501, loss 0.1257, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.0842, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 8501, loss 0.0427, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 9001, loss 0.0542, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 9501, loss 0.0721, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 10001, loss 0.0605, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 10501, loss 0.0271, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 11001, loss 0.0215, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 11501, loss 0.0245, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 12001, loss 0.0313, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 12501, loss 0.0356, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 13001, loss 0.0228, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 13501, loss 0.0241, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 14001, loss 0.0461, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 14501, loss 0.0085, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
running_time is 15.871912538000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.0
normal_0.5
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_1
./test_glass0/result_MLP_15000_0.0_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_2
----------------------



epoch 1, loss 0.6930, train acc 66.67%, f1 0.0339, precision 0.3333, recall 0.0179, auc 0.5002
epoch 501, loss 0.3794, train acc 81.29%, f1 0.7091, precision 0.7222, recall 0.6964, auc 0.7830
epoch 1001, loss 0.2744, train acc 83.04%, f1 0.7387, precision 0.7455, recall 0.7321, auc 0.8052
epoch 1501, loss 0.2228, train acc 83.04%, f1 0.7339, precision 0.7547, recall 0.7143, auc 0.8006
epoch 2001, loss 0.1953, train acc 85.38%, f1 0.7748, precision 0.7818, recall 0.7679, auc 0.8318
epoch 2501, loss 0.1791, train acc 88.89%, f1 0.8319, precision 0.8246, recall 0.8393, auc 0.8762
epoch 3001, loss 0.2450, train acc 90.64%, f1 0.8621, precision 0.8333, recall 0.8929, auc 0.9030
epoch 3501, loss 0.1938, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 4001, loss 0.2029, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 4501, loss 0.1555, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5001, loss 0.1049, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.1067, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6001, loss 0.1637, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6501, loss 0.1094, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 7001, loss 0.1511, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7501, loss 0.1036, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8001, loss 0.1212, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8501, loss 0.0879, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9001, loss 0.1247, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.0897, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10001, loss 0.0513, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10501, loss 0.0762, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11001, loss 0.1251, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.0787, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12001, loss 0.0690, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 12501, loss 0.0870, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13001, loss 0.0895, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.0446, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14001, loss 0.0383, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.1009, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
running_time is 15.979809392000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.0
normal_0.5
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_2
./test_glass0/result_MLP_15000_0.0_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_3
----------------------



epoch 1, loss 0.6934, train acc 53.22%, f1 0.1304, precision 0.1667, recall 0.1071, auc 0.4231
epoch 501, loss 0.4162, train acc 79.53%, f1 0.6903, precision 0.6842, recall 0.6964, auc 0.7700
epoch 1001, loss 0.2625, train acc 84.21%, f1 0.7611, precision 0.7544, recall 0.7679, auc 0.8231
epoch 1501, loss 0.4447, train acc 85.38%, f1 0.7748, precision 0.7818, recall 0.7679, auc 0.8318
epoch 2001, loss 0.3184, train acc 85.96%, f1 0.7818, precision 0.7963, recall 0.7679, auc 0.8361
epoch 2501, loss 0.3566, train acc 88.30%, f1 0.8148, precision 0.8462, recall 0.7857, auc 0.8581
epoch 3001, loss 0.2579, train acc 90.06%, f1 0.8468, precision 0.8545, recall 0.8393, auc 0.8849
epoch 3501, loss 0.2214, train acc 90.06%, f1 0.8440, precision 0.8679, recall 0.8214, auc 0.8803
epoch 4001, loss 0.2052, train acc 92.40%, f1 0.8829, precision 0.8909, recall 0.8750, auc 0.9114
epoch 4501, loss 0.1424, train acc 92.40%, f1 0.8829, precision 0.8909, recall 0.8750, auc 0.9114
epoch 5001, loss 0.2031, train acc 93.57%, f1 0.9027, precision 0.8947, recall 0.9107, auc 0.9293
epoch 5501, loss 0.0657, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 6001, loss 0.1265, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 6501, loss 0.1352, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 7001, loss 0.0983, train acc 95.91%, f1 0.9369, precision 0.9455, recall 0.9286, auc 0.9512
epoch 7501, loss 0.1462, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8001, loss 0.1235, train acc 97.08%, f1 0.9550, precision 0.9636, recall 0.9464, auc 0.9645
epoch 8501, loss 0.0888, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9001, loss 0.0546, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9501, loss 0.0646, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 10001, loss 0.0982, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 10501, loss 0.0667, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11001, loss 0.0615, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11501, loss 0.0741, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 12001, loss 0.1006, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 12501, loss 0.0698, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 13001, loss 0.0554, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 13501, loss 0.0545, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14001, loss 0.0379, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14501, loss 0.0710, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
running_time is 15.844862612
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.0
normal_0.5
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_3
./test_glass0/result_MLP_15000_0.0_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_4
----------------------



epoch 1, loss 0.6933, train acc 64.91%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4826
epoch 501, loss 0.4124, train acc 80.12%, f1 0.6852, precision 0.7115, recall 0.6607, auc 0.7651
epoch 1001, loss 0.4262, train acc 83.63%, f1 0.7544, precision 0.7414, recall 0.7679, auc 0.8187
epoch 1501, loss 0.3164, train acc 87.13%, f1 0.8070, precision 0.7931, recall 0.8214, auc 0.8585
epoch 2001, loss 0.3212, train acc 87.72%, f1 0.8174, precision 0.7966, recall 0.8393, auc 0.8675
epoch 2501, loss 0.2418, train acc 90.06%, f1 0.8440, precision 0.8679, recall 0.8214, auc 0.8803
epoch 3001, loss 0.2927, train acc 90.06%, f1 0.8440, precision 0.8679, recall 0.8214, auc 0.8803
epoch 3501, loss 0.2486, train acc 91.81%, f1 0.8750, precision 0.8750, recall 0.8750, auc 0.9071
epoch 4001, loss 0.1617, train acc 91.81%, f1 0.8750, precision 0.8750, recall 0.8750, auc 0.9071
epoch 4501, loss 0.2346, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 5001, loss 0.1677, train acc 91.23%, f1 0.8673, precision 0.8596, recall 0.8750, auc 0.9027
epoch 5501, loss 0.1729, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 6001, loss 0.2331, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 6501, loss 0.2075, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 7001, loss 0.2328, train acc 94.15%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9336
epoch 7501, loss 0.1224, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 8001, loss 0.1661, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 8501, loss 0.1325, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 9001, loss 0.1539, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 9501, loss 0.1748, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 10001, loss 0.1692, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 10501, loss 0.1369, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 11001, loss 0.0394, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 11501, loss 0.0788, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12001, loss 0.0645, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12501, loss 0.1015, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13001, loss 0.1007, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13501, loss 0.0815, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14001, loss 0.0495, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14501, loss 0.0951, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
running_time is 15.768376903
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.0
normal_0.5
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_4
./test_glass0/result_MLP_15000_0.0_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_5
----------------------



epoch 1, loss 0.6931, train acc 67.44%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3254, train acc 80.81%, f1 0.7027, precision 0.7091, recall 0.6964, auc 0.7792
epoch 1001, loss 0.4505, train acc 83.72%, f1 0.7455, precision 0.7593, recall 0.7321, auc 0.8100
epoch 1501, loss 0.3335, train acc 84.88%, f1 0.7679, precision 0.7679, recall 0.7679, auc 0.8279
epoch 2001, loss 0.2619, train acc 86.05%, f1 0.7895, precision 0.7759, recall 0.8036, auc 0.8458
epoch 2501, loss 0.2694, train acc 87.79%, f1 0.8174, precision 0.7966, recall 0.8393, auc 0.8679
epoch 3001, loss 0.1550, train acc 89.53%, f1 0.8421, precision 0.8276, recall 0.8571, auc 0.8855
epoch 3501, loss 0.1895, train acc 92.44%, f1 0.8807, precision 0.9057, recall 0.8571, auc 0.9070
epoch 4001, loss 0.2251, train acc 93.02%, f1 0.8929, precision 0.8929, recall 0.8929, auc 0.9206
epoch 4501, loss 0.1832, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 5001, loss 0.1383, train acc 94.77%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9427
epoch 5501, loss 0.1332, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 6001, loss 0.1848, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 6501, loss 0.1789, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 7001, loss 0.1587, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 7501, loss 0.1808, train acc 95.35%, f1 0.9286, precision 0.9286, recall 0.9286, auc 0.9470
epoch 8001, loss 0.1576, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 8501, loss 0.1313, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 9001, loss 0.1741, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 9501, loss 0.1302, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 10001, loss 0.0883, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 10501, loss 0.0790, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 11001, loss 0.0931, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 11501, loss 0.0913, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 12001, loss 0.0480, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 12501, loss 0.1072, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 13001, loss 0.0778, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 13501, loss 0.0404, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 14001, loss 0.0811, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
epoch 14501, loss 0.0627, train acc 96.51%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9603
running_time is 16.031931656
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.0
normal_0.5
./test_glass0/model_MLP_15000_0.0/record_1/MLP_15000_0.0_5
./test_glass0/result_MLP_15000_0.0_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_1
----------------------



epoch 1, loss 0.6865, train acc 53.80%, f1 0.0920, precision 0.1290, recall 0.0714, auc 0.4183
epoch 501, loss 0.3420, train acc 84.80%, f1 0.7679, precision 0.7679, recall 0.7679, auc 0.8274
epoch 1001, loss 0.3026, train acc 86.55%, f1 0.8034, precision 0.7705, recall 0.8393, auc 0.8588
epoch 1501, loss 0.2676, train acc 88.30%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8810
epoch 2001, loss 0.2446, train acc 90.06%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8986
epoch 2501, loss 0.2109, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 3001, loss 0.1871, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 3501, loss 0.1843, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 4001, loss 0.1259, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 4501, loss 0.2128, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 5001, loss 0.1666, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 5501, loss 0.1368, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6001, loss 0.1933, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6501, loss 0.1620, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 7001, loss 0.1053, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 7501, loss 0.0554, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 8001, loss 0.0887, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 8501, loss 0.0675, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9001, loss 0.0666, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 9501, loss 0.0548, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 10001, loss 0.0430, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 10501, loss 0.0346, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 11001, loss 0.0379, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 11501, loss 0.0544, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0386, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0278, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0337, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0378, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0442, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0242, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 15.883001294
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.01
normal_0.5
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_1
./test_glass0/result_MLP_15000_0.01_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_2
----------------------



epoch 1, loss 0.6870, train acc 67.25%, f1 0.0667, precision 0.5000, recall 0.0357, auc 0.5092
epoch 501, loss 0.3525, train acc 81.29%, f1 0.7037, precision 0.7308, recall 0.6786, auc 0.7784
epoch 1001, loss 0.3921, train acc 83.04%, f1 0.7387, precision 0.7455, recall 0.7321, auc 0.8052
epoch 1501, loss 0.3304, train acc 84.21%, f1 0.7568, precision 0.7636, recall 0.7500, auc 0.8185
epoch 2001, loss 0.2691, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 2501, loss 0.2432, train acc 90.64%, f1 0.8621, precision 0.8333, recall 0.8929, auc 0.9030
epoch 3001, loss 0.2289, train acc 91.23%, f1 0.8718, precision 0.8361, recall 0.9107, auc 0.9119
epoch 3501, loss 0.2563, train acc 91.23%, f1 0.8718, precision 0.8361, recall 0.9107, auc 0.9119
epoch 4001, loss 0.1625, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 4501, loss 0.1821, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5001, loss 0.1809, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.0884, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6001, loss 0.1119, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6501, loss 0.0883, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7001, loss 0.1181, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 7501, loss 0.1105, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 8001, loss 0.1153, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 8501, loss 0.1070, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 9001, loss 0.0846, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.0855, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 10001, loss 0.0924, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 10501, loss 0.0675, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 11001, loss 0.0678, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 11501, loss 0.0968, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12001, loss 0.1116, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12501, loss 0.0395, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13001, loss 0.0853, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13501, loss 0.0293, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
epoch 14001, loss 0.0618, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
epoch 14501, loss 0.0847, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
running_time is 15.880618968999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.01
normal_0.5
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_2
./test_glass0/result_MLP_15000_0.01_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_3
----------------------



epoch 1, loss 0.6822, train acc 60.23%, f1 0.0286, precision 0.0714, recall 0.0179, auc 0.4524
epoch 501, loss 0.3864, train acc 82.46%, f1 0.7368, precision 0.7241, recall 0.7500, auc 0.8054
epoch 1001, loss 0.3310, train acc 84.21%, f1 0.7611, precision 0.7544, recall 0.7679, auc 0.8231
epoch 1501, loss 0.3855, train acc 86.55%, f1 0.7965, precision 0.7895, recall 0.8036, auc 0.8496
epoch 2001, loss 0.3034, train acc 87.13%, f1 0.8070, precision 0.7931, recall 0.8214, auc 0.8585
epoch 2501, loss 0.3083, train acc 87.13%, f1 0.8036, precision 0.8036, recall 0.8036, auc 0.8540
epoch 3001, loss 0.2649, train acc 88.89%, f1 0.8257, precision 0.8491, recall 0.8036, auc 0.8670
epoch 3501, loss 0.1996, train acc 89.47%, f1 0.8393, precision 0.8393, recall 0.8393, auc 0.8805
epoch 4001, loss 0.1803, train acc 92.40%, f1 0.8807, precision 0.9057, recall 0.8571, auc 0.9068
epoch 4501, loss 0.1553, train acc 93.57%, f1 0.9009, precision 0.9091, recall 0.8929, auc 0.9247
epoch 5001, loss 0.1690, train acc 94.15%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9336
epoch 5501, loss 0.1341, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 6001, loss 0.1204, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 6501, loss 0.1003, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 7001, loss 0.1219, train acc 95.32%, f1 0.9286, precision 0.9286, recall 0.9286, auc 0.9469
epoch 7501, loss 0.1337, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 8001, loss 0.1356, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8501, loss 0.0712, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9001, loss 0.0507, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.1761, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 10001, loss 0.1046, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 10501, loss 0.1536, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11001, loss 0.0656, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11501, loss 0.0686, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 12001, loss 0.0547, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 12501, loss 0.0822, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13001, loss 0.0524, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13501, loss 0.0768, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 14001, loss 0.0457, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 14501, loss 0.0499, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
running_time is 16.029138185
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.01
normal_0.5
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_3
./test_glass0/result_MLP_15000_0.01_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_4
----------------------



epoch 1, loss 0.6870, train acc 63.16%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4696
epoch 501, loss 0.4672, train acc 79.53%, f1 0.6957, precision 0.6780, recall 0.7143, auc 0.7745
epoch 1001, loss 0.2784, train acc 81.87%, f1 0.7304, precision 0.7119, recall 0.7500, auc 0.8011
epoch 1501, loss 0.1858, train acc 84.21%, f1 0.7692, precision 0.7377, recall 0.8036, auc 0.8322
epoch 2001, loss 0.3167, train acc 85.96%, f1 0.7895, precision 0.7759, recall 0.8036, auc 0.8453
epoch 2501, loss 0.2354, train acc 87.72%, f1 0.8142, precision 0.8070, recall 0.8214, auc 0.8629
epoch 3001, loss 0.1957, train acc 88.89%, f1 0.8348, precision 0.8136, recall 0.8571, auc 0.8807
epoch 3501, loss 0.2368, train acc 90.64%, f1 0.8571, precision 0.8571, recall 0.8571, auc 0.8938
epoch 4001, loss 0.1876, train acc 91.81%, f1 0.8750, precision 0.8750, recall 0.8750, auc 0.9071
epoch 4501, loss 0.2354, train acc 92.40%, f1 0.8829, precision 0.8909, recall 0.8750, auc 0.9114
epoch 5001, loss 0.2053, train acc 92.40%, f1 0.8850, precision 0.8772, recall 0.8929, auc 0.9160
epoch 5501, loss 0.0966, train acc 91.23%, f1 0.8673, precision 0.8596, recall 0.8750, auc 0.9027
epoch 6001, loss 0.2169, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 6501, loss 0.1278, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 7001, loss 0.1157, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 7501, loss 0.1616, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 8001, loss 0.1886, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 8501, loss 0.1779, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 9001, loss 0.1647, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 9501, loss 0.1269, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 10001, loss 0.0977, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 10501, loss 0.1600, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 11001, loss 0.1322, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 11501, loss 0.0985, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 12001, loss 0.1364, train acc 96.49%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9602
epoch 12501, loss 0.1897, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 13001, loss 0.0870, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 13501, loss 0.0974, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 14001, loss 0.1272, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 14501, loss 0.1110, train acc 97.66%, f1 0.9636, precision 0.9815, recall 0.9464, auc 0.9689
running_time is 15.714611957999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.01
normal_0.5
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_4
./test_glass0/result_MLP_15000_0.01_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_5
----------------------



epoch 1, loss 0.6870, train acc 65.70%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4871
epoch 501, loss 0.4692, train acc 81.40%, f1 0.7241, precision 0.7000, recall 0.7500, auc 0.7974
epoch 1001, loss 0.4137, train acc 82.56%, f1 0.7368, precision 0.7241, recall 0.7500, auc 0.8060
epoch 1501, loss 0.2416, train acc 86.63%, f1 0.8000, precision 0.7797, recall 0.8214, auc 0.8547
epoch 2001, loss 0.2674, train acc 90.70%, f1 0.8621, precision 0.8333, recall 0.8929, auc 0.9033
epoch 2501, loss 0.2338, train acc 93.02%, f1 0.8929, precision 0.8929, recall 0.8929, auc 0.9206
epoch 3001, loss 0.2529, train acc 93.60%, f1 0.9009, precision 0.9091, recall 0.8929, auc 0.9249
epoch 3501, loss 0.2343, train acc 92.44%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9209
epoch 4001, loss 0.2271, train acc 93.60%, f1 0.9009, precision 0.9091, recall 0.8929, auc 0.9249
epoch 4501, loss 0.2040, train acc 94.19%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9338
epoch 5001, loss 0.1224, train acc 93.60%, f1 0.9009, precision 0.9091, recall 0.8929, auc 0.9249
epoch 5501, loss 0.1247, train acc 94.77%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9427
epoch 6001, loss 0.1567, train acc 94.77%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9427
epoch 6501, loss 0.1001, train acc 94.77%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9427
epoch 7001, loss 0.1035, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 7501, loss 0.1197, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 8001, loss 0.1021, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 8501, loss 0.1229, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 9001, loss 0.0878, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 9501, loss 0.0820, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 10001, loss 0.0966, train acc 97.09%, f1 0.9550, precision 0.9636, recall 0.9464, auc 0.9646
epoch 10501, loss 0.0831, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 11001, loss 0.1312, train acc 97.67%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9735
epoch 11501, loss 0.0400, train acc 98.26%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 12001, loss 0.0670, train acc 98.26%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 12501, loss 0.0742, train acc 97.67%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9735
epoch 13001, loss 0.0765, train acc 98.26%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 13501, loss 0.0233, train acc 98.84%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9868
epoch 14001, loss 0.0346, train acc 98.26%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14501, loss 0.0894, train acc 98.26%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
running_time is 15.809770454
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.01
normal_0.5
./test_glass0/model_MLP_15000_0.01/record_1/MLP_15000_0.01_5
./test_glass0/result_MLP_15000_0.01_normal_0.5/record_1/
----------------------



the AUC is 0.5357142857142857

the Fscore is 0.13333333333333333

the precision is 1.0

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_1
----------------------



epoch 1, loss 0.6746, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3215, train acc 85.38%, f1 0.7788, precision 0.7719, recall 0.7857, auc 0.8363
epoch 1001, loss 0.4289, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 1501, loss 0.2944, train acc 89.47%, f1 0.8448, precision 0.8167, recall 0.8750, auc 0.8897
epoch 2001, loss 0.2718, train acc 88.89%, f1 0.8376, precision 0.8033, recall 0.8750, auc 0.8853
epoch 2501, loss 0.1937, train acc 88.30%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8856
epoch 3001, loss 0.1836, train acc 90.06%, f1 0.8571, precision 0.8095, recall 0.9107, auc 0.9032
epoch 3501, loss 0.2516, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 4001, loss 0.1838, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 4501, loss 0.1507, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 5001, loss 0.1751, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 5501, loss 0.1368, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 6001, loss 0.1207, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 6501, loss 0.1375, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 7001, loss 0.0797, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7501, loss 0.0701, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.0735, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8501, loss 0.0939, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 9001, loss 0.0762, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 9501, loss 0.1042, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 10001, loss 0.0621, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 10501, loss 0.0540, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11001, loss 0.0950, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11501, loss 0.0490, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12001, loss 0.0850, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12501, loss 0.0729, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13001, loss 0.0473, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.0344, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14001, loss 0.0416, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.0530, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
running_time is 15.854797302
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.02
normal_0.5
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_1
./test_glass0/result_MLP_15000_0.02_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_2
----------------------



epoch 1, loss 0.6812, train acc 61.99%, f1 0.0299, precision 0.0909, recall 0.0179, auc 0.4655
epoch 501, loss 0.2971, train acc 82.46%, f1 0.7414, precision 0.7167, recall 0.7679, auc 0.8100
epoch 1001, loss 0.2974, train acc 84.21%, f1 0.7611, precision 0.7544, recall 0.7679, auc 0.8231
epoch 1501, loss 0.3368, train acc 86.55%, f1 0.8034, precision 0.7705, recall 0.8393, auc 0.8588
epoch 2001, loss 0.2601, train acc 90.06%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8986
epoch 2501, loss 0.2681, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 3001, loss 0.2147, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 3501, loss 0.1556, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 4001, loss 0.1542, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 4501, loss 0.1534, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5001, loss 0.1464, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 5501, loss 0.1794, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6001, loss 0.1301, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 6501, loss 0.0948, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7001, loss 0.1478, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7501, loss 0.1611, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8001, loss 0.1230, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8501, loss 0.1095, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9001, loss 0.0623, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.0858, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10001, loss 0.1412, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10501, loss 0.0736, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11001, loss 0.0818, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11501, loss 0.0588, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12001, loss 0.1334, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12501, loss 0.1359, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 13001, loss 0.1169, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 13501, loss 0.0608, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 14001, loss 0.0879, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 14501, loss 0.0520, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
running_time is 15.898126354
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.02
normal_0.5
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_2
./test_glass0/result_MLP_15000_0.02_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_3
----------------------



epoch 1, loss 0.6777, train acc 66.67%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4957
epoch 501, loss 0.4723, train acc 81.29%, f1 0.7333, precision 0.6875, recall 0.7857, auc 0.8059
epoch 1001, loss 0.3515, train acc 84.21%, f1 0.7652, precision 0.7458, recall 0.7857, auc 0.8276
epoch 1501, loss 0.2451, train acc 85.96%, f1 0.7966, precision 0.7581, recall 0.8393, auc 0.8544
epoch 2001, loss 0.2395, train acc 86.55%, f1 0.7965, precision 0.7895, recall 0.8036, auc 0.8496
epoch 2501, loss 0.2990, train acc 88.30%, f1 0.8276, precision 0.8000, recall 0.8571, auc 0.8764
epoch 3001, loss 0.1696, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 3501, loss 0.2315, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 4001, loss 0.1198, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 4501, loss 0.1772, train acc 94.15%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9336
epoch 5001, loss 0.1352, train acc 95.32%, f1 0.9286, precision 0.9286, recall 0.9286, auc 0.9469
epoch 5501, loss 0.0791, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 6001, loss 0.0955, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 6501, loss 0.1108, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7001, loss 0.0725, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7501, loss 0.0328, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8001, loss 0.0407, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 8501, loss 0.0730, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9001, loss 0.0813, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.0335, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 10001, loss 0.1252, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 10501, loss 0.1264, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11001, loss 0.0629, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11501, loss 0.1020, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 12001, loss 0.0729, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 12501, loss 0.0654, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13001, loss 0.0897, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13501, loss 0.0885, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 14001, loss 0.0239, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 14501, loss 0.0695, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
running_time is 15.751923694999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.02
normal_0.5
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_3
./test_glass0/result_MLP_15000_0.02_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_4
----------------------



epoch 1, loss 0.6860, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3632, train acc 81.87%, f1 0.7257, precision 0.7193, recall 0.7321, auc 0.7965
epoch 1001, loss 0.3178, train acc 82.46%, f1 0.7368, precision 0.7241, recall 0.7500, auc 0.8054
epoch 1501, loss 0.2966, train acc 85.38%, f1 0.7826, precision 0.7627, recall 0.8036, auc 0.8409
epoch 2001, loss 0.3154, train acc 88.30%, f1 0.8214, precision 0.8214, recall 0.8214, auc 0.8672
epoch 2501, loss 0.3003, train acc 90.06%, f1 0.8468, precision 0.8545, recall 0.8393, auc 0.8849
epoch 3001, loss 0.3097, train acc 91.81%, f1 0.8727, precision 0.8889, recall 0.8571, auc 0.9025
epoch 3501, loss 0.2488, train acc 91.23%, f1 0.8624, precision 0.8868, recall 0.8393, auc 0.8936
epoch 4001, loss 0.1060, train acc 90.64%, f1 0.8596, precision 0.8448, recall 0.8750, auc 0.8984
epoch 4501, loss 0.2308, train acc 90.06%, f1 0.8496, precision 0.8421, recall 0.8571, auc 0.8894
epoch 5001, loss 0.1903, train acc 91.23%, f1 0.8696, precision 0.8475, recall 0.8929, auc 0.9073
epoch 5501, loss 0.1726, train acc 92.40%, f1 0.8850, precision 0.8772, recall 0.8929, auc 0.9160
epoch 6001, loss 0.1202, train acc 92.98%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9249
epoch 6501, loss 0.1915, train acc 92.98%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9249
epoch 7001, loss 0.1466, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 7501, loss 0.1368, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8001, loss 0.1631, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 8501, loss 0.0834, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 9001, loss 0.1537, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 9501, loss 0.1193, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 10001, loss 0.0917, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 10501, loss 0.0449, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11001, loss 0.0560, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11501, loss 0.1144, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 12001, loss 0.0527, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 12501, loss 0.0850, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13001, loss 0.0850, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13501, loss 0.0415, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14001, loss 0.0750, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14501, loss 0.0596, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
running_time is 15.97321653
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.02
normal_0.5
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_4
./test_glass0/result_MLP_15000_0.02_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_5
----------------------



epoch 1, loss 0.6828, train acc 67.44%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3498, train acc 80.23%, f1 0.7069, precision 0.6833, recall 0.7321, auc 0.7842
epoch 1001, loss 0.2866, train acc 83.72%, f1 0.7586, precision 0.7333, recall 0.7857, auc 0.8239
epoch 1501, loss 0.3782, train acc 86.05%, f1 0.7895, precision 0.7759, recall 0.8036, auc 0.8458
epoch 2001, loss 0.2631, train acc 86.63%, f1 0.8000, precision 0.7797, recall 0.8214, auc 0.8547
epoch 2501, loss 0.2404, train acc 87.21%, f1 0.8070, precision 0.7931, recall 0.8214, auc 0.8590
epoch 3001, loss 0.2447, train acc 88.95%, f1 0.8319, precision 0.8246, recall 0.8393, auc 0.8765
epoch 3501, loss 0.2073, train acc 91.28%, f1 0.8673, precision 0.8596, recall 0.8750, auc 0.9030
epoch 4001, loss 0.1905, train acc 94.19%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9338
epoch 4501, loss 0.1685, train acc 94.19%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9338
epoch 5001, loss 0.1668, train acc 93.60%, f1 0.9027, precision 0.8947, recall 0.9107, auc 0.9295
epoch 5501, loss 0.1615, train acc 94.19%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9384
epoch 6001, loss 0.1939, train acc 94.19%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9384
epoch 6501, loss 0.1630, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 7001, loss 0.1580, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 7501, loss 0.0707, train acc 94.19%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9430
epoch 8001, loss 0.2012, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 8501, loss 0.1095, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 9001, loss 0.1108, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 9501, loss 0.1335, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 10001, loss 0.1315, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 10501, loss 0.2058, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 11001, loss 0.1625, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 11501, loss 0.0761, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 12001, loss 0.1304, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 12501, loss 0.1470, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 13001, loss 0.0708, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 13501, loss 0.1574, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 14001, loss 0.1882, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 14501, loss 0.1082, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
running_time is 15.884817021
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.02
normal_0.5
./test_glass0/model_MLP_15000_0.02/record_1/MLP_15000_0.02_5
./test_glass0/result_MLP_15000_0.02_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_1
----------------------



epoch 1, loss 0.6901, train acc 69.59%, f1 0.2121, precision 0.7000, recall 0.1250, auc 0.5495
epoch 501, loss 0.3192, train acc 85.96%, f1 0.7895, precision 0.7759, recall 0.8036, auc 0.8453
epoch 1001, loss 0.2877, train acc 87.13%, f1 0.8136, precision 0.7742, recall 0.8571, auc 0.8677
epoch 1501, loss 0.3174, train acc 88.89%, f1 0.8376, precision 0.8033, recall 0.8750, auc 0.8853
epoch 2001, loss 0.1826, train acc 90.06%, f1 0.8571, precision 0.8095, recall 0.9107, auc 0.9032
epoch 2501, loss 0.1706, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 3001, loss 0.2259, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 3501, loss 0.1590, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 4001, loss 0.1273, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 4501, loss 0.2661, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 5001, loss 0.2010, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 5501, loss 0.1581, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 6001, loss 0.0929, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 6501, loss 0.0921, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 7001, loss 0.0971, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 7501, loss 0.0872, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 8001, loss 0.0740, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 8501, loss 0.1031, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9001, loss 0.1014, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9501, loss 0.0906, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10001, loss 0.0749, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10501, loss 0.0582, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 11001, loss 0.0949, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 11501, loss 0.0838, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12001, loss 0.0650, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12501, loss 0.0586, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13001, loss 0.0475, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.0365, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14001, loss 0.0529, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14501, loss 0.0926, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 15.831570979000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.03
normal_0.5
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_1
./test_glass0/result_MLP_15000_0.03_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_2
----------------------



epoch 1, loss 0.6806, train acc 70.18%, f1 0.4000, precision 0.5862, recall 0.3036, auc 0.5996
epoch 501, loss 0.3282, train acc 82.46%, f1 0.7414, precision 0.7167, recall 0.7679, auc 0.8100
epoch 1001, loss 0.3953, train acc 84.21%, f1 0.7568, precision 0.7636, recall 0.7500, auc 0.8185
epoch 1501, loss 0.3142, train acc 85.38%, f1 0.7706, precision 0.7925, recall 0.7500, auc 0.8272
epoch 2001, loss 0.3250, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 2501, loss 0.2099, train acc 90.64%, f1 0.8621, precision 0.8333, recall 0.8929, auc 0.9030
epoch 3001, loss 0.2017, train acc 91.23%, f1 0.8718, precision 0.8361, recall 0.9107, auc 0.9119
epoch 3501, loss 0.1645, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 4001, loss 0.1084, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 4501, loss 0.1333, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 5001, loss 0.0985, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.1523, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6001, loss 0.1032, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6501, loss 0.0915, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 7001, loss 0.1569, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 7501, loss 0.1219, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8001, loss 0.0952, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8501, loss 0.0979, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9001, loss 0.1555, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9501, loss 0.1000, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10001, loss 0.0596, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10501, loss 0.1101, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11001, loss 0.0595, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.0827, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12001, loss 0.1288, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12501, loss 0.1175, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13001, loss 0.1091, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.0347, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14001, loss 0.0950, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.1204, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
running_time is 15.902517185999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.03
normal_0.5
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_2
./test_glass0/result_MLP_15000_0.03_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_3
----------------------



epoch 1, loss 0.6757, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.4355, train acc 81.29%, f1 0.7333, precision 0.6875, recall 0.7857, auc 0.8059
epoch 1001, loss 0.3656, train acc 83.04%, f1 0.7521, precision 0.7213, recall 0.7857, auc 0.8189
epoch 1501, loss 0.3068, train acc 85.96%, f1 0.7931, precision 0.7667, recall 0.8214, auc 0.8498
epoch 2001, loss 0.2709, train acc 88.30%, f1 0.8276, precision 0.8000, recall 0.8571, auc 0.8764
epoch 2501, loss 0.2786, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 3001, loss 0.1750, train acc 90.06%, f1 0.8522, precision 0.8305, recall 0.8750, auc 0.8940
epoch 3501, loss 0.1723, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 4001, loss 0.1676, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 4501, loss 0.1502, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 5001, loss 0.1426, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 5501, loss 0.1985, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 6001, loss 0.1049, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 6501, loss 0.1199, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 7001, loss 0.1367, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 7501, loss 0.1009, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8001, loss 0.0984, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8501, loss 0.0987, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9001, loss 0.0402, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9501, loss 0.1090, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10001, loss 0.0884, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 10501, loss 0.0595, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11001, loss 0.0612, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11501, loss 0.0563, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12001, loss 0.0672, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 12501, loss 0.1330, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13001, loss 0.0748, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13501, loss 0.0820, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14001, loss 0.1563, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14501, loss 0.1457, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
running_time is 15.84284974
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.03
normal_0.5
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_3
./test_glass0/result_MLP_15000_0.03_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_4
----------------------



epoch 1, loss 0.6710, train acc 66.67%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4957
epoch 501, loss 0.4596, train acc 80.70%, f1 0.7227, precision 0.6825, recall 0.7679, auc 0.7970
epoch 1001, loss 0.3710, train acc 81.87%, f1 0.7304, precision 0.7119, recall 0.7500, auc 0.8011
epoch 1501, loss 0.3678, train acc 85.38%, f1 0.7826, precision 0.7627, recall 0.8036, auc 0.8409
epoch 2001, loss 0.2620, train acc 88.89%, f1 0.8288, precision 0.8364, recall 0.8214, auc 0.8716
epoch 2501, loss 0.2335, train acc 88.30%, f1 0.8214, precision 0.8214, recall 0.8214, auc 0.8672
epoch 3001, loss 0.2836, train acc 89.47%, f1 0.8421, precision 0.8276, recall 0.8571, auc 0.8851
epoch 3501, loss 0.2920, train acc 90.06%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8986
epoch 4001, loss 0.2555, train acc 91.23%, f1 0.8696, precision 0.8475, recall 0.8929, auc 0.9073
epoch 4501, loss 0.1417, train acc 91.81%, f1 0.8772, precision 0.8621, recall 0.8929, auc 0.9116
epoch 5001, loss 0.1265, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 5501, loss 0.2707, train acc 91.81%, f1 0.8772, precision 0.8621, recall 0.8929, auc 0.9116
epoch 6001, loss 0.2408, train acc 91.81%, f1 0.8772, precision 0.8621, recall 0.8929, auc 0.9116
epoch 6501, loss 0.2541, train acc 91.23%, f1 0.8696, precision 0.8475, recall 0.8929, auc 0.9073
epoch 7001, loss 0.1365, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 7501, loss 0.1645, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 8001, loss 0.1896, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 8501, loss 0.1208, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 9001, loss 0.1817, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 9501, loss 0.1024, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 10001, loss 0.1792, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10501, loss 0.1871, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 11001, loss 0.1384, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 11501, loss 0.2691, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12001, loss 0.1363, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12501, loss 0.1202, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13001, loss 0.1114, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 13501, loss 0.1157, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 14001, loss 0.1493, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 14501, loss 0.0797, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
running_time is 15.777398549
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.03
normal_0.5
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_4
./test_glass0/result_MLP_15000_0.03_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_5
----------------------



epoch 1, loss 0.6760, train acc 59.88%, f1 0.1882, precision 0.2759, recall 0.1429, auc 0.4809
epoch 501, loss 0.4230, train acc 81.40%, f1 0.7288, precision 0.6935, recall 0.7679, auc 0.8020
epoch 1001, loss 0.3488, train acc 84.30%, f1 0.7652, precision 0.7458, recall 0.7857, auc 0.8282
epoch 1501, loss 0.2898, train acc 88.37%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8815
epoch 2001, loss 0.2978, train acc 88.37%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8815
epoch 2501, loss 0.3115, train acc 91.28%, f1 0.8673, precision 0.8596, recall 0.8750, auc 0.9030
epoch 3001, loss 0.2830, train acc 93.02%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9252
epoch 3501, loss 0.2006, train acc 93.60%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9341
epoch 4001, loss 0.2045, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 4501, loss 0.1320, train acc 94.19%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9430
epoch 5001, loss 0.1177, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 5501, loss 0.1156, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 6001, loss 0.0768, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 6501, loss 0.0516, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 7001, loss 0.1494, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 7501, loss 0.1045, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 8001, loss 0.0953, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 8501, loss 0.1356, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 9001, loss 0.0961, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 9501, loss 0.1068, train acc 98.26%, f1 0.9725, precision 1.0000, recall 0.9464, auc 0.9732
epoch 10001, loss 0.0499, train acc 97.67%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9735
epoch 10501, loss 0.0565, train acc 98.26%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9825
epoch 11001, loss 0.0523, train acc 98.84%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9868
epoch 11501, loss 0.0629, train acc 98.26%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9825
epoch 12001, loss 0.0390, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 12501, loss 0.0671, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 13001, loss 0.0541, train acc 98.84%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9868
epoch 13501, loss 0.0437, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 14001, loss 0.0539, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 14501, loss 0.0270, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
running_time is 15.763333323
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.03
normal_0.5
./test_glass0/model_MLP_15000_0.03/record_1/MLP_15000_0.03_5
./test_glass0/result_MLP_15000_0.03_normal_0.5/record_1/
----------------------



the AUC is 0.5714285714285714

the Fscore is 0.25

the precision is 1.0

the recall is 0.14285714285714285

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_1
----------------------



epoch 1, loss 0.6834, train acc 68.42%, f1 0.6087, precision 0.5122, recall 0.7500, auc 0.7011
epoch 501, loss 0.4232, train acc 83.63%, f1 0.7667, precision 0.7188, recall 0.8214, auc 0.8325
epoch 1001, loss 0.3759, train acc 85.96%, f1 0.8000, precision 0.7500, recall 0.8571, auc 0.8590
epoch 1501, loss 0.2933, train acc 88.89%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8945
epoch 2001, loss 0.2888, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 2501, loss 0.3945, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 3001, loss 0.2793, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 3501, loss 0.2829, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 4001, loss 0.1653, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 4501, loss 0.1104, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 5001, loss 0.1503, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 5501, loss 0.1073, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 6001, loss 0.1249, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 6501, loss 0.1661, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 7001, loss 0.1037, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 7501, loss 0.0951, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 8001, loss 0.0994, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 8501, loss 0.1887, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9001, loss 0.1246, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9501, loss 0.1199, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10001, loss 0.0974, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10501, loss 0.0299, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11001, loss 0.1220, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11501, loss 0.0968, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12001, loss 0.0365, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12501, loss 0.0506, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13001, loss 0.0905, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.1019, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14001, loss 0.0444, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 14501, loss 0.0182, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
running_time is 15.80648234
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.04
normal_0.5
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_1
./test_glass0/result_MLP_15000_0.04_normal_0.5/record_1/
----------------------



the AUC is 0.5763546798029557

the Fscore is 0.42857142857142855

the precision is 0.42857142857142855

the recall is 0.42857142857142855

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_2
----------------------



epoch 1, loss 0.6674, train acc 63.74%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4739
epoch 501, loss 0.2656, train acc 81.29%, f1 0.7193, precision 0.7069, recall 0.7321, auc 0.7922
epoch 1001, loss 0.3399, train acc 85.38%, f1 0.7826, precision 0.7627, recall 0.8036, auc 0.8409
epoch 1501, loss 0.2968, train acc 85.96%, f1 0.7895, precision 0.7759, recall 0.8036, auc 0.8453
epoch 2001, loss 0.2629, train acc 88.89%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8945
epoch 2501, loss 0.2370, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 3001, loss 0.2418, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 3501, loss 0.1733, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 4001, loss 0.1138, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 4501, loss 0.1412, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 5001, loss 0.1828, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 5501, loss 0.1381, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 6001, loss 0.1159, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 6501, loss 0.1418, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 7001, loss 0.1559, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 7501, loss 0.1257, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 8001, loss 0.0759, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8501, loss 0.1507, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 9001, loss 0.1698, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 9501, loss 0.1896, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10001, loss 0.0692, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 10501, loss 0.0952, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 11001, loss 0.0833, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 11501, loss 0.0995, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12001, loss 0.0562, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 12501, loss 0.0947, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 13001, loss 0.1320, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 13501, loss 0.1031, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 14001, loss 0.1080, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 14501, loss 0.1192, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
running_time is 15.791262294000001
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.04
normal_0.5
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_2
./test_glass0/result_MLP_15000_0.04_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_3
----------------------



epoch 1, loss 0.6611, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.4183, train acc 80.70%, f1 0.7273, precision 0.6769, recall 0.7857, auc 0.8016
epoch 1001, loss 0.3744, train acc 83.04%, f1 0.7521, precision 0.7213, recall 0.7857, auc 0.8189
epoch 1501, loss 0.3195, train acc 84.21%, f1 0.7692, precision 0.7377, recall 0.8036, auc 0.8322
epoch 2001, loss 0.3251, train acc 87.13%, f1 0.8070, precision 0.7931, recall 0.8214, auc 0.8585
epoch 2501, loss 0.2226, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 3001, loss 0.2379, train acc 90.64%, f1 0.8596, precision 0.8448, recall 0.8750, auc 0.8984
epoch 3501, loss 0.2041, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 4001, loss 0.1692, train acc 92.98%, f1 0.8929, precision 0.8929, recall 0.8929, auc 0.9203
epoch 4501, loss 0.1759, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5001, loss 0.1718, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.1459, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6001, loss 0.0703, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6501, loss 0.1289, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7001, loss 0.0985, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7501, loss 0.1115, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8001, loss 0.1163, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8501, loss 0.1532, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9001, loss 0.0730, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 9501, loss 0.0744, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 10001, loss 0.0481, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10501, loss 0.0674, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11001, loss 0.0299, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11501, loss 0.0699, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 12001, loss 0.1117, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12501, loss 0.0351, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 13001, loss 0.0945, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 13501, loss 0.0600, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14001, loss 0.0348, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 14501, loss 0.0475, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
running_time is 15.798875182
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.04
normal_0.5
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_3
./test_glass0/result_MLP_15000_0.04_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_4
----------------------



epoch 1, loss 0.6674, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.4614, train acc 81.29%, f1 0.7288, precision 0.6935, recall 0.7679, auc 0.8013
epoch 1001, loss 0.3659, train acc 83.63%, f1 0.7627, precision 0.7258, recall 0.8036, auc 0.8279
epoch 1501, loss 0.3637, train acc 84.80%, f1 0.7797, precision 0.7419, recall 0.8214, auc 0.8411
epoch 2001, loss 0.2603, train acc 86.55%, f1 0.8000, precision 0.7797, recall 0.8214, auc 0.8542
epoch 2501, loss 0.2603, train acc 88.89%, f1 0.8348, precision 0.8136, recall 0.8571, auc 0.8807
epoch 3001, loss 0.2185, train acc 89.47%, f1 0.8448, precision 0.8167, recall 0.8750, auc 0.8897
epoch 3501, loss 0.2454, train acc 88.30%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8810
epoch 4001, loss 0.3105, train acc 89.47%, f1 0.8500, precision 0.7969, recall 0.9107, auc 0.8988
epoch 4501, loss 0.1557, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 5001, loss 0.2104, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 5501, loss 0.2137, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 6001, loss 0.2506, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 6501, loss 0.1548, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 7001, loss 0.1510, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 7501, loss 0.1462, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 8001, loss 0.2347, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 8501, loss 0.1342, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 9001, loss 0.2057, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 9501, loss 0.1203, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 10001, loss 0.1468, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 10501, loss 0.1419, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 11001, loss 0.1235, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 11501, loss 0.1646, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 12001, loss 0.2016, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 12501, loss 0.1395, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 13001, loss 0.1460, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 13501, loss 0.1900, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 14001, loss 0.1035, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 14501, loss 0.1578, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
running_time is 15.941708105
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.04
normal_0.5
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_4
./test_glass0/result_MLP_15000_0.04_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_5
----------------------



epoch 1, loss 0.6772, train acc 57.56%, f1 0.0267, precision 0.0526, recall 0.0179, auc 0.4313
epoch 501, loss 0.3455, train acc 80.81%, f1 0.7273, precision 0.6769, recall 0.7857, auc 0.8023
epoch 1001, loss 0.2896, train acc 83.72%, f1 0.7667, precision 0.7188, recall 0.8214, auc 0.8331
epoch 1501, loss 0.3682, train acc 86.05%, f1 0.8033, precision 0.7424, recall 0.8750, auc 0.8642
epoch 2001, loss 0.2731, train acc 88.37%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8815
epoch 2501, loss 0.2353, train acc 88.95%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8950
epoch 3001, loss 0.1609, train acc 91.86%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9166
epoch 3501, loss 0.1422, train acc 93.02%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9252
epoch 4001, loss 0.1401, train acc 94.19%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9384
epoch 4501, loss 0.1701, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 5001, loss 0.2010, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 5501, loss 0.1334, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 6001, loss 0.1553, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 6501, loss 0.1237, train acc 94.19%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9430
epoch 7001, loss 0.0882, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 7501, loss 0.1545, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 8001, loss 0.0736, train acc 94.77%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9474
epoch 8501, loss 0.0697, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 9001, loss 0.0969, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 9501, loss 0.0588, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 10001, loss 0.0546, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 10501, loss 0.0837, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 11001, loss 0.0790, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 11501, loss 0.0634, train acc 95.93%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9560
epoch 12001, loss 0.0520, train acc 95.93%, f1 0.9369, precision 0.9455, recall 0.9286, auc 0.9514
epoch 12501, loss 0.0813, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 13001, loss 0.0572, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 13501, loss 0.0719, train acc 97.67%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9781
epoch 14001, loss 0.0537, train acc 98.26%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9825
epoch 14501, loss 0.1023, train acc 98.26%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9825
running_time is 15.880867241999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.04
normal_0.5
./test_glass0/model_MLP_15000_0.04/record_1/MLP_15000_0.04_5
./test_glass0/result_MLP_15000_0.04_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_1
----------------------



epoch 1, loss 0.6779, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3540, train acc 84.80%, f1 0.7759, precision 0.7500, recall 0.8036, auc 0.8366
epoch 1001, loss 0.4016, train acc 86.55%, f1 0.8067, precision 0.7619, recall 0.8571, auc 0.8634
epoch 1501, loss 0.3644, train acc 88.89%, f1 0.8403, precision 0.7937, recall 0.8929, auc 0.8899
epoch 2001, loss 0.2740, train acc 88.30%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8856
epoch 2501, loss 0.2138, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 3001, loss 0.3558, train acc 87.72%, f1 0.8293, precision 0.7612, recall 0.9107, auc 0.8858
epoch 3501, loss 0.2503, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 4001, loss 0.2353, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 4501, loss 0.2137, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 5001, loss 0.1858, train acc 90.64%, f1 0.8689, precision 0.8030, recall 0.9464, auc 0.9167
epoch 5501, loss 0.1939, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 6001, loss 0.1586, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 6501, loss 0.1178, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 7001, loss 0.1571, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 7501, loss 0.1233, train acc 92.98%, f1 0.9016, precision 0.8333, recall 0.9821, auc 0.9432
epoch 8001, loss 0.1769, train acc 92.98%, f1 0.9016, precision 0.8333, recall 0.9821, auc 0.9432
epoch 8501, loss 0.1710, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 9001, loss 0.0731, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 9501, loss 0.1436, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 10001, loss 0.1072, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 10501, loss 0.1128, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 11001, loss 0.1114, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 11501, loss 0.0655, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 12001, loss 0.1068, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 12501, loss 0.1068, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13001, loss 0.0793, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 13501, loss 0.0753, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14001, loss 0.1216, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 14501, loss 0.1402, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
running_time is 15.845565493
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.05
normal_0.5
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_1
./test_glass0/result_MLP_15000_0.05_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_2
----------------------



epoch 1, loss 0.6619, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3886, train acc 81.87%, f1 0.7350, precision 0.7049, recall 0.7679, auc 0.8057
epoch 1001, loss 0.3286, train acc 84.80%, f1 0.7719, precision 0.7586, recall 0.7857, auc 0.8320
epoch 1501, loss 0.2424, train acc 86.55%, f1 0.8034, precision 0.7705, recall 0.8393, auc 0.8588
epoch 2001, loss 0.2053, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 2501, loss 0.2047, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 3001, loss 0.1401, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 3501, loss 0.2216, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 4001, loss 0.1533, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 4501, loss 0.1348, train acc 95.91%, f1 0.9381, precision 0.9298, recall 0.9464, auc 0.9558
epoch 5001, loss 0.1709, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.0994, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6001, loss 0.1019, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6501, loss 0.1027, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7001, loss 0.1699, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7501, loss 0.1203, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8001, loss 0.0599, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8501, loss 0.1443, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 9001, loss 0.1214, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 9501, loss 0.1290, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10001, loss 0.1009, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10501, loss 0.0974, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11001, loss 0.1635, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.0880, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 12001, loss 0.0622, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12501, loss 0.0417, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13001, loss 0.0978, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13501, loss 0.0425, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14001, loss 0.0796, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
epoch 14501, loss 0.0844, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
running_time is 15.803766762
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.05
normal_0.5
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_2
./test_glass0/result_MLP_15000_0.05_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_3
----------------------



epoch 1, loss 0.6702, train acc 62.57%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4652
epoch 501, loss 0.3785, train acc 79.53%, f1 0.7107, precision 0.6615, recall 0.7679, auc 0.7883
epoch 1001, loss 0.2552, train acc 83.63%, f1 0.7705, precision 0.7121, recall 0.8393, auc 0.8370
epoch 1501, loss 0.2671, train acc 88.30%, f1 0.8276, precision 0.8000, recall 0.8571, auc 0.8764
epoch 2001, loss 0.2796, train acc 89.47%, f1 0.8475, precision 0.8065, recall 0.8929, auc 0.8943
epoch 2501, loss 0.2097, train acc 90.06%, f1 0.8522, precision 0.8305, recall 0.8750, auc 0.8940
epoch 3001, loss 0.2636, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 3501, loss 0.1574, train acc 92.98%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9249
epoch 4001, loss 0.1444, train acc 93.57%, f1 0.9027, precision 0.8947, recall 0.9107, auc 0.9293
epoch 4501, loss 0.1279, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 5001, loss 0.2117, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 5501, loss 0.0656, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 6001, loss 0.1137, train acc 96.49%, f1 0.9464, precision 0.9464, recall 0.9464, auc 0.9602
epoch 6501, loss 0.1973, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7001, loss 0.2009, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7501, loss 0.1473, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8001, loss 0.0709, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 8501, loss 0.0735, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 9001, loss 0.1328, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 9501, loss 0.0725, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 10001, loss 0.0624, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 10501, loss 0.0497, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 11001, loss 0.0549, train acc 98.25%, f1 0.9730, precision 0.9818, recall 0.9643, auc 0.9778
epoch 11501, loss 0.0396, train acc 98.83%, f1 0.9821, precision 0.9821, recall 0.9821, auc 0.9867
epoch 12001, loss 0.0490, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 12501, loss 0.0458, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 13001, loss 0.0546, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0322, train acc 99.42%, f1 0.9910, precision 1.0000, recall 0.9821, auc 0.9911
epoch 14001, loss 0.0232, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0359, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 16.022913493
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.05
normal_0.5
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_3
./test_glass0/result_MLP_15000_0.05_normal_0.5/record_1/
----------------------



the AUC is 0.5899014778325122

the Fscore is 0.3333333333333333

the precision is 0.75

the recall is 0.21428571428571427

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_4
----------------------



epoch 1, loss 0.6821, train acc 67.25%, f1 0.0667, precision 0.5000, recall 0.0357, auc 0.5092
epoch 501, loss 0.3719, train acc 81.29%, f1 0.7288, precision 0.6935, recall 0.7679, auc 0.8013
epoch 1001, loss 0.3474, train acc 81.87%, f1 0.7438, precision 0.6923, recall 0.8036, auc 0.8148
epoch 1501, loss 0.4267, train acc 84.21%, f1 0.7731, precision 0.7302, recall 0.8214, auc 0.8368
epoch 2001, loss 0.3145, train acc 86.55%, f1 0.8034, precision 0.7705, recall 0.8393, auc 0.8588
epoch 2501, loss 0.2409, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 3001, loss 0.1769, train acc 88.30%, f1 0.8305, precision 0.7903, recall 0.8750, auc 0.8810
epoch 3501, loss 0.1542, train acc 90.06%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8986
epoch 4001, loss 0.2438, train acc 91.23%, f1 0.8718, precision 0.8361, recall 0.9107, auc 0.9119
epoch 4501, loss 0.1721, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 5001, loss 0.2566, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 5501, loss 0.1958, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 6001, loss 0.2043, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 6501, loss 0.2232, train acc 92.40%, f1 0.8870, precision 0.8644, recall 0.9107, auc 0.9206
epoch 7001, loss 0.2391, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 7501, loss 0.1887, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 8001, loss 0.1967, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 8501, loss 0.2056, train acc 93.57%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9339
epoch 9001, loss 0.2378, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 9501, loss 0.0879, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 10001, loss 0.1143, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 10501, loss 0.1182, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 11001, loss 0.0843, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 11501, loss 0.1303, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12001, loss 0.1125, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12501, loss 0.1602, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13001, loss 0.1198, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13501, loss 0.1372, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 14001, loss 0.1204, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 14501, loss 0.0904, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
running_time is 15.934606309000001
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.05
normal_0.5
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_4
./test_glass0/result_MLP_15000_0.05_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_5
----------------------



epoch 1, loss 0.6982, train acc 34.30%, f1 0.4978, precision 0.3314, recall 1.0000, auc 0.5129
epoch 501, loss 0.3874, train acc 80.23%, f1 0.7213, precision 0.6667, recall 0.7857, auc 0.7980
epoch 1001, loss 0.3707, train acc 82.56%, f1 0.7458, precision 0.7097, recall 0.7857, auc 0.8153
epoch 1501, loss 0.2923, train acc 84.30%, f1 0.7731, precision 0.7302, recall 0.8214, auc 0.8374
epoch 2001, loss 0.3815, train acc 84.88%, f1 0.7833, precision 0.7344, recall 0.8393, auc 0.8464
epoch 2501, loss 0.3343, train acc 86.63%, f1 0.8000, precision 0.7797, recall 0.8214, auc 0.8547
epoch 3001, loss 0.2744, train acc 88.95%, f1 0.8348, precision 0.8136, recall 0.8571, auc 0.8812
epoch 3501, loss 0.2870, train acc 88.95%, f1 0.8348, precision 0.8136, recall 0.8571, auc 0.8812
epoch 4001, loss 0.1772, train acc 89.53%, f1 0.8421, precision 0.8276, recall 0.8571, auc 0.8855
epoch 4501, loss 0.2369, train acc 90.70%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9126
epoch 5001, loss 0.2614, train acc 91.86%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9166
epoch 5501, loss 0.0925, train acc 91.86%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9166
epoch 6001, loss 0.1839, train acc 93.60%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9341
epoch 6501, loss 0.2028, train acc 93.60%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9387
epoch 7001, loss 0.1833, train acc 93.02%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9390
epoch 7501, loss 0.1159, train acc 93.60%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9387
epoch 8001, loss 0.1802, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 8501, loss 0.1113, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 9001, loss 0.2000, train acc 93.02%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9390
epoch 9501, loss 0.1488, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 10001, loss 0.2547, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 10501, loss 0.1323, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11001, loss 0.1298, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11501, loss 0.1370, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 12001, loss 0.1827, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 12501, loss 0.1052, train acc 93.60%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9387
epoch 13001, loss 0.0906, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 13501, loss 0.1447, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 14001, loss 0.1505, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 14501, loss 0.0945, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
running_time is 15.701110233000001
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.05
normal_0.5
./test_glass0/model_MLP_15000_0.05/record_1/MLP_15000_0.05_5
./test_glass0/result_MLP_15000_0.05_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_1
----------------------



epoch 1, loss 0.6472, train acc 66.67%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4957
epoch 501, loss 0.3222, train acc 83.63%, f1 0.7667, precision 0.7188, recall 0.8214, auc 0.8325
epoch 1001, loss 0.3010, train acc 86.55%, f1 0.8099, precision 0.7538, recall 0.8750, auc 0.8679
epoch 1501, loss 0.3597, train acc 87.13%, f1 0.8226, precision 0.7500, recall 0.9107, auc 0.8814
epoch 2001, loss 0.3637, train acc 88.30%, f1 0.8361, precision 0.7727, recall 0.9107, auc 0.8901
epoch 2501, loss 0.2184, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 3001, loss 0.2018, train acc 89.47%, f1 0.8571, precision 0.7714, recall 0.9643, auc 0.9126
epoch 3501, loss 0.2092, train acc 89.47%, f1 0.8571, precision 0.7714, recall 0.9643, auc 0.9126
epoch 4001, loss 0.2297, train acc 90.06%, f1 0.8618, precision 0.7910, recall 0.9464, auc 0.9123
epoch 4501, loss 0.2192, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 5001, loss 0.2009, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 5501, loss 0.1468, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 6001, loss 0.1290, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 6501, loss 0.0859, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 7001, loss 0.0820, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 7501, loss 0.2024, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 8001, loss 0.1270, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 8501, loss 0.1141, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 9001, loss 0.0504, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 9501, loss 0.1450, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 10001, loss 0.0934, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 10501, loss 0.1409, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 11001, loss 0.0477, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 11501, loss 0.0857, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12001, loss 0.1457, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12501, loss 0.0852, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13001, loss 0.0902, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13501, loss 0.1000, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14001, loss 0.1023, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.0561, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
running_time is 15.852744697999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.06
normal_0.5
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_1
./test_glass0/result_MLP_15000_0.06_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_2
----------------------



epoch 1, loss 0.6520, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3921, train acc 82.46%, f1 0.7414, precision 0.7167, recall 0.7679, auc 0.8100
epoch 1001, loss 0.3112, train acc 84.21%, f1 0.7611, precision 0.7544, recall 0.7679, auc 0.8231
epoch 1501, loss 0.2315, train acc 89.47%, f1 0.8475, precision 0.8065, recall 0.8929, auc 0.8943
epoch 2001, loss 0.1892, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 2501, loss 0.1459, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 3001, loss 0.1657, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 3501, loss 0.1639, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 4001, loss 0.1673, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 4501, loss 0.1866, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 5001, loss 0.0918, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 5501, loss 0.0633, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6001, loss 0.0935, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6501, loss 0.1105, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7001, loss 0.1297, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 7501, loss 0.0966, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.0649, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 8501, loss 0.0587, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 9001, loss 0.1172, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 9501, loss 0.0722, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 10001, loss 0.0681, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 10501, loss 0.1573, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11001, loss 0.0302, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.0774, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12001, loss 0.0635, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 12501, loss 0.1053, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13001, loss 0.1452, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13501, loss 0.0382, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14001, loss 0.0830, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14501, loss 0.1155, train acc 98.25%, f1 0.9735, precision 0.9649, recall 0.9821, auc 0.9824
running_time is 15.737964214
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.06
normal_0.5
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_2
./test_glass0/result_MLP_15000_0.06_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_3
----------------------



epoch 1, loss 0.6427, train acc 61.99%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4609
epoch 501, loss 0.4158, train acc 81.29%, f1 0.7333, precision 0.6875, recall 0.7857, auc 0.8059
epoch 1001, loss 0.3257, train acc 83.04%, f1 0.7642, precision 0.7015, recall 0.8393, auc 0.8327
epoch 1501, loss 0.4070, train acc 85.38%, f1 0.7863, precision 0.7541, recall 0.8214, auc 0.8455
epoch 2001, loss 0.3687, train acc 85.38%, f1 0.7863, precision 0.7541, recall 0.8214, auc 0.8455
epoch 2501, loss 0.3655, train acc 88.30%, f1 0.8246, precision 0.8103, recall 0.8393, auc 0.8718
epoch 3001, loss 0.2109, train acc 90.06%, f1 0.8468, precision 0.8545, recall 0.8393, auc 0.8849
epoch 3501, loss 0.2681, train acc 91.81%, f1 0.8750, precision 0.8750, recall 0.8750, auc 0.9071
epoch 4001, loss 0.2094, train acc 93.57%, f1 0.9027, precision 0.8947, recall 0.9107, auc 0.9293
epoch 4501, loss 0.2237, train acc 94.15%, f1 0.9107, precision 0.9107, recall 0.9107, auc 0.9336
epoch 5001, loss 0.2031, train acc 92.98%, f1 0.8947, precision 0.8793, recall 0.9107, auc 0.9249
epoch 5501, loss 0.2463, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 6001, loss 0.0960, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 6501, loss 0.1512, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 7001, loss 0.1381, train acc 94.15%, f1 0.9123, precision 0.8966, recall 0.9286, auc 0.9382
epoch 7501, loss 0.1551, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 8001, loss 0.0753, train acc 94.74%, f1 0.9204, precision 0.9123, recall 0.9286, auc 0.9425
epoch 8501, loss 0.1147, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 9001, loss 0.1332, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 9501, loss 0.0662, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 10001, loss 0.1565, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10501, loss 0.1523, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11001, loss 0.0928, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11501, loss 0.1669, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12001, loss 0.0492, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12501, loss 0.0842, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13001, loss 0.1035, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13501, loss 0.0637, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14001, loss 0.1123, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14501, loss 0.0958, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
running_time is 15.636199987
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.06
normal_0.5
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_3
./test_glass0/result_MLP_15000_0.06_normal_0.5/record_1/
----------------------



the AUC is 0.6699507389162562

the Fscore is 0.5853658536585367

the precision is 0.4444444444444444

the recall is 0.8571428571428571

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_4
----------------------



epoch 1, loss 0.6860, train acc 63.74%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4739
epoch 501, loss 0.3618, train acc 80.70%, f1 0.7273, precision 0.6769, recall 0.7857, auc 0.8016
epoch 1001, loss 0.4360, train acc 83.04%, f1 0.7603, precision 0.7077, recall 0.8214, auc 0.8281
epoch 1501, loss 0.4207, train acc 83.63%, f1 0.7705, precision 0.7121, recall 0.8393, auc 0.8370
epoch 2001, loss 0.3639, train acc 87.13%, f1 0.8167, precision 0.7656, recall 0.8750, auc 0.8723
epoch 2501, loss 0.3398, train acc 88.30%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8856
epoch 3001, loss 0.3168, train acc 89.47%, f1 0.8475, precision 0.8065, recall 0.8929, auc 0.8943
epoch 3501, loss 0.1606, train acc 88.89%, f1 0.8403, precision 0.7937, recall 0.8929, auc 0.8899
epoch 4001, loss 0.1498, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 4501, loss 0.1690, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 5001, loss 0.1993, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 5501, loss 0.1757, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 6001, loss 0.1177, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 6501, loss 0.1408, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 7001, loss 0.1458, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 7501, loss 0.1590, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 8001, loss 0.1300, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8501, loss 0.0954, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 9001, loss 0.1435, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 9501, loss 0.2135, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10001, loss 0.0922, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10501, loss 0.1963, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 11001, loss 0.1071, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 11501, loss 0.1069, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12001, loss 0.0982, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12501, loss 0.0797, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13001, loss 0.0909, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13501, loss 0.1412, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 14001, loss 0.1163, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 14501, loss 0.0779, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
running_time is 15.778659481
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.06
normal_0.5
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_4
./test_glass0/result_MLP_15000_0.06_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_5
----------------------



epoch 1, loss 0.6763, train acc 67.44%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3516, train acc 81.98%, f1 0.7480, precision 0.6866, recall 0.8214, auc 0.8202
epoch 1001, loss 0.4138, train acc 82.56%, f1 0.7541, precision 0.6970, recall 0.8214, auc 0.8245
epoch 1501, loss 0.2707, train acc 84.88%, f1 0.7869, precision 0.7273, recall 0.8571, auc 0.8510
epoch 2001, loss 0.3712, train acc 87.79%, f1 0.8235, precision 0.7778, recall 0.8750, auc 0.8772
epoch 2501, loss 0.3537, train acc 87.21%, f1 0.8103, precision 0.7833, recall 0.8393, auc 0.8636
epoch 3001, loss 0.2498, train acc 87.21%, f1 0.8136, precision 0.7742, recall 0.8571, auc 0.8682
epoch 3501, loss 0.2590, train acc 88.37%, f1 0.8361, precision 0.7727, recall 0.9107, auc 0.8907
epoch 4001, loss 0.2358, train acc 91.86%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9212
epoch 4501, loss 0.1605, train acc 93.02%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9298
epoch 5001, loss 0.1991, train acc 93.02%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9344
epoch 5501, loss 0.1814, train acc 92.44%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9347
epoch 6001, loss 0.1885, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 6501, loss 0.1298, train acc 93.02%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9390
epoch 7001, loss 0.2382, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 7501, loss 0.1422, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 8001, loss 0.1319, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 8501, loss 0.1879, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 9001, loss 0.1383, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 9501, loss 0.1725, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 10001, loss 0.1136, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 10501, loss 0.1333, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 11001, loss 0.1345, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 11501, loss 0.0612, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 12001, loss 0.1541, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 12501, loss 0.0916, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 13001, loss 0.0445, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 13501, loss 0.0807, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 14001, loss 0.1287, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
epoch 14501, loss 0.0644, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
running_time is 15.928675235000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.06
normal_0.5
./test_glass0/model_MLP_15000_0.06/record_1/MLP_15000_0.06_5
./test_glass0/result_MLP_15000_0.06_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_1
----------------------



epoch 1, loss 0.6860, train acc 47.37%, f1 0.5545, precision 0.3836, recall 1.0000, auc 0.6087
epoch 501, loss 0.3987, train acc 83.63%, f1 0.7742, precision 0.7059, recall 0.8571, auc 0.8416
epoch 1001, loss 0.2904, train acc 84.21%, f1 0.7874, precision 0.7042, recall 0.8929, auc 0.8551
epoch 1501, loss 0.4296, train acc 87.13%, f1 0.8226, precision 0.7500, recall 0.9107, auc 0.8814
epoch 2001, loss 0.3204, train acc 87.13%, f1 0.8254, precision 0.7429, recall 0.9286, auc 0.8860
epoch 2501, loss 0.3289, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 3001, loss 0.2380, train acc 88.89%, f1 0.8455, precision 0.7761, recall 0.9286, auc 0.8991
epoch 3501, loss 0.2125, train acc 91.23%, f1 0.8780, precision 0.8060, recall 0.9643, auc 0.9256
epoch 4001, loss 0.1395, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 4501, loss 0.2073, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 5001, loss 0.1151, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 5501, loss 0.1451, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 6001, loss 0.1036, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 6501, loss 0.1091, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 7001, loss 0.1163, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 7501, loss 0.0903, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 8001, loss 0.1028, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8501, loss 0.1051, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9001, loss 0.0859, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 9501, loss 0.0650, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 10001, loss 0.1208, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 10501, loss 0.1247, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 11001, loss 0.1002, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 11501, loss 0.1117, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 12001, loss 0.0692, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 12501, loss 0.0595, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 13001, loss 0.0422, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 13501, loss 0.1095, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 14001, loss 0.0490, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 14501, loss 0.0389, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
running_time is 15.724907408000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.07
normal_0.5
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_1
./test_glass0/result_MLP_15000_0.07_normal_0.5/record_1/
----------------------



the AUC is 0.5911330049261083

the Fscore is 0.38095238095238093

the precision is 0.5714285714285714

the recall is 0.2857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_2
----------------------



epoch 1, loss 0.6637, train acc 56.73%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4217
epoch 501, loss 0.3732, train acc 81.87%, f1 0.7395, precision 0.6984, recall 0.7857, auc 0.8102
epoch 1001, loss 0.2104, train acc 84.80%, f1 0.7797, precision 0.7419, recall 0.8214, auc 0.8411
epoch 1501, loss 0.2613, train acc 87.72%, f1 0.8264, precision 0.7692, recall 0.8929, auc 0.8812
epoch 2001, loss 0.3140, train acc 87.72%, f1 0.8264, precision 0.7692, recall 0.8929, auc 0.8812
epoch 2501, loss 0.3019, train acc 89.47%, f1 0.8500, precision 0.7969, recall 0.9107, auc 0.8988
epoch 3001, loss 0.2131, train acc 91.23%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9210
epoch 3501, loss 0.2111, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 4001, loss 0.2079, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 4501, loss 0.1483, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 5001, loss 0.1533, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 5501, loss 0.2056, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6001, loss 0.1219, train acc 95.32%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9515
epoch 6501, loss 0.0786, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7001, loss 0.0854, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 7501, loss 0.1051, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 8001, loss 0.1263, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 8501, loss 0.1033, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 9001, loss 0.1118, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 9501, loss 0.0751, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10001, loss 0.0834, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10501, loss 0.0693, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 11001, loss 0.1374, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 11501, loss 0.1099, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 12001, loss 0.0704, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 12501, loss 0.1424, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13001, loss 0.1299, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13501, loss 0.0760, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14001, loss 0.0620, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14501, loss 0.0356, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
running_time is 15.788752808000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.07
normal_0.5
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_2
./test_glass0/result_MLP_15000_0.07_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_3
----------------------



epoch 1, loss 0.6524, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3870, train acc 81.29%, f1 0.7333, precision 0.6875, recall 0.7857, auc 0.8059
epoch 1001, loss 0.3082, train acc 83.63%, f1 0.7705, precision 0.7121, recall 0.8393, auc 0.8370
epoch 1501, loss 0.2450, train acc 85.38%, f1 0.7899, precision 0.7460, recall 0.8393, auc 0.8501
epoch 2001, loss 0.3194, train acc 87.72%, f1 0.8205, precision 0.7869, recall 0.8571, auc 0.8720
epoch 2501, loss 0.2437, train acc 89.47%, f1 0.8475, precision 0.8065, recall 0.8929, auc 0.8943
epoch 3001, loss 0.1387, train acc 88.89%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8945
epoch 3501, loss 0.2841, train acc 90.06%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8986
epoch 4001, loss 0.2081, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 4501, loss 0.2083, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 5001, loss 0.1596, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 5501, loss 0.1231, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 6001, loss 0.1381, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 6501, loss 0.1382, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 7001, loss 0.1402, train acc 94.15%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9428
epoch 7501, loss 0.2397, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 8001, loss 0.1025, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 8501, loss 0.0928, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9001, loss 0.1102, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9501, loss 0.0977, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10001, loss 0.0871, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10501, loss 0.1262, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 11001, loss 0.0393, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 11501, loss 0.1146, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 12001, loss 0.0758, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 12501, loss 0.0953, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 13001, loss 0.0374, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 13501, loss 0.1185, train acc 97.08%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9691
epoch 14001, loss 0.0732, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
epoch 14501, loss 0.0892, train acc 97.66%, f1 0.9643, precision 0.9643, recall 0.9643, auc 0.9734
running_time is 15.759549066000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.07
normal_0.5
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_3
./test_glass0/result_MLP_15000_0.07_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_4
----------------------



epoch 1, loss 0.6353, train acc 67.84%, f1 0.1538, precision 0.5556, recall 0.0893, auc 0.5273
epoch 501, loss 0.3691, train acc 79.53%, f1 0.7200, precision 0.6522, recall 0.8036, auc 0.7974
epoch 1001, loss 0.3225, train acc 83.04%, f1 0.7642, precision 0.7015, recall 0.8393, auc 0.8327
epoch 1501, loss 0.2862, train acc 84.21%, f1 0.7769, precision 0.7231, recall 0.8393, auc 0.8414
epoch 2001, loss 0.2757, train acc 87.13%, f1 0.8167, precision 0.7656, recall 0.8750, auc 0.8723
epoch 2501, loss 0.2597, train acc 87.72%, f1 0.8293, precision 0.7612, recall 0.9107, auc 0.8858
epoch 3001, loss 0.2239, train acc 89.47%, f1 0.8500, precision 0.7969, recall 0.9107, auc 0.8988
epoch 3501, loss 0.2147, train acc 88.89%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8945
epoch 4001, loss 0.2598, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 4501, loss 0.2061, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 5001, loss 0.1932, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 5501, loss 0.2547, train acc 91.23%, f1 0.8718, precision 0.8361, recall 0.9107, auc 0.9119
epoch 6001, loss 0.1222, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 6501, loss 0.1855, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 7001, loss 0.2037, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 7501, loss 0.1483, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 8001, loss 0.2265, train acc 92.98%, f1 0.8966, precision 0.8667, recall 0.9286, auc 0.9295
epoch 8501, loss 0.1651, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 9001, loss 0.1245, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 9501, loss 0.2157, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 10001, loss 0.2006, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 10501, loss 0.1049, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 11001, loss 0.1321, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 11501, loss 0.1783, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 12001, loss 0.1313, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 12501, loss 0.1434, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 13001, loss 0.1170, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 13501, loss 0.1203, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 14001, loss 0.1187, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 14501, loss 0.1476, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
running_time is 15.677387386999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.07
normal_0.5
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_4
./test_glass0/result_MLP_15000_0.07_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_5
----------------------



epoch 1, loss 0.6693, train acc 66.86%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4957
epoch 501, loss 0.3127, train acc 80.81%, f1 0.7317, precision 0.6716, recall 0.8036, auc 0.8070
epoch 1001, loss 0.2909, train acc 81.40%, f1 0.7333, precision 0.6875, recall 0.7857, auc 0.8067
epoch 1501, loss 0.3210, train acc 81.98%, f1 0.7559, precision 0.6761, recall 0.8571, auc 0.8294
epoch 2001, loss 0.3532, train acc 84.30%, f1 0.7805, precision 0.7164, recall 0.8571, auc 0.8467
epoch 2501, loss 0.2569, train acc 84.30%, f1 0.7805, precision 0.7164, recall 0.8571, auc 0.8467
epoch 3001, loss 0.3429, train acc 86.05%, f1 0.8033, precision 0.7424, recall 0.8750, auc 0.8642
epoch 3501, loss 0.2108, train acc 87.79%, f1 0.8235, precision 0.7778, recall 0.8750, auc 0.8772
epoch 4001, loss 0.2259, train acc 88.37%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8861
epoch 4501, loss 0.2755, train acc 87.79%, f1 0.8264, precision 0.7692, recall 0.8929, auc 0.8818
epoch 5001, loss 0.1827, train acc 89.53%, f1 0.8500, precision 0.7969, recall 0.9107, auc 0.8993
epoch 5501, loss 0.2159, train acc 89.53%, f1 0.8475, precision 0.8065, recall 0.8929, auc 0.8947
epoch 6001, loss 0.1552, train acc 90.12%, f1 0.8547, precision 0.8197, recall 0.8929, auc 0.8990
epoch 6501, loss 0.1868, train acc 91.86%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9166
epoch 7001, loss 0.2300, train acc 92.44%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9301
epoch 7501, loss 0.1537, train acc 91.86%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9258
epoch 8001, loss 0.1079, train acc 92.44%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9301
epoch 8501, loss 0.1284, train acc 93.02%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9344
epoch 9001, loss 0.1640, train acc 93.60%, f1 0.9043, precision 0.8814, recall 0.9286, auc 0.9341
epoch 9501, loss 0.1340, train acc 94.19%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9430
epoch 10001, loss 0.1125, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 10501, loss 0.1447, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 11001, loss 0.1657, train acc 95.35%, f1 0.9298, precision 0.9138, recall 0.9464, auc 0.9517
epoch 11501, loss 0.0841, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 12001, loss 0.1168, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 12501, loss 0.0983, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 13001, loss 0.0762, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 13501, loss 0.1026, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 14001, loss 0.0948, train acc 97.09%, f1 0.9558, precision 0.9474, recall 0.9643, auc 0.9692
epoch 14501, loss 0.0736, train acc 96.51%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9649
running_time is 15.714954653999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.07
normal_0.5
./test_glass0/model_MLP_15000_0.07/record_1/MLP_15000_0.07_5
./test_glass0/result_MLP_15000_0.07_normal_0.5/record_1/
----------------------



the AUC is 0.5357142857142857

the Fscore is 0.13333333333333333

the precision is 1.0

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_1
----------------------



epoch 1, loss 0.6546, train acc 62.57%, f1 0.1795, precision 0.3182, recall 0.1250, auc 0.4973
epoch 501, loss 0.3618, train acc 84.21%, f1 0.7840, precision 0.7101, recall 0.8750, auc 0.8505
epoch 1001, loss 0.3338, train acc 86.55%, f1 0.8160, precision 0.7391, recall 0.9107, auc 0.8771
epoch 1501, loss 0.3953, train acc 89.47%, f1 0.8548, precision 0.7794, recall 0.9464, auc 0.9080
epoch 2001, loss 0.3108, train acc 89.47%, f1 0.8548, precision 0.7794, recall 0.9464, auc 0.9080
epoch 2501, loss 0.2963, train acc 89.47%, f1 0.8571, precision 0.7714, recall 0.9643, auc 0.9126
epoch 3001, loss 0.3200, train acc 90.06%, f1 0.8640, precision 0.7826, recall 0.9643, auc 0.9169
epoch 3501, loss 0.3040, train acc 91.23%, f1 0.8780, precision 0.8060, recall 0.9643, auc 0.9256
epoch 4001, loss 0.1485, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 4501, loss 0.1743, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 5001, loss 0.2072, train acc 92.98%, f1 0.9016, precision 0.8333, recall 0.9821, auc 0.9432
epoch 5501, loss 0.1892, train acc 93.57%, f1 0.9091, precision 0.8462, recall 0.9821, auc 0.9476
epoch 6001, loss 0.1115, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 6501, loss 0.0730, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 7001, loss 0.1369, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 7501, loss 0.2169, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.0955, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 8501, loss 0.0685, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 9001, loss 0.0805, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 9501, loss 0.1561, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 10001, loss 0.0847, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10501, loss 0.0823, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 11001, loss 0.1438, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 11501, loss 0.0409, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12001, loss 0.1405, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12501, loss 0.0705, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13001, loss 0.1337, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13501, loss 0.0389, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14001, loss 0.0330, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14501, loss 0.0794, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 15.742503581
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.08
normal_0.5
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_1
./test_glass0/result_MLP_15000_0.08_normal_0.5/record_1/
----------------------



the AUC is 0.5738916256157635

the Fscore is 0.36363636363636365

the precision is 0.5

the recall is 0.2857142857142857

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_2
----------------------



epoch 1, loss 0.6482, train acc 65.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4870
epoch 501, loss 0.3646, train acc 81.87%, f1 0.7559, precision 0.6761, recall 0.8571, auc 0.8286
epoch 1001, loss 0.2699, train acc 85.96%, f1 0.8125, precision 0.7222, recall 0.9286, auc 0.8773
epoch 1501, loss 0.3497, train acc 88.89%, f1 0.8455, precision 0.7761, recall 0.9286, auc 0.8991
epoch 2001, loss 0.2363, train acc 90.06%, f1 0.8618, precision 0.7910, recall 0.9464, auc 0.9123
epoch 2501, loss 0.2651, train acc 91.23%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9210
epoch 3001, loss 0.2028, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 3501, loss 0.1796, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 4001, loss 0.1838, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 4501, loss 0.0782, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 5001, loss 0.1014, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 5501, loss 0.1024, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 6001, loss 0.1370, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6501, loss 0.1644, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7001, loss 0.1269, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7501, loss 0.1151, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.1164, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8501, loss 0.0992, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 9001, loss 0.0712, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 9501, loss 0.1199, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10001, loss 0.1251, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10501, loss 0.0614, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 11001, loss 0.0707, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 11501, loss 0.0389, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12001, loss 0.1085, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 12501, loss 0.0342, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13001, loss 0.0768, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 13501, loss 0.0489, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14001, loss 0.0727, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
epoch 14501, loss 0.0817, train acc 97.66%, f1 0.9649, precision 0.9483, recall 0.9821, auc 0.9780
running_time is 15.888188377
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.08
normal_0.5
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_2
./test_glass0/result_MLP_15000_0.08_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_3
----------------------



epoch 1, loss 0.6415, train acc 63.74%, f1 0.1389, precision 0.3125, recall 0.0893, auc 0.4968
epoch 501, loss 0.4269, train acc 81.29%, f1 0.7419, precision 0.6765, recall 0.8214, auc 0.8151
epoch 1001, loss 0.3673, train acc 83.04%, f1 0.7680, precision 0.6957, recall 0.8571, auc 0.8373
epoch 1501, loss 0.4398, train acc 85.96%, f1 0.8000, precision 0.7500, recall 0.8571, auc 0.8590
epoch 2001, loss 0.2683, train acc 86.55%, f1 0.8099, precision 0.7538, recall 0.8750, auc 0.8679
epoch 2501, loss 0.2933, train acc 88.30%, f1 0.8361, precision 0.7727, recall 0.9107, auc 0.8901
epoch 3001, loss 0.1522, train acc 87.72%, f1 0.8320, precision 0.7536, recall 0.9286, auc 0.8904
epoch 3501, loss 0.2393, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 4001, loss 0.2417, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 4501, loss 0.1321, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 5001, loss 0.2039, train acc 93.57%, f1 0.9060, precision 0.8689, recall 0.9464, auc 0.9384
epoch 5501, loss 0.1262, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 6001, loss 0.0785, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 6501, loss 0.1276, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 7001, loss 0.1112, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 7501, loss 0.0903, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 8001, loss 0.1762, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8501, loss 0.0991, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9001, loss 0.1040, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 9501, loss 0.1223, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10001, loss 0.0979, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 10501, loss 0.0936, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 11001, loss 0.0984, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 11501, loss 0.1015, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12001, loss 0.1087, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12501, loss 0.1413, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 13001, loss 0.0765, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 13501, loss 0.1196, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 14001, loss 0.0736, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 14501, loss 0.0879, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
running_time is 16.02949155
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.08
normal_0.5
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_3
./test_glass0/result_MLP_15000_0.08_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_4
----------------------



epoch 1, loss 0.6350, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3894, train acc 80.70%, f1 0.7317, precision 0.6716, recall 0.8036, auc 0.8061
epoch 1001, loss 0.3103, train acc 82.46%, f1 0.7581, precision 0.6912, recall 0.8393, auc 0.8283
epoch 1501, loss 0.4020, train acc 84.80%, f1 0.7903, precision 0.7206, recall 0.8750, auc 0.8549
epoch 2001, loss 0.3153, train acc 85.96%, f1 0.8033, precision 0.7424, recall 0.8750, auc 0.8636
epoch 2501, loss 0.2520, train acc 87.72%, f1 0.8205, precision 0.7869, recall 0.8571, auc 0.8720
epoch 3001, loss 0.2639, train acc 89.47%, f1 0.8448, precision 0.8167, recall 0.8750, auc 0.8897
epoch 3501, loss 0.2240, train acc 89.47%, f1 0.8525, precision 0.7879, recall 0.9286, auc 0.9034
epoch 4001, loss 0.2203, train acc 90.64%, f1 0.8644, precision 0.8226, recall 0.9107, auc 0.9075
epoch 4501, loss 0.2664, train acc 91.81%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9208
epoch 5001, loss 0.1805, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 5501, loss 0.1821, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 6001, loss 0.1491, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 6501, loss 0.1803, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 7001, loss 0.1544, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 7501, loss 0.1156, train acc 91.81%, f1 0.8833, precision 0.8281, recall 0.9464, auc 0.9254
epoch 8001, loss 0.2775, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 8501, loss 0.1649, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 9001, loss 0.1966, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 9501, loss 0.0822, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 10001, loss 0.1003, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 10501, loss 0.1301, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 11001, loss 0.1673, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 11501, loss 0.1885, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 12001, loss 0.1120, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 12501, loss 0.1806, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 13001, loss 0.1114, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 13501, loss 0.1870, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 14001, loss 0.1196, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 14501, loss 0.1244, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
running_time is 15.862341805
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.08
normal_0.5
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_4
./test_glass0/result_MLP_15000_0.08_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_5
----------------------



epoch 1, loss 0.6868, train acc 36.63%, f1 0.5068, precision 0.3394, recall 1.0000, auc 0.5302
epoch 501, loss 0.3365, train acc 80.81%, f1 0.7273, precision 0.6769, recall 0.7857, auc 0.8023
epoch 1001, loss 0.3414, train acc 81.40%, f1 0.7377, precision 0.6818, recall 0.8036, auc 0.8113
epoch 1501, loss 0.4287, train acc 83.14%, f1 0.7717, precision 0.6901, recall 0.8750, auc 0.8427
epoch 2001, loss 0.3790, train acc 84.88%, f1 0.7937, precision 0.7143, recall 0.8929, auc 0.8602
epoch 2501, loss 0.3150, train acc 85.47%, f1 0.7967, precision 0.7313, recall 0.8750, auc 0.8599
epoch 3001, loss 0.2772, train acc 85.47%, f1 0.7934, precision 0.7385, recall 0.8571, auc 0.8553
epoch 3501, loss 0.3175, train acc 87.21%, f1 0.8226, precision 0.7500, recall 0.9107, auc 0.8821
epoch 4001, loss 0.2288, train acc 90.12%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9083
epoch 4501, loss 0.2785, train acc 91.28%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9169
epoch 5001, loss 0.2045, train acc 91.28%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9169
epoch 5501, loss 0.2206, train acc 91.86%, f1 0.8814, precision 0.8387, recall 0.9286, auc 0.9212
epoch 6001, loss 0.2514, train acc 92.44%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9255
epoch 6501, loss 0.1834, train acc 92.44%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9255
epoch 7001, loss 0.2394, train acc 93.02%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9344
epoch 7501, loss 0.1333, train acc 93.02%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9344
epoch 8001, loss 0.1991, train acc 93.02%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9390
epoch 8501, loss 0.1443, train acc 92.44%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9347
epoch 9001, loss 0.1834, train acc 94.19%, f1 0.9138, precision 0.8833, recall 0.9464, auc 0.9430
epoch 9501, loss 0.1569, train acc 93.02%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9344
epoch 10001, loss 0.1473, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 10501, loss 0.1421, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 11001, loss 0.1716, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11501, loss 0.1266, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 12001, loss 0.0714, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 12501, loss 0.0985, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 13001, loss 0.1624, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 13501, loss 0.1148, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
epoch 14001, loss 0.1324, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 14501, loss 0.0664, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
running_time is 15.781803492999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.08
normal_0.5
./test_glass0/model_MLP_15000_0.08/record_1/MLP_15000_0.08_5
./test_glass0/result_MLP_15000_0.08_normal_0.5/record_1/
----------------------



the AUC is 0.5357142857142857

the Fscore is 0.13333333333333333

the precision is 1.0

the recall is 0.07142857142857142

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_1
----------------------



epoch 1, loss 0.6368, train acc 66.67%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4957
epoch 501, loss 0.4248, train acc 83.04%, f1 0.7680, precision 0.6957, recall 0.8571, auc 0.8373
epoch 1001, loss 0.2811, train acc 85.96%, f1 0.8125, precision 0.7222, recall 0.9286, auc 0.8773
epoch 1501, loss 0.2305, train acc 87.72%, f1 0.8320, precision 0.7536, recall 0.9286, auc 0.8904
epoch 2001, loss 0.3503, train acc 85.96%, f1 0.8125, precision 0.7222, recall 0.9286, auc 0.8773
epoch 2501, loss 0.3410, train acc 89.47%, f1 0.8525, precision 0.7879, recall 0.9286, auc 0.9034
epoch 3001, loss 0.3097, train acc 90.64%, f1 0.8689, precision 0.8030, recall 0.9464, auc 0.9167
epoch 3501, loss 0.2028, train acc 91.23%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9210
epoch 4001, loss 0.2675, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 4501, loss 0.1941, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 5001, loss 0.2579, train acc 94.15%, f1 0.9167, precision 0.8594, recall 0.9821, auc 0.9519
epoch 5501, loss 0.1994, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 6001, loss 0.1809, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 6501, loss 0.2214, train acc 95.32%, f1 0.9322, precision 0.8871, recall 0.9821, auc 0.9606
epoch 7001, loss 0.1719, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 7501, loss 0.0958, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 8001, loss 0.0838, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 8501, loss 0.2013, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 9001, loss 0.1123, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 9501, loss 0.1835, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 10001, loss 0.1170, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 10501, loss 0.1320, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 11001, loss 0.0502, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 11501, loss 0.1384, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12001, loss 0.0930, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12501, loss 0.0980, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13001, loss 0.0547, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13501, loss 0.1607, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14001, loss 0.0389, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 14501, loss 0.0409, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
running_time is 15.76971715
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.09
normal_0.5
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_1
./test_glass0/result_MLP_15000_0.09_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_2
----------------------



epoch 1, loss 0.6223, train acc 60.23%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4478
epoch 501, loss 0.3056, train acc 83.04%, f1 0.7642, precision 0.7015, recall 0.8393, auc 0.8327
epoch 1001, loss 0.3710, train acc 85.38%, f1 0.8000, precision 0.7246, recall 0.8929, auc 0.8638
epoch 1501, loss 0.2662, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 2001, loss 0.2156, train acc 89.47%, f1 0.8548, precision 0.7794, recall 0.9464, auc 0.9080
epoch 2501, loss 0.2104, train acc 90.64%, f1 0.8689, precision 0.8030, recall 0.9464, auc 0.9167
epoch 3001, loss 0.1898, train acc 90.64%, f1 0.8689, precision 0.8030, recall 0.9464, auc 0.9167
epoch 3501, loss 0.1944, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 4001, loss 0.1854, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 4501, loss 0.1303, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 5001, loss 0.1475, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 5501, loss 0.1544, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 6001, loss 0.1103, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 6501, loss 0.1085, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 7001, loss 0.0902, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 7501, loss 0.1082, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 8001, loss 0.0559, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 8501, loss 0.1113, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 9001, loss 0.1372, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 9501, loss 0.1481, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 10001, loss 0.0745, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10501, loss 0.0822, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 11001, loss 0.1181, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.1638, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12001, loss 0.1440, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 12501, loss 0.1167, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13001, loss 0.0688, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 13501, loss 0.0595, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14001, loss 0.0899, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.0653, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
running_time is 15.796906929999999
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.09
normal_0.5
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_2
./test_glass0/result_MLP_15000_0.09_normal_0.5/record_1/
----------------------



the AUC is 0.4827586206896552

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_3
----------------------



epoch 1, loss 0.6294, train acc 67.25%, f1 0.0667, precision 0.5000, recall 0.0357, auc 0.5092
epoch 501, loss 0.4324, train acc 80.70%, f1 0.7360, precision 0.6667, recall 0.8214, auc 0.8107
epoch 1001, loss 0.4316, train acc 83.04%, f1 0.7642, precision 0.7015, recall 0.8393, auc 0.8327
epoch 1501, loss 0.4203, train acc 85.38%, f1 0.7899, precision 0.7460, recall 0.8393, auc 0.8501
epoch 2001, loss 0.2443, train acc 85.96%, f1 0.8000, precision 0.7500, recall 0.8571, auc 0.8590
epoch 2501, loss 0.3208, train acc 87.72%, f1 0.8293, precision 0.7612, recall 0.9107, auc 0.8858
epoch 3001, loss 0.2792, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 3501, loss 0.1505, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 4001, loss 0.2347, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 4501, loss 0.2243, train acc 92.40%, f1 0.8926, precision 0.8308, recall 0.9643, auc 0.9343
epoch 5001, loss 0.1651, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 5501, loss 0.1620, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 6001, loss 0.1719, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 6501, loss 0.1278, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 7001, loss 0.1265, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 7501, loss 0.1721, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8001, loss 0.1298, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 8501, loss 0.2220, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 9001, loss 0.1502, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9501, loss 0.1132, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10001, loss 0.1401, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 10501, loss 0.1497, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 11001, loss 0.1210, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 11501, loss 0.1637, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 12001, loss 0.0625, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 12501, loss 0.0980, train acc 95.91%, f1 0.9402, precision 0.9016, recall 0.9821, auc 0.9650
epoch 13001, loss 0.0594, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13501, loss 0.0995, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 14001, loss 0.1181, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 14501, loss 0.0386, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
running_time is 15.775218646
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.09
normal_0.5
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_3
./test_glass0/result_MLP_15000_0.09_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_4
----------------------



epoch 1, loss 0.6877, train acc 53.80%, f1 0.5864, precision 0.4148, recall 1.0000, auc 0.6565
epoch 501, loss 0.3318, train acc 78.95%, f1 0.7097, precision 0.6471, recall 0.7857, auc 0.7885
epoch 1001, loss 0.3486, train acc 81.87%, f1 0.7559, precision 0.6761, recall 0.8571, auc 0.8286
epoch 1501, loss 0.3183, train acc 83.63%, f1 0.7705, precision 0.7121, recall 0.8393, auc 0.8370
epoch 2001, loss 0.3593, train acc 85.96%, f1 0.8000, precision 0.7500, recall 0.8571, auc 0.8590
epoch 2501, loss 0.1974, train acc 88.30%, f1 0.8276, precision 0.8000, recall 0.8571, auc 0.8764
epoch 3001, loss 0.1884, train acc 90.06%, f1 0.8571, precision 0.8095, recall 0.9107, auc 0.9032
epoch 3501, loss 0.2167, train acc 90.64%, f1 0.8621, precision 0.8333, recall 0.8929, auc 0.9030
epoch 4001, loss 0.1748, train acc 90.06%, f1 0.8571, precision 0.8095, recall 0.9107, auc 0.9032
epoch 4501, loss 0.1877, train acc 91.81%, f1 0.8793, precision 0.8500, recall 0.9107, auc 0.9162
epoch 5001, loss 0.1958, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 5501, loss 0.1953, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 6001, loss 0.1857, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 6501, loss 0.1569, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 7001, loss 0.2208, train acc 94.74%, f1 0.9217, precision 0.8983, recall 0.9464, auc 0.9471
epoch 7501, loss 0.1935, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8001, loss 0.1206, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 8501, loss 0.1355, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9001, loss 0.1393, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 9501, loss 0.0950, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10001, loss 0.1078, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 10501, loss 0.0883, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 11001, loss 0.1004, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 11501, loss 0.0954, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12001, loss 0.1316, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 12501, loss 0.1298, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 13001, loss 0.1168, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 13501, loss 0.1052, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 14001, loss 0.1188, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 14501, loss 0.1439, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
running_time is 15.7251302
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.09
normal_0.5
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_4
./test_glass0/result_MLP_15000_0.09_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_5
----------------------



epoch 1, loss 0.6587, train acc 67.44%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3702, train acc 80.81%, f1 0.7481, precision 0.6533, recall 0.8750, auc 0.8254
epoch 1001, loss 0.4241, train acc 83.14%, f1 0.7752, precision 0.6849, recall 0.8929, auc 0.8473
epoch 1501, loss 0.3638, train acc 83.72%, f1 0.7812, precision 0.6944, recall 0.8929, auc 0.8516
epoch 2001, loss 0.4554, train acc 85.47%, f1 0.8031, precision 0.7183, recall 0.9107, auc 0.8692
epoch 2501, loss 0.2751, train acc 86.63%, f1 0.8160, precision 0.7391, recall 0.9107, auc 0.8778
epoch 3001, loss 0.2517, train acc 86.05%, f1 0.8065, precision 0.7353, recall 0.8929, auc 0.8688
epoch 3501, loss 0.2147, train acc 86.63%, f1 0.8099, precision 0.7538, recall 0.8750, auc 0.8685
epoch 4001, loss 0.2512, train acc 88.95%, f1 0.8455, precision 0.7761, recall 0.9286, auc 0.8996
epoch 4501, loss 0.2378, train acc 91.28%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9215
epoch 5001, loss 0.1794, train acc 91.86%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9304
epoch 5501, loss 0.2162, train acc 91.86%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9304
epoch 6001, loss 0.1677, train acc 93.02%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9390
epoch 6501, loss 0.2173, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 7001, loss 0.2510, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 7501, loss 0.1624, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 8001, loss 0.1512, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 8501, loss 0.1253, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 9001, loss 0.1774, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 9501, loss 0.1222, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 10001, loss 0.1523, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 10501, loss 0.1627, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11001, loss 0.0931, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11501, loss 0.1485, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 12001, loss 0.1543, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 12501, loss 0.1659, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 13001, loss 0.1088, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 13501, loss 0.1359, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 14001, loss 0.1845, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 14501, loss 0.1123, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
running_time is 15.711930553999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.09
normal_0.5
./test_glass0/model_MLP_15000_0.09/record_1/MLP_15000_0.09_5
./test_glass0/result_MLP_15000_0.09_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_1
----------------------



epoch 1, loss 0.6731, train acc 46.78%, f1 0.5517, precision 0.3810, recall 1.0000, auc 0.6043
epoch 501, loss 0.2983, train acc 84.21%, f1 0.7874, precision 0.7042, recall 0.8929, auc 0.8551
epoch 1001, loss 0.3541, train acc 85.38%, f1 0.8062, precision 0.7123, recall 0.9286, auc 0.8730
epoch 1501, loss 0.3083, train acc 85.96%, f1 0.8125, precision 0.7222, recall 0.9286, auc 0.8773
epoch 2001, loss 0.2169, train acc 86.55%, f1 0.8189, precision 0.7324, recall 0.9286, auc 0.8817
epoch 2501, loss 0.2271, train acc 87.13%, f1 0.8254, precision 0.7429, recall 0.9286, auc 0.8860
epoch 3001, loss 0.2439, train acc 88.30%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8947
epoch 3501, loss 0.2788, train acc 88.89%, f1 0.8455, precision 0.7761, recall 0.9286, auc 0.8991
epoch 4001, loss 0.2302, train acc 91.23%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9210
epoch 4501, loss 0.1848, train acc 92.40%, f1 0.8943, precision 0.8209, recall 0.9821, auc 0.9389
epoch 5001, loss 0.2415, train acc 92.40%, f1 0.8943, precision 0.8209, recall 0.9821, auc 0.9389
epoch 5501, loss 0.1784, train acc 92.98%, f1 0.9032, precision 0.8235, recall 1.0000, auc 0.9478
epoch 6001, loss 0.1570, train acc 93.57%, f1 0.9106, precision 0.8358, recall 1.0000, auc 0.9522
epoch 6501, loss 0.1491, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 7001, loss 0.1782, train acc 94.15%, f1 0.9180, precision 0.8485, recall 1.0000, auc 0.9565
epoch 7501, loss 0.1583, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 8001, loss 0.0816, train acc 94.74%, f1 0.9256, precision 0.8615, recall 1.0000, auc 0.9609
epoch 8501, loss 0.1186, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 9001, loss 0.1023, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 9501, loss 0.0767, train acc 95.91%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9696
epoch 10001, loss 0.1004, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 10501, loss 0.0756, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 11001, loss 0.0998, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 11501, loss 0.1219, train acc 96.49%, f1 0.9492, precision 0.9032, recall 1.0000, auc 0.9739
epoch 12001, loss 0.0976, train acc 97.08%, f1 0.9573, precision 0.9180, recall 1.0000, auc 0.9783
epoch 12501, loss 0.0993, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 13001, loss 0.0488, train acc 98.83%, f1 0.9825, precision 0.9655, recall 1.0000, auc 0.9913
epoch 13501, loss 0.0852, train acc 99.42%, f1 0.9912, precision 0.9825, recall 1.0000, auc 0.9957
epoch 14001, loss 0.0781, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0691, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 15.725394392999998
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_1.csv
./test_glass0/standlization_data/glass0_std_test_1.csv
MLP_15000_0.1
normal_0.5
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_1
./test_glass0/result_MLP_15000_0.1_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_2
----------------------



epoch 1, loss 0.6405, train acc 67.25%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 501, loss 0.3761, train acc 82.46%, f1 0.7619, precision 0.6857, recall 0.8571, auc 0.8329
epoch 1001, loss 0.3391, train acc 84.21%, f1 0.7874, precision 0.7042, recall 0.8929, auc 0.8551
epoch 1501, loss 0.3147, train acc 88.89%, f1 0.8430, precision 0.7846, recall 0.9107, auc 0.8945
epoch 2001, loss 0.1984, train acc 89.47%, f1 0.8525, precision 0.7879, recall 0.9286, auc 0.9034
epoch 2501, loss 0.2332, train acc 91.81%, f1 0.8852, precision 0.8182, recall 0.9643, auc 0.9300
epoch 3001, loss 0.2020, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 3501, loss 0.2162, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 4001, loss 0.1017, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 4501, loss 0.1902, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 5001, loss 0.1152, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 5501, loss 0.1711, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 6001, loss 0.1095, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 6501, loss 0.1824, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7001, loss 0.1445, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 7501, loss 0.0805, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8001, loss 0.1143, train acc 96.49%, f1 0.9483, precision 0.9167, recall 0.9821, auc 0.9693
epoch 8501, loss 0.0803, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9001, loss 0.1572, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 9501, loss 0.0489, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10001, loss 0.0818, train acc 97.66%, f1 0.9655, precision 0.9333, recall 1.0000, auc 0.9826
epoch 10501, loss 0.1033, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11001, loss 0.1358, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 11501, loss 0.0984, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12001, loss 0.1138, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 12501, loss 0.1030, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13001, loss 0.0428, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 13501, loss 0.1099, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14001, loss 0.1342, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
epoch 14501, loss 0.0447, train acc 98.25%, f1 0.9739, precision 0.9492, recall 1.0000, auc 0.9870
running_time is 15.803170016000001
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_2.csv
./test_glass0/standlization_data/glass0_std_test_2.csv
MLP_15000_0.1
normal_0.5
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_2
./test_glass0/result_MLP_15000_0.1_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_3
----------------------



epoch 1, loss 0.6325, train acc 59.65%, f1 0.1687, precision 0.2593, recall 0.1250, auc 0.4755
epoch 501, loss 0.3944, train acc 80.12%, f1 0.7258, precision 0.6618, recall 0.8036, auc 0.8018
epoch 1001, loss 0.3074, train acc 83.04%, f1 0.7642, precision 0.7015, recall 0.8393, auc 0.8327
epoch 1501, loss 0.2922, train acc 85.38%, f1 0.7967, precision 0.7313, recall 0.8750, auc 0.8592
epoch 2001, loss 0.3408, train acc 88.30%, f1 0.8333, precision 0.7812, recall 0.8929, auc 0.8856
epoch 2501, loss 0.3504, train acc 87.72%, f1 0.8293, precision 0.7612, recall 0.9107, auc 0.8858
epoch 3001, loss 0.2679, train acc 87.13%, f1 0.8254, precision 0.7429, recall 0.9286, auc 0.8860
epoch 3501, loss 0.2775, train acc 89.47%, f1 0.8525, precision 0.7879, recall 0.9286, auc 0.9034
epoch 4001, loss 0.1760, train acc 90.06%, f1 0.8571, precision 0.8095, recall 0.9107, auc 0.9032
epoch 4501, loss 0.1950, train acc 91.23%, f1 0.8760, precision 0.8154, recall 0.9464, auc 0.9210
epoch 5001, loss 0.2022, train acc 92.40%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9297
epoch 5501, loss 0.1998, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 6001, loss 0.1274, train acc 92.98%, f1 0.9000, precision 0.8438, recall 0.9643, auc 0.9387
epoch 6501, loss 0.1701, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 7001, loss 0.1625, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 7501, loss 0.1865, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8001, loss 0.1330, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8501, loss 0.1374, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 9001, loss 0.1314, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 9501, loss 0.1454, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 10001, loss 0.1444, train acc 95.32%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9561
epoch 10501, loss 0.1164, train acc 96.49%, f1 0.9474, precision 0.9310, recall 0.9643, auc 0.9648
epoch 11001, loss 0.1680, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 11501, loss 0.1386, train acc 95.91%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9604
epoch 12001, loss 0.1293, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 12501, loss 0.1106, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13001, loss 0.0574, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 13501, loss 0.0806, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 14001, loss 0.0956, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
epoch 14501, loss 0.1301, train acc 97.08%, f1 0.9565, precision 0.9322, recall 0.9821, auc 0.9737
running_time is 15.686994579
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_3.csv
./test_glass0/standlization_data/glass0_std_test_3.csv
MLP_15000_0.1
normal_0.5
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_3
./test_glass0/result_MLP_15000_0.1_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_4
----------------------



epoch 1, loss 0.6243, train acc 67.25%, f1 0.0345, precision 0.5000, recall 0.0179, auc 0.5046
epoch 501, loss 0.3949, train acc 77.78%, f1 0.7164, precision 0.6154, recall 0.8571, auc 0.7981
epoch 1001, loss 0.3887, train acc 81.87%, f1 0.7559, precision 0.6761, recall 0.8571, auc 0.8286
epoch 1501, loss 0.2734, train acc 83.04%, f1 0.7680, precision 0.6957, recall 0.8571, auc 0.8373
epoch 2001, loss 0.2998, train acc 83.63%, f1 0.7812, precision 0.6944, recall 0.8929, auc 0.8508
epoch 2501, loss 0.2634, train acc 87.13%, f1 0.8226, precision 0.7500, recall 0.9107, auc 0.8814
epoch 3001, loss 0.2230, train acc 90.06%, f1 0.8595, precision 0.8000, recall 0.9286, auc 0.9078
epoch 3501, loss 0.2323, train acc 90.64%, f1 0.8667, precision 0.8125, recall 0.9286, auc 0.9121
epoch 4001, loss 0.2550, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 4501, loss 0.2506, train acc 91.23%, f1 0.8739, precision 0.8254, recall 0.9286, auc 0.9165
epoch 5001, loss 0.1222, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 5501, loss 0.2053, train acc 92.40%, f1 0.8889, precision 0.8525, recall 0.9286, auc 0.9252
epoch 6001, loss 0.1789, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 6501, loss 0.1856, train acc 92.98%, f1 0.8983, precision 0.8548, recall 0.9464, auc 0.9341
epoch 7001, loss 0.2050, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 7501, loss 0.2080, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 8001, loss 0.1455, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 8501, loss 0.1455, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 9001, loss 0.2046, train acc 93.57%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9430
epoch 9501, loss 0.0873, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 10001, loss 0.1250, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 10501, loss 0.1629, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 11001, loss 0.1260, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 11501, loss 0.2312, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 12001, loss 0.1420, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 12501, loss 0.2013, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 13001, loss 0.1407, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
epoch 13501, loss 0.1346, train acc 94.15%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9474
epoch 14001, loss 0.0964, train acc 94.74%, f1 0.9244, precision 0.8730, recall 0.9821, auc 0.9563
epoch 14501, loss 0.1833, train acc 94.74%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9517
running_time is 15.697753915
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_4.csv
./test_glass0/standlization_data/glass0_std_test_4.csv
MLP_15000_0.1
normal_0.5
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_4
./test_glass0/result_MLP_15000_0.1_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_5
----------------------



epoch 1, loss 0.6163, train acc 62.21%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4612
epoch 501, loss 0.4236, train acc 82.56%, f1 0.7619, precision 0.6857, recall 0.8571, auc 0.8337
epoch 1001, loss 0.3566, train acc 83.14%, f1 0.7786, precision 0.6800, recall 0.9107, auc 0.8519
epoch 1501, loss 0.3574, train acc 86.63%, f1 0.8189, precision 0.7324, recall 0.9286, auc 0.8824
epoch 2001, loss 0.2680, train acc 86.05%, f1 0.8125, precision 0.7222, recall 0.9286, auc 0.8781
epoch 2501, loss 0.2352, train acc 88.37%, f1 0.8387, precision 0.7647, recall 0.9286, auc 0.8953
epoch 3001, loss 0.2623, train acc 89.53%, f1 0.8525, precision 0.7879, recall 0.9286, auc 0.9039
epoch 3501, loss 0.3139, train acc 90.70%, f1 0.8689, precision 0.8030, recall 0.9464, auc 0.9172
epoch 4001, loss 0.2189, train acc 92.44%, f1 0.8908, precision 0.8413, recall 0.9464, auc 0.9301
epoch 4501, loss 0.1784, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 5001, loss 0.1661, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 5501, loss 0.2472, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 6001, loss 0.1380, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 6501, loss 0.1384, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 7001, loss 0.1968, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 7501, loss 0.1803, train acc 93.60%, f1 0.9076, precision 0.8571, recall 0.9643, auc 0.9433
epoch 8001, loss 0.1893, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 8501, loss 0.1562, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 9001, loss 0.1718, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 9501, loss 0.1210, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 10001, loss 0.1191, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 10501, loss 0.1075, train acc 95.93%, f1 0.9391, precision 0.9153, recall 0.9643, auc 0.9606
epoch 11001, loss 0.1549, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 11501, loss 0.0670, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 12001, loss 0.1847, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 12501, loss 0.1261, train acc 94.19%, f1 0.9153, precision 0.8710, recall 0.9643, auc 0.9477
epoch 13001, loss 0.0620, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 13501, loss 0.1700, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 14001, loss 0.0738, train acc 94.77%, f1 0.9231, precision 0.8852, recall 0.9643, auc 0.9520
epoch 14501, loss 0.0796, train acc 95.35%, f1 0.9310, precision 0.9000, recall 0.9643, auc 0.9563
running_time is 15.765711131000002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_glass0/standlization_data/glass0_std_train_5.csv
./test_glass0/standlization_data/glass0_std_test_5.csv
MLP_15000_0.1
normal_0.5
./test_glass0/model_MLP_15000_0.1/record_1/MLP_15000_0.1_5
./test_glass0/result_MLP_15000_0.1_normal_0.5/record_1/
----------------------



the AUC is 0.5

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
